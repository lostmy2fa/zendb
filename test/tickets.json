{"results":[{"url":"https://confluent.zendesk.com/api/v2/tickets/1963.json","id":1963,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-13T19:57:59Z","updated_at":"2017-07-14T17:34:11Z","type":"incident","subject":"Custom backing topics for state stores","raw_subject":"Custom backing topics for state stores","description":"Is there a way to specify (non-internal) backing topics for state stores?\r\n\r\nThis seems like an important way to restore the state of an application if it is modified and the application ID is changed, and for some state to survive the Kafka Streams Reset Tool: https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Streams+Application+Reset+Tool\r\n\r\nReconsuming all events from the beginning of time to restore state does not seem feasible for some use cases, e.g. when there are many input events and the input event topic needs to be compacted to avoid unbounded growth.","priority":null,"status":"open","recipient":null,"requester_id":13182623587,"submitter_id":13182623587,"assignee_id":5930716698,"organization_id":6127153607,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","confluent__3_2_0","development","gold","jdk_1_8","jira_escalated","kafka_streams","p3_issue","recommendation___best_practices","streams_escalated","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"kafka_streams"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"2477"},{"id":34347728,"value":"640"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"kafka_streams"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"2477"},{"id":34347728,"value":"640"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1953.json","id":1953,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-12T23:30:30Z","updated_at":"2017-07-13T15:54:58Z","type":"incident","subject":"High level Kafka Connect use case","raw_subject":"High level Kafka Connect use case","description":"How would I use Kafka Connect to pull data from a database table and write it to a file?\r\n\r\nI followed the jdbc sqlite example to pull the accounts table into a topic. I am trying to figure out how I could create a Kafka Connector to read that data, using the File Connector as my test.\r\n\r\nBelow are the console consumer showing the two records in my topic, the configuration of a file sink connector, and the contents of the generated sink file.\r\n\r\nI recognize that this question probably demonstrates a fundamental ignorance of Kafka Connect use cases. Am I attempting something that makes no sense?\r\n\r\n[206047844@ashaplq00003 ~]$ bin/kafka-console-consumer --bootstrap-server localhost:9092 --zookeeper localhost:2181/kafka --from-beginning --topic demo-jdbc-accounts\r\n{\"schema\":{\"type\":\"struct\",\"fields\":[{\"type\":\"int32\",\"optional\":false,\"field\":\"id\"},{\"type\":\"string\",\"optional\":true,\"field\":\"name\"}],\"optional\":false,\"name\":\"accounts\"},\"payload\":{\"id\":1,\"name\":\"deepak\"}}\r\n{\"schema\":{\"type\":\"struct\",\"fields\":[{\"type\":\"int32\",\"optional\":false,\"field\":\"id\"},{\"type\":\"string\",\"optional\":true,\"field\":\"name\"}],\"optional\":false,\"name\":\"accounts\"},\"payload\":{\"id\":2,\"name\":\"bob\"}}\r\n^CProcessed a total of 2 messages\r\n\r\n[206047844@ashaplq00003 ~]$ curl -X GET localhost:8083/connectors/demo-jdbc-file-sink/config\r\n{\"topics\":\"demo-jdbc-accounts\",\"file\":\"jdbc.sink.txt\",\"tasks.max\":\"1\",\"name\":\"demo-jdbc-file-sink\",\"connector.class\":\"FileStreamSink\"}\r\n\r\n[206047844@ashaplq00003 ~]$\r\n[206047844@ashaplq00003 ~]$ cat jdbc.sink.txt\r\norg.apache.kafka.connect.data.Struct@1c19d37b\r\norg.apache.kafka.connect.data.Struct@6bb7d339\r\n","priority":null,"status":"open","recipient":null,"requester_id":6021608663,"submitter_id":6021608663,"assignee_id":5699232346,"organization_id":6607631286,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["confluent__3_0_1","development","jdk_1_7","kafka_connect","p3_issue","rhel_6"],"custom_fields":[{"id":24843497,"value":"confluent__3_0_1"},{"id":26235617,"value":"jdk_1_7"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"kafka_connect"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"1457"},{"id":34347728,"value":"26"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_0_1"},{"id":26235617,"value":"jdk_1_7"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"kafka_connect"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"1457"},{"id":34347728,"value":"26"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1950.json","id":1950,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-12T21:34:44Z","updated_at":"2017-07-12T21:49:30Z","type":"incident","subject":"Confluent on Kubernetes. ","raw_subject":"Confluent on Kubernetes. ","description":"I need to be able to bring up the Confluent platform in a Kubernetes environment. I'm just looking for notes and docs at this time. ","priority":null,"status":"open","recipient":null,"requester_id":22314449307,"submitter_id":22314449307,"assignee_id":13678049447,"organization_id":16907285687,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["confluent__3_2_2","general_question","gold","jdk_1_8","multiple","p3_issue","rhel_7","rick_conrad","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"general_question"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"714"},{"id":34347728,"value":"661"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"general_question"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"714"},{"id":34347728,"value":"661"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1944.json","id":1944,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-12T15:29:24Z","updated_at":"2017-07-12T20:06:23Z","type":"incident","subject":"Feature Request - View and Re-Post Messages from Confluent Control Center","raw_subject":"Feature Request - View and Re-Post Messages from Confluent Control Center","description":"For troubleshooting, we would like to have a screen in Confluent Control Center to enable the following capabilities. \r\n* View messages in a Kafka Topic by range of time or by last N messages\r\n* Edit the contents of the messages (just a plain text editor)\r\n* Re-post the messages to same topic (as new messages, not replay)\r\n* Ability to point the tool to all of the clusters being monitored by C3\r\n* export the viewed messages to a file\r\n* import the messages from a file to the screen that permits re-posting to a topic","priority":null,"status":"open","recipient":null,"requester_id":9110465307,"submitter_id":9110465307,"assignee_id":13678049447,"organization_id":10819252647,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["bug","confluent__3_2_0","confluent_control_center","gold","jdk_1_8","jeremy_custenborder","multiple","p4_issue","rhel_7","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":"bug"},{"id":33471847,"value":"p4_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"294"},{"id":34347728,"value":"266"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":"bug"},{"id":33471847,"value":"p4_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"294"},{"id":34347728,"value":"266"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1942.json","id":1942,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-12T03:28:31Z","updated_at":"2017-07-15T01:13:26Z","type":"incident","subject":"How to identify that the broker is ready for requests through JMX?","raw_subject":"How to identify that the broker is ready for requests through JMX?","description":"How to identify that the broker is ready for requests though JMX?","priority":null,"status":"open","recipient":null,"requester_id":16162852587,"submitter_id":21324568227,"assignee_id":21324568227,"organization_id":14010977147,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["apache_kafka__0_10_2_0","broker","development","gold","jdk_1_8","p3_issue","recommendation___best_practices","rhel_6","us_canada"],"custom_fields":[{"id":24843497,"value":"apache_kafka__0_10_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"broker"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"3493"},{"id":34347728,"value":"980"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"apache_kafka__0_10_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"broker"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"3493"},{"id":34347728,"value":"980"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1939.json","id":1939,"external_id":null,"via":{"channel":"web","source":{"to":{},"from":{"ticket_id":null,"subject":null},"rel":"follow_up"}},"created_at":"2017-07-11T22:04:53Z","updated_at":"2017-07-13T19:10:12Z","type":"incident","subject":"RE: [Request received by Confluent Support] Confluent License Key // Macy's Onboarding","raw_subject":"RE: [Request received by Confluent Support] Confluent License Key // Macy's Onboarding","description":"This is a follow-up to your previous request #1372 \"Confluent License Key // Ma...\"\n\nHi Support,\n\nI’m seeing a “Your license has expired. Sign up for a subscription.” message when I start Control-Center with the below license key.\n\n \n\nAtulya B | IFS TIBCO+ | Macy’s Systems and Technology\n\n5985 State Bridge Road | Johns Creek, GA 30097 | 312-929-5416\n \n\n⚠ EXT MSG:","priority":null,"status":"open","recipient":"support@confluent.io","requester_id":21787299508,"submitter_id":21787299508,"assignee_id":5699232346,"organization_id":16542134308,"group_id":29623388,"collaborator_ids":[21963998867],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["bug","confluent__3_2_0","confluent_control_center","gold","jdk_1_8","p3_issue","staging","summarized","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":""},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":"bug"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"staging"},{"id":77414608,"value":null},{"id":34347708,"value":"971"},{"id":34347728,"value":"578"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":""},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":"bug"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"staging"},{"id":77414608,"value":null},{"id":34347708,"value":"971"},{"id":34347728,"value":"578"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1936.json","id":1936,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-11T18:28:27Z","updated_at":"2017-07-14T00:54:35Z","type":"incident","subject":"Kafka Latency & Performance Tuning","raw_subject":"Kafka Latency & Performance Tuning","description":"Hi Jason,\n\nPer our email conversation, I'm opening up this support case where we can continue investigating the performance issues you're seeing.  \n\nBest,\nSam","priority":null,"status":"open","recipient":null,"requester_id":6062717623,"submitter_id":3324019678,"assignee_id":5972174278,"organization_id":6832912406,"group_id":28849068,"collaborator_ids":[5930716698,3324019678,21095585667,6073717403,6073718363],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["development","p3_issue"],"custom_fields":[{"id":24843497,"value":""},{"id":26235617,"value":""},{"id":26235607,"value":""},{"id":33020448,"value":""},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"5332"},{"id":34347728,"value":"74"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":""},{"id":26235617,"value":""},{"id":26235607,"value":""},{"id":33020448,"value":""},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"5332"},{"id":34347728,"value":"74"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1889.json","id":1889,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-06T17:13:18Z","updated_at":"2017-07-13T18:46:31Z","type":"incident","subject":"Kafka Connect Offsets","raw_subject":"Kafka Connect Offsets","description":"Is there a way to manage kafka connect offsets?  Am I able to set a connector to read from newest or point specifically to a point in time to read from?","priority":null,"status":"open","recipient":null,"requester_id":21000116327,"submitter_id":21000116327,"assignee_id":5699232346,"organization_id":15862541148,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","confluent__3_2_1","consumer","development","documentation_issue","gold","jdk_1_8","p3_issue","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"consumer"},{"id":47641647,"value":"documentation_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"3323"},{"id":34347728,"value":"227"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"consumer"},{"id":47641647,"value":"documentation_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"3323"},{"id":34347728,"value":"227"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1885.json","id":1885,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-06T10:54:32Z","updated_at":"2017-07-14T06:17:39Z","type":"incident","subject":"Zookeeper ACLs for multiple Kafka Brokers","raw_subject":"Zookeeper ACLs for multiple Kafka Brokers","description":"Hello,\r\n\r\nI am configuring ACLs for zookeeper nodes used by kafka brokers using the manual(http://docs.confluent.io/current/kafka/zookeeper-authentication.html). I have 3 brokers in a cluster, their principals are: kafka/broker1@REALM, kafka/broker2@REALM and kafka/broker3@REALM. When I execute zookeeper-security-migration tool on broker1, it sets ACLs \"cdrwa\" for \"kafka/broker1@REALM\" and \"r\" for anyone. After migration, brokers 2 and 3 cannot modify the nodes in zookeeper (as they are not listed in ACLs) and cluster is broken. \r\n\r\nWhat can I do in this case? Can Zookeeper somehow be configured to compare principals without hostnames during ACLs checking? Or maybe Kafka brokers can set ACLs for all brokers for each zookeeper node?","priority":null,"status":"open","recipient":null,"requester_id":5979417006,"submitter_id":5979417006,"assignee_id":13678049447,"organization_id":6312218263,"group_id":29623388,"collaborator_ids":[17825563008],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","configuration_issue","confluent__3_2_1","development","enterprise","europe","gold","jdk_1_8","kai_waehner","p3_issue","zookeeper"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"zookeeper"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"6705"},{"id":34347728,"value":"876"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"zookeeper"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"6705"},{"id":34347728,"value":"876"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1883.json","id":1883,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-05T22:26:51Z","updated_at":"2017-07-15T00:11:59Z","type":"incident","subject":"Message format for old consumers in 0.10","raw_subject":"Message format for old consumers in 0.10","description":"I need some clarifications..\r\n\r\nThe old consumer (uses zookeeper) is also available in 0.10 also. When old consumer is used from 0.10, can it read the messages in 0.10 message format or it expects older formats. In other words will broker need to convert messages to an older format for supporting zookeeper based consumer in 0.10.","priority":null,"status":"open","recipient":null,"requester_id":16162878107,"submitter_id":16162878107,"assignee_id":5699232346,"organization_id":14010977147,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["apache_kafka__0_10_2_0","configuration_issue","general_question","gold","jdk_1_8","p3_issue","production","rhel_6","us_canada"],"custom_fields":[{"id":24843497,"value":"apache_kafka__0_10_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"general_question"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"5382"},{"id":34347728,"value":"213"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"apache_kafka__0_10_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"general_question"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"5382"},{"id":34347728,"value":"213"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1876.json","id":1876,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-05T18:21:51Z","updated_at":"2017-07-13T17:54:21Z","type":"incident","subject":"Kafka 11","raw_subject":"Kafka 11","description":"Hi, Can you tell me when the Confluent enterprise package will be updated to include Kafka 11?\r\n\r\nAlso, have you made progress on interceptor support for other languages (librd)?\r\n\r\nThanks, \r\nJeff","priority":null,"status":"open","recipient":null,"requester_id":21243744848,"submitter_id":21243744848,"assignee_id":5699232346,"organization_id":15862541148,"group_id":29623388,"collaborator_ids":[21000058107],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","confluent__3_2_1","general_question__roadmap_request","gold","jdk_1_8","non_technical_request__roadmap_request","p3_issue","production","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"general_question__roadmap_request"},{"id":47641647,"value":"non_technical_request__roadmap_request"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"2381"},{"id":34347728,"value":"394"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"general_question__roadmap_request"},{"id":47641647,"value":"non_technical_request__roadmap_request"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"2381"},{"id":34347728,"value":"394"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1872.json","id":1872,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-05T14:47:23Z","updated_at":"2017-07-14T13:19:04Z","type":"incident","subject":"Mirrormaker - Producer failing with \" Producer is closed forcefully.\"","raw_subject":"Mirrormaker - Producer failing with \" Producer is closed forcefully.\"","description":"Hi,\r\n\r\nIn one of our mirrormaker, we see that producer is failing with the following error.\r\nIt shuts the mirrormaker down.\r\n\r\n\r\n====================================\r\n[2017-07-05 12:41:47,914Z](kafka-producer-network-thread | producer-1) ERROR - o.a.k.c.p.i.ErrorLoggingCallback - Error when sending message to topic entityEventListing.global with key: 60 bytes, value: 10320 bytes with error:\r\njava.lang.IllegalStateException: Producer is closed forcefully.\r\n\tat org.apache.kafka.clients.producer.internals.RecordAccumulator.abortBatches(RecordAccumulator.java:513)\r\n\tat org.apache.kafka.clients.producer.internals.RecordAccumulator.abortIncompleteBatches(RecordAccumulator.java:493)\r\n\tat org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:156)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n\r\n[2017-07-05 12:41:47,925Z](mirrormaker-thread-0) ERROR - k.t.MirrorMaker$MirrorMakerThread - [mirrormaker-thread-0] Mirror maker thread exited abnormally, stopping the whole mirror maker.\r\n====================================\r\n\r\nCan you let us know\r\n1. What is the reason for this errror ? what could have caused this error\r\n2. How can I avoid this error ?\r\n\r\n\r\nThis is a case which is in between  Production Degradation (As I restarted the process) and Feature Request.\r\n","priority":null,"status":"open","recipient":null,"requester_id":9125304907,"submitter_id":9125304907,"assignee_id":5930716698,"organization_id":8874211307,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["_restaurants__leisure","centos_7","confluent__3_1_2","customer","gold","homeaway","hotels","jdk_1_8","mirrormaker","p2_issue","production","recommendation___best_practices","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_1_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"mirrormaker"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"11691"},{"id":34347728,"value":"1531"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_1_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"mirrormaker"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"11691"},{"id":34347728,"value":"1531"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1861.json","id":1861,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-03T15:11:06Z","updated_at":"2017-07-13T10:45:07Z","type":"incident","subject":"KStream : MultiThreading causes locking directories.","raw_subject":"KStream : MultiThreading causes locking directories.","description":"One of our user's app is on\r\nkafka.version 0.10.2.1-cp1, \r\nconfluent.version 3.2.0 \r\n\r\nI heard that issue of more than one thread causing locking directories is fixed, but our app thows a bunch of errors.\r\n\r\n```2017-06-28T05:03:08,688Z](StreamThread-3)([]) WARN - StreamThread - Could not create task 0_79. Will retry.\r\n! org.apache.kafka.streams.errors.LockException: task [0_79] Failed to lock the state directory for task 0_79\r\n! at org.apache.kafka.streams.processor.internals.ProcessorStateManager.<init>(ProcessorStateManager.java:100)```\r\n\r\nThe only work around at this point is - Moving back to a single thread per instance seems to have fixed it.\r\n\r\nNote: The Kafka Server is on version 3.1.2","priority":null,"status":"open","recipient":null,"requester_id":9125304907,"submitter_id":9125304907,"assignee_id":13678049447,"organization_id":8874211307,"group_id":29623388,"collaborator_ids":[9065547468,6027140346,6031526186],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["_restaurants__leisure","centos_7","confluent__3_1_2","customer","gold","homeaway","hotels","jdk_1_8","jira_escalated","kafka_streams","p3_issue","production","streams_escalated","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_1_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"kafka_streams"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"1731"},{"id":34347728,"value":"586"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_1_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"kafka_streams"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"1731"},{"id":34347728,"value":"586"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1857.json","id":1857,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-01T19:08:28Z","updated_at":"2017-07-15T06:51:27Z","type":"incident","subject":"Kafka outage","raw_subject":"Kafka outage","description":"We have a serious Kafka issue and are unable to understand what the problem is. Our Confluent Control center is no longer responding.","priority":null,"status":"open","recipient":null,"requester_id":5878153046,"submitter_id":5878153046,"assignee_id":13678049447,"organization_id":5719751706,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","confluent__3_2_1","confluent_control_center","europe","gold","jdk_1_8","kai_waehner","p1_issue","production","third_party_software"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":"third_party_software"},{"id":33471847,"value":"p1_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"13765"},{"id":34347728,"value":"151"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":"third_party_software"},{"id":33471847,"value":"p1_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"13765"},{"id":34347728,"value":"151"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1965.json","id":1965,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-13T23:22:15Z","updated_at":"2017-07-14T01:42:39Z","type":"incident","subject":"Custom Connector configuration on Confluent control center","raw_subject":"Custom Connector configuration on Confluent control center","description":"We are trying to use the splunk sink connector https://github.com/jcustenborder/kafka-connect-splunk (developed by Jeremy Custenborder) to be managed by Control Center. Since this is not packaged by Confluent, how do we achieve it? Did not find any article pointing to the steps for the same.","priority":null,"status":"pending","recipient":null,"requester_id":18464926128,"submitter_id":18464926128,"assignee_id":5907439417,"organization_id":14045283907,"group_id":29623388,"collaborator_ids":[18464888008],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["confluent__3_2_1","gold","jdk_1_8","kafka_connect","p3_issue","qa","rhel_7","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"kafka_connect"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"qa"},{"id":77414608,"value":null},{"id":34347708,"value":"73"},{"id":34347728,"value":"73"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"kafka_connect"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"qa"},{"id":77414608,"value":null},{"id":34347708,"value":"73"},{"id":34347728,"value":"73"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1964.json","id":1964,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-13T23:07:04Z","updated_at":"2017-07-15T19:01:04Z","type":"incident","subject":"Messages distribution across different partitions","raw_subject":"Messages distribution across different partitions","description":"Hi,\r\n\r\nHow do we check the load or messages distribution across the different partitions on a single topic?  We have a topic with 4 partitions and sending a unique key along with the messages.  Kafka would then decide on the partition to write to.  (key.hashCode() % numberOfPartitions). \r\n\r\nThanks,\r\nSusan","priority":null,"status":"solved","recipient":null,"requester_id":2373748777,"submitter_id":2373748777,"assignee_id":5907439417,"organization_id":1146899927,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["broker__monitoring","cisco","confluent__2_0_1","jdk_1_7","p3_issue","production","recommendation___best_practices","rhel_6","summarized","support_cust","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__2_0_1"},{"id":26235617,"value":"jdk_1_7"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"broker__monitoring"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"147"},{"id":34347728,"value":"34"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__2_0_1"},{"id":26235617,"value":"jdk_1_7"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"broker__monitoring"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"147"},{"id":34347728,"value":"34"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1962.json","id":1962,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-13T18:17:25Z","updated_at":"2017-07-15T19:01:04Z","type":"incident","subject":"Broker performance degradation","raw_subject":"Broker performance degradation","description":"Messages writing to kafka experienced significant performance degradation. \r\n Looking at all the broker logs and we found the following error on one of the broker (08):\r\n\r\n[2017-07-12 12:15:06,223] ERROR Error while accepting connection (kafka.network.Acceptor)\r\njava.io.IOException: Too many open files\r\n        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)\r\n        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)\r\n        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)\r\n        at kafka.network.Acceptor.accept(SocketServer.scala:319)\r\n        at kafka.network.Acceptor.run(SocketServer.scala:264)\r\n        at java.lang.Thread.run(Thread.java:745)\r\n\r\nWe have since then increase the open filer to 10000 from 1024.  Uploading the server.log files from all broker nodes.  Please let us know if you need other logs in order to root cause this issue.  ","priority":null,"status":"solved","recipient":null,"requester_id":2373748777,"submitter_id":2373748777,"assignee_id":5907439417,"organization_id":1146899927,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["broker","cisco","configuration_issue","confluent__2_0_1","jdk_1_7","p2_issue","production","rhel_6","summarized","support_cust","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__2_0_1"},{"id":26235617,"value":"jdk_1_7"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"broker"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"784"},{"id":34347728,"value":"73"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__2_0_1"},{"id":26235617,"value":"jdk_1_7"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"broker"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"784"},{"id":34347728,"value":"73"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1961.json","id":1961,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-13T16:57:18Z","updated_at":"2017-07-14T20:01:04Z","type":"incident","subject":"Super Users Implementation with auto.create.topic.enable=true","raw_subject":"Super Users Implementation with auto.create.topic.enable=true","description":"Hello,\r\n\r\nI have implemented super users in one of our clusters with auto.create.topic.enable=true config which was in place before adding the super.users config. When one of our clients tried to publish to a non-existing topic over Plaintext Port 9092, basically the topic needs to be created by the cluster and should be able to publish the message right away, but it did throw an authorization exception when they tried. \r\n\r\nHere is the command they tried to use to publish \r\n1. /opt/kafka/bin/kafka-console-producer.sh --broker-list 10.65.133.33:9092 --topic open-test3\r\ntest\r\n[2017-07-13 11:00:04,983] WARN Error while fetching metadata with correlation id 1 : {open-test3=TOPIC_AUTHORIZATION_FAILED} (org.apache.kafka.clients.NetworkClient)\r\n[2017-07-13 11:00:04,984] ERROR Error when sending message to topic open-test3 with key: null, value: 4 bytes with error: (org.apache.kafka.clients.producer.internals.ErrorLoggingCallback)\r\norg.apache.kafka.common.errors.TopicAuthorizationException: Not authorized to access topics: [open-test3]\r\n2. List of Permissions on topic=* level(No permissions added on kafka-cluster level)\r\nCurrent ACLs for resource `Topic:*`:\r\n \tUser:* has Allow permission for operations: Describe from hosts: *\r\n\tUser:* has Allow permission for operations: Read from hosts: *\r\n\tUser:* has Allow permission for operations: Write from hosts: *\r\n\tUser:* has Allow permission for operations: All from hosts: *\r\n\r\nCouple of things we tried to make it work:\r\n1. We added the following permissions and restarted the cluster \r\nCurrent ACLs for resource `Cluster:kafka-cluster`:\r\n \tUser:CN=ttcesvlx1007.target.com,OU=2586396,O=Target Corporation,L=Minneapolis,ST=MN,C=US has Allow permission for operations: Create from hosts: *\r\n\tUser:CN=ttcesvlx1005.target.com,OU=616973,O=Target Corporation,L=Minneapolis,ST=MN,C=US has Allow permission for operations: Create from hosts: *\r\n\tUser:CN=ttcesvlx1006.target.com,OU=616976,O=Target Corporation,L=Minneapolis,ST=MN,C=US has Allow permission for operations: Create from hosts: *\r\nBut, nothing worked out as we have ended up with the same exception.\r\n2. After we added the wide open permissions with create without any cluster restarts, it just worked and able to publish to a non existing topic.\r\nCurrent ACLs for resource `Cluster:kafka-cluster`:\r\n \tUser:CN=ttcesvlx1007.target.com,OU=2586396,O=Target Corporation,L=Minneapolis,ST=MN,C=US has Allow permission for operations: Create from hosts: *\r\n\tUser:CN=ttcesvlx1005.target.com,OU=616973,O=Target Corporation,L=Minneapolis,ST=MN,C=US has Allow permission for operations: Create from hosts: *\r\n\tUser:CN=ttcesvlx1006.target.com,OU=616976,O=Target Corporation,L=Minneapolis,ST=MN,C=US has Allow permission for operations: Create from hosts: *\r\nUser:* has Allow permission for operations: Create from hosts:*\r\n\r\nBasically, we expect super.users to take care of it, if it din't atleast the permissions added with create using broker principals on cluster level should actually handle the metadata with creating the topic by itself but din't work in either of the cases. So, just wanted to understand if it needs wide open permissions for it to work or Is there any further improvements on future release for only brokers to handle the metadata for creating the topics if auto.create.topic.enable is set to true.\r\n\r\nAlso we have a new team member joined our team, so could you please add Josh.Granberry@target.com to access the confluent support url.\r\n\r\nRegards,\r\nSandeep Reddy","priority":null,"status":"solved","recipient":null,"requester_id":1086486587,"submitter_id":1086486587,"assignee_id":5930716698,"organization_id":757015537,"group_id":29623388,"collaborator_ids":[6082672883],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["apache_kafka__0_10_2_1","broker__acls","cc_added_here","configuration_issue","gold","jdk_1_8","multiple","p3_issue","rhel_7","summarized","us_canada"],"custom_fields":[{"id":24843497,"value":"apache_kafka__0_10_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"broker__acls"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"890"},{"id":34347728,"value":"185"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"apache_kafka__0_10_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"broker__acls"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"890"},{"id":34347728,"value":"185"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1960.json","id":1960,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-13T16:46:49Z","updated_at":"2017-07-14T17:01:04Z","type":"incident","subject":"User Account","raw_subject":"User Account","description":"Please create a Support Portal account for Zach Stevens zstevens@yapstone.com ","priority":null,"status":"solved","recipient":null,"requester_id":6071854286,"submitter_id":6071854286,"assignee_id":5907439417,"organization_id":6805216766,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["apache_kafka__0_10_2_1","centos_6","enterprise","general_question__account_admin","gold","hans_jespersen","jdk_1_7","non_technical_request__account_admin","p3_issue","production","summarized","us_canada"],"custom_fields":[{"id":24843497,"value":"apache_kafka__0_10_2_1"},{"id":26235617,"value":"jdk_1_7"},{"id":26235607,"value":"centos_6"},{"id":33020448,"value":"general_question__account_admin"},{"id":47641647,"value":"non_technical_request__account_admin"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"49"},{"id":34347728,"value":"49"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"apache_kafka__0_10_2_1"},{"id":26235617,"value":"jdk_1_7"},{"id":26235607,"value":"centos_6"},{"id":33020448,"value":"general_question__account_admin"},{"id":47641647,"value":"non_technical_request__account_admin"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"49"},{"id":34347728,"value":"49"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1959.json","id":1959,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-13T16:40:50Z","updated_at":"2017-07-14T19:21:52Z","type":"incident","subject":"Schema registry id conflict","raw_subject":"Schema registry id conflict","description":"Hi\r\n\r\nWe have encountered a situation where the schema registry has registered two subjects with the same id.\r\n\r\nhttp://schema-registry.kafkauat.uat.aws.ad.zopa.com:8081/subjects/zopa-origination-quotation-QuotePrimitivesGenerated-by-requestId-value/versions/latest\r\n\r\n{\"subject\":\"zopa-origination-quotation-QuotePrimitivesGenerated-by-requestId-value\",\"version\":1,\"id\":22,\"schema\":\"{\\\"type\\\":\\\"record\\\",\\\"name\\\":\\\"QuotePrimitivesGenerated\\\",\\\"namespace\\\":\\\"com.zopa.events.origination.quotation\\\",\\\"fields\\\":[{\\\"name\\\":\\\"requestId\\\",\\\"type\\\":{\\\"type\\\":\\\"string\\\",\\\"avro.java.string\\\":\\\"String\\\"}},{\\\"name\\\":\\\"applicationId\\\",\\\"type\\\":{\\\"type\\\":\\\"string\\\",\\\"avro.java.string\\\":\\\"String\\\"}},{\\\"name\\\":\\\"primitives\\\",\\\"type\\\":{\\\"type\\\":\\\"array\\\",\\\"items\\\":{\\\"type\\\":\\\"record\\\",\\\"name\\\":\\\"QuotePrimitive\\\",\\\"fields\\\":[{\\\"name\\\":\\\"id\\\",\\\"type\\\":{\\\"type\\\":\\\"string\\\",\\\"avro.java.string\\\":\\\"String\\\"}},{\\\"name\\\":\\\"amount\\\",\\\"type\\\":{\\\"type\\\":\\\"bytes\\\",\\\"logicalType\\\":\\\"decimal\\\",\\\"precision\\\":20,\\\"scale\\\":8}},{\\\"name\\\":\\\"term\\\",\\\"type\\\":\\\"int\\\"},{\\\"name\\\":\\\"isRequestedQuote\\\",\\\"type\\\":\\\"boolean\\\",\\\"default\\\":false}]}}}]}\"}\r\n\r\n\r\nhttp://schema-registry.kafkauat.uat.aws.ad.zopa.com:8081/schemas/ids/22\r\n\r\n{\"schema\":\"{\\\"type\\\":\\\"record\\\",\\\"name\\\":\\\"PaymentPlanCreated\\\",\\\"namespace\\\":\\\"com.zopa.events.loanservicing\\\",\\\"fields\\\":[{\\\"name\\\":\\\"memberId\\\",\\\"type\\\":[\\\"null\\\",\\\"string\\\"],\\\"default\\\":null},{\\\"name\\\":\\\"loanId\\\",\\\"type\\\":[\\\"null\\\",\\\"string\\\"],\\\"default\\\":null},{\\\"name\\\":\\\"planId\\\",\\\"type\\\":[\\\"null\\\",\\\"string\\\"],\\\"default\\\":null},{\\\"name\\\":\\\"createdTime\\\",\\\"type\\\":{\\\"type\\\":\\\"long\\\",\\\"connect.version\\\":1,\\\"connect.name\\\":\\\"org.apache.kafka.connect.data.Timestamp\\\",\\\"logicalType\\\":\\\"timestamp-millis\\\"}}],\\\"connect.name\\\":\\\"com.zopa.events.loanservicing.PaymentPlanCreated\\\"}\"}\r\n\r\nIt is on version:\r\n3.2.0-4\r\n\r\n\r\nMessages produced with the first schema return 22, these are then deserialized with the latter schema.\r\n\r\nHow can we get past this issue and how could it have been caused? Happy to jump on a zoom.\r\n\r\nI have marked as P1 Production as it has halted our Prod go live until it's resolved.\r\n\r\nThanks\r\nAdrian","priority":null,"status":"hold","recipient":null,"requester_id":19548920387,"submitter_id":19548920387,"assignee_id":5907439417,"organization_id":14302137927,"group_id":29623388,"collaborator_ids":[20513997487],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","confluent__3_2_0","europe","jira_escalated","p1_issue","platinum","production","schema_registry"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":""},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"schema_registry"},{"id":47641647,"value":""},{"id":33471847,"value":"p1_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"16565"},{"id":34347728,"value":"592"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":""},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"schema_registry"},{"id":47641647,"value":""},{"id":33471847,"value":"p1_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"16565"},{"id":34347728,"value":"592"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1958.json","id":1958,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-13T14:55:40Z","updated_at":"2017-07-14T12:45:40Z","type":"incident","subject":"Kakfa Streams message headers bug","raw_subject":"Kakfa Streams message headers bug","description":"Hi,\r\n\r\nWe're trying to use the new message headers functionality introduced in Kafka 0.11.0.0 (https://cwiki.apache.org/confluence/display/KAFKA/KIP-82+-+Add+Record+Headers) in our Kafka Streams applications, but we're noticing that if we set headers on the ProducerRecords that are sent into the input topics of the topology that they don't come out the other side of the topology. I stepped through a topology in the debugger and believe it's at least partially due to the SourceNodeRecordDeserializer not properly respecting message headers here:\r\n\r\nhttps://github.com/apache/kafka/blob/trunk/streams/src/main/java/org/apache/kafka/streams/processor/internals/SourceNodeRecordDeserializer.java#L60\r\n\r\nwhere it isn't using the ConsumerRecord constructor which supports headers:\r\n\r\nhttps://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerRecord.java#L122\r\n\r\nFor additional background here is the line before which we noticed that we still have the message headers, and after which we no longer have them:\r\n\r\nhttps://github.com/apache/kafka/blob/trunk/streams/src/main/java/org/apache/kafka/streams/processor/internals/RecordQueue.java#L93\r\n\r\n(Also please note that again this is with Kafka 0.11.0.0, the support page does not yet have 0.11.0.0 as an option in the \"Confluent/Kafka Version dropdown menu\")\r\n\r\nThanks.\r\nCJ\r\n","priority":null,"status":"hold","recipient":null,"requester_id":14655136168,"submitter_id":14655136168,"assignee_id":5930716698,"organization_id":10885029188,"group_id":29623388,"collaborator_ids":[21095585667,5711588123,16249212348],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["apache_kafka__0_11_0_0","debian_7","development","gold","jdk_1_8","jira_escalated","kafka_streams","p3_issue","streams_escalated","us_canada"],"custom_fields":[{"id":24843497,"value":"apache_kafka__0_11_0_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"debian_7"},{"id":33020448,"value":"kafka_streams"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"1233"},{"id":34347728,"value":"50"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"apache_kafka__0_11_0_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"debian_7"},{"id":33020448,"value":"kafka_streams"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"1233"},{"id":34347728,"value":"50"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1957.json","id":1957,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-13T14:52:49Z","updated_at":"2017-07-14T15:18:03Z","type":"incident","subject":"Streams Application Doesn't Recover After Network Exception","raw_subject":"Streams Application Doesn't Recover After Network Exception","description":"Streams application had to be terminated to get back online after an unknown network exception.\r\n\r\n2017-07-13 05:19:09.488 [WARN] [kafka-producer-network-thread | stream-lsa-verificationV2-7c335cd1-c940-4ec7-8fb7-812bd968b497-StreamThread-8-producer] [o.a.k.c.p.i.Sender] - Got error produce response with correlation id 935818 on topic-partition stream-lsa-verificationV2-PsnSessionsStore-changelog-2, retrying (9 attempts left). Error: NETWORK_EXCEPTION\r\n2017-07-13 05:19:09.488 [WARN] [kafka-producer-network-thread | stream-lsa-verificationV2-7c335cd1-c940-4ec7-8fb7-812bd968b497-StreamThread-8-producer] [o.a.k.c.p.i.Sender] - Got error produce response with correlation id 935818 on topic-partition stream-lsa-verificationV2-KSTREAM-MAP-0000000004-repartition-2, retrying (9 attempts left). Error: NETWORK_EXCEPTION\r\n2017-07-13 05:19:09.488 [WARN] [kafka-producer-network-thread | stream-lsa-verificationV2-7c335cd1-c940-4ec7-8fb7-812bd968b497-StreamThread-8-producer] [o.a.k.c.p.i.Sender] - Got error produce response with correlation id 935817 on topic-partition stream-lsa-verificationV2-PsnSessionsStore-changelog-2, retrying (9 attempts left). Error: NETWORK_EXCEPTION\r\n2017-07-13 05:19:09.489 [WARN] [kafka-producer-network-thread | stream-lsa-verificationV2-7c335cd1-c940-4ec7-8fb7-812bd968b497-StreamThread-8-producer] [o.a.k.c.p.i.Sender] - Got error produce response with correlation id 935817 on topic-partition stream-lsa-verificationV2-KSTREAM-MAP-0000000004-repartition-2, retrying (9 attempts left). Error: NETWORK_EXCEPTION\r\n2017-07-13 05:19:09.489 [WARN] [kafka-producer-network-thread | stream-lsa-verificationV2-7c335cd1-c940-4ec7-8fb7-812bd968b497-StreamThread-8-producer] [o.a.k.c.p.i.Sender] - Got error produce response with correlation id 935816 on topic-partition stream-lsa-verificationV2-PsnSessionsStore-changelog-2, retrying (9 attempts left). Error: NETWORK_EXCEPTION\r\n2017-07-13 05:19:09.489 [WARN] [kafka-producer-network-thread | stream-lsa-verificationV2-7c335cd1-c940-4ec7-8fb7-812bd968b497-StreamThread-8-producer] [o.a.k.c.p.i.Sender] - Got error produce response with correlation id 935816 on topic-partition stream-lsa-verificationV2-KSTREAM-MAP-0000000004-repartition-2, retrying (9 attempts left). Error: NETWORK_EXCEPTION\r\n2017-07-13 05:19:09.489 [WARN] [kafka-producer-network-thread | stream-lsa-verificationV2-7c335cd1-c940-4ec7-8fb7-812bd968b497-StreamThread-8-producer] [o.a.k.c.p.i.Sender] - Got error produce response with correlation id 935815 on topic-partition stream-lsa-verificationV2-PsnSessionsStore-changelog-2, retrying (9 attempts left). Error: NETWORK_EXCEPTION\r\n2017-07-13 05:19:09.489 [WARN] [kafka-producer-network-thread | stream-lsa-verificationV2-7c335cd1-c940-4ec7-8fb7-812bd968b497-StreamThread-8-producer] [o.a.k.c.p.i.Sender] - Got error produce response with correlation id 935815 on topic-partition stream-lsa-verificationV2-KSTREAM-MAP-0000000004-repartition-2, retrying (9 attempts left). Error: NETWORK_EXCEPTION\r\n2017-07-13 05:19:09.489 [WARN] [kafka-producer-network-thread | stream-lsa-verificationV2-7c335cd1-c940-4ec7-8fb7-812bd968b497-StreamThread-8-producer] [o.a.k.c.p.i.Sender] - Got error produce response with correlation id 935814 on topic-partition stream-lsa-verificationV2-PsnSessionsStore-changelog-2, retrying (9 attempts left). Error: NETWORK_EXCEPTION\r\n2017-07-13 05:19:09.489 [WARN] [kafka-producer-network-thread | stream-lsa-verificationV2-7c335cd1-c940-4ec7-8fb7-812bd968b497-StreamThread-8-producer] [o.a.k.c.p.i.Sender] - Got error produce response with correlation id 935814 on topic-partition stream-lsa-verificationV2-KSTREAM-MAP-0000000004-repartition-2, retrying (9 attempts left). Error: NETWORK_EXCEPTION\r\n\r\nStreaming application logs attached.\r\n\r\nThis ticket includes a secure attachment. Use this link to access the attached files:\r\n https://confluent.sendsafely.com/receive/?thread=VLGW-2E72&packageCode=82XqmrXAJC8QvlwlZAphky09uJkGdpDYO3uimIE63Bw#keyCode=K3mxG5jGDYywASIES-zj3Tc25OwY0r6IoVtzPgc5JLU","priority":null,"status":"hold","recipient":null,"requester_id":16333291488,"submitter_id":16333291488,"assignee_id":5907439417,"organization_id":14093709488,"group_id":29623388,"collaborator_ids":[21071077408],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","confluent__3_2_1","gold","jdk_1_8","jira_escalated","kafka_streams","p2_issue","production","streams_escalated","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"kafka_streams"},{"id":47641647,"value":""},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"4562"},{"id":34347728,"value":"6"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"kafka_streams"},{"id":47641647,"value":""},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"4562"},{"id":34347728,"value":"6"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1956.json","id":1956,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-13T14:00:17Z","updated_at":"2017-07-15T17:01:04Z","type":"incident","subject":"Unable to fetch the consumer group list","raw_subject":"Unable to fetch the consumer group list","description":"We have Replicators set up and they are up and running. However, when trying to get the consumer group list, we are unable to. Using the below command to get the group list. \r\n\r\ndocker run --rm -ti --net=host confluentinc/cp-enterprise-kafka kafka-consumer-groups --list --bootstrap-server <KAFKA_HOSTS>\r\n\r\nAttaching the connector logs as well. Please let me know if any more information required. \r\n","priority":null,"status":"solved","recipient":null,"requester_id":5992054266,"submitter_id":5992054266,"assignee_id":5930716698,"organization_id":6232563146,"group_id":29623388,"collaborator_ids":[6088173626,5992038406],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","chris_matta","confluent__3_2_2","enterprise","gold","jdk_1_8","p3_issue","qa","recommendation___best_practices","replicator","summarized","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"replicator"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"qa"},{"id":77414608,"value":null},{"id":34347708,"value":"1457"},{"id":34347728,"value":"39"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"replicator"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"qa"},{"id":77414608,"value":null},{"id":34347708,"value":"1457"},{"id":34347728,"value":"39"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1955.json","id":1955,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-13T13:42:12Z","updated_at":"2017-07-14T19:45:43Z","type":"incident","subject":"Timeout Exceptions in Control center logs","raw_subject":"Timeout Exceptions in Control center logs","description":"We are seeing time out exceptions as specified below. Can you please let me know why C3 throwing these exceptions ?\r\n\r\n\r\nException :\r\n\r\nCaused by: org.apache.kafka.common.errors.TimeoutException: Expiring 2 record(s) for _confluent-monitoring-2: 30016 ms has passed since batch creation plus linger time\r\n[2017-07-13 07:46:03,162] DEBUG Scavenging sessions at 1499931963162 (org.eclipse.jetty.server.session:347)\r\n[2017-07-13 07:46:07,035] WARN failed to publish monitoring heartbeat message (io.confluent.controlcenter.streams.verify.MonitoringHeartbeatSender:106)\r\njava.util.concurrent.TimeoutException: Timeout after waiting for 14971 ms.\r\n        at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:64)\r\n        at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:25)\r\n        at io.confluent.controlcenter.streams.verify.MonitoringHeartbeatSender.sendHeartbeat(MonitoringHeartbeatSender.java:103)\r\n        at io.confluent.controlcenter.streams.verify.MonitoringHeartbeatSender.run(MonitoringHeartbeatSender.java:67)\r\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\r\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\r\n        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n        at java.lang.Thread.run(Thread.java:745)","priority":null,"status":"pending","recipient":null,"requester_id":18368692907,"submitter_id":18368692907,"assignee_id":5907439417,"organization_id":14045283907,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_6","confluent__3_2_2","confluent_control_center","gold","jdk_1_8","p3_issue","staging","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_6"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"staging"},{"id":77414608,"value":null},{"id":34347708,"value":"1178"},{"id":34347728,"value":"30"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_6"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"staging"},{"id":77414608,"value":null},{"id":34347708,"value":"1178"},{"id":34347728,"value":"30"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1954.json","id":1954,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-13T00:08:51Z","updated_at":"2017-07-13T09:29:40Z","type":"incident","subject":"0.10 Upgrade related questions","raw_subject":"0.10 Upgrade related questions","description":"Hi We are going to upgrade the message formats to 0.10 on brokers that we have already upgraded to 0.10 binaries. We have some questions that we would like to clarify.\r\n1. In our testing we have seen that even if the log.message.format.version is 0.10.2.0, the messages sent from the older clients are still stored in old format (timestamp field is missing.). Only when 0.10 producers produce the message and the format is 0.10 will the message be stored in 0.10 format with timestamp. We were told that 0.10 brokers will add a timestamp and store it as 0.10 format message even if t comes from an older client if the format version is set to 0.10. Is there a way to store messages in 0.10 format when produced from an older client?\r\n\r\n2. We also noticed that replicas always copy the message in the same format as it is on the leader. There is no conversion of formats during the replication. Is there a way to do this..for ex,. a broker with 0.9 format can replicate from 0.10 format \r\nbroker and save in 0.9 format?\r\n\r\n3. We'll only upgrade few brokers to start with. If something goes wrong on those few brokers how can we keep the cluster running fine. Even if we take the brokers out of the traffic their replicas may be on other brokers and in 0.10 format which can cause issues to the older clients. How will we handle this situation.\r\n\r\n","priority":null,"status":"pending","recipient":null,"requester_id":16162878107,"submitter_id":16162878107,"assignee_id":5699232346,"organization_id":14010977147,"group_id":29623388,"collaborator_ids":[16233911168,16260667548],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["apache_kafka__0_10_2_0","gold","jdk_1_8","p3_issue","production","rhel_6","us_canada"],"custom_fields":[{"id":24843497,"value":"apache_kafka__0_10_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":""},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"3609"},{"id":34347728,"value":"208"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"apache_kafka__0_10_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":""},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"3609"},{"id":34347728,"value":"208"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1952.json","id":1952,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-12T22:55:30Z","updated_at":"2017-07-14T09:08:00Z","type":"incident","subject":"Access to support portal for colleagues","raw_subject":"Access to support portal for colleagues","description":"Would it be possible to get an access into this portal for following people?\r\nellie.norris@merck.com\r\nryan_gerlach@merck.com\r\nadam.sotona@merck.com\r\nrandy.qin@merck.com\r\nalexander_shusterman@merck.com","priority":null,"status":"solved","recipient":null,"requester_id":17065697347,"submitter_id":17065697347,"assignee_id":5699232346,"organization_id":14111291808,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["confluent__3_2_1","europe","general_question__account_admin","jdk_1_8","multiple","non_technical_request__account_admin","p3_issue","ubuntu_14_04_lts"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"ubuntu_14_04_lts"},{"id":33020448,"value":"general_question__account_admin"},{"id":47641647,"value":"non_technical_request__account_admin"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"821"},{"id":34347728,"value":"34"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"good","id":1750402686,"comment":null,"reason":"No reason provided","reason_id":332227},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"ubuntu_14_04_lts"},{"id":33020448,"value":"general_question__account_admin"},{"id":47641647,"value":"non_technical_request__account_admin"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"821"},{"id":34347728,"value":"34"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1949.json","id":1949,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-12T20:47:32Z","updated_at":"2017-07-12T21:33:39Z","type":"incident","subject":"Upgrade steps from 3.2.1 to 3.2.2","raw_subject":"Upgrade steps from 3.2.1 to 3.2.2","description":"could you send any upgrade process for our environment from 3.2.1 to 3.2.2.\r\n\r\nWe actually interested in s3 connect flush interval feature. Is there a way just to upgrade connect nodes and leave the rest of the components with 3.2.1. This feature is needed for current application and hence looking for quick turnaround. Let us know","priority":null,"status":"pending","recipient":null,"requester_id":5766348623,"submitter_id":5766348623,"assignee_id":13678049447,"organization_id":5273937083,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["broker__tools_scripts","confluent__3_2_1","gold","jdk_1_8","jeremy_custenborder","multiple","p3_issue","rhel_7","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"broker__tools_scripts"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"191"},{"id":34347728,"value":"24"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"broker__tools_scripts"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"191"},{"id":34347728,"value":"24"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1948.json","id":1948,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-12T20:33:49Z","updated_at":"2017-07-13T22:01:03Z","type":"incident","subject":"Kafka 0.11.0.0 Docker images","raw_subject":"Kafka 0.11.0.0 Docker images","description":"Hi,\r\n\r\nWe are currently evaluating some new functionality introduced as part of the recent Kafka 0.11.0.0 release, and noticed that there does not appear to be a matching Confluent release (that we could see, I'm assuming that will be 3.3?). We were wondering when 3.3 was planned to be released.\r\n\r\nThank you.\r\nCJ","priority":null,"status":"solved","recipient":null,"requester_id":14655136168,"submitter_id":14655136168,"assignee_id":5699232346,"organization_id":10885029188,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["confluent__3_2_2","debian_7","development","general_question","gold","jdk_1_8","non_technical_request","p3_issue","summarized","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"debian_7"},{"id":33020448,"value":"general_question"},{"id":47641647,"value":"non_technical_request"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"733"},{"id":34347728,"value":"182"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"debian_7"},{"id":33020448,"value":"general_question"},{"id":47641647,"value":"non_technical_request"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"733"},{"id":34347728,"value":"182"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1947.json","id":1947,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-12T18:58:26Z","updated_at":"2017-07-14T17:01:04Z","type":"incident","subject":"Kafka-S3 connector flush ","raw_subject":"Kafka-S3 connector flush ","description":"With reference to ticket Request #1615, do we now have 'rotate.interval.ms' property available for kafka-s3 connector with 3.2.2 release?","priority":null,"status":"solved","recipient":null,"requester_id":5796235823,"submitter_id":5796235823,"assignee_id":21324568227,"organization_id":5273937083,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["confluent__3_2_2","development","gold","jdk_1_8","jeremy_custenborder","kafka_connect__s3_connector","non_technical_request__roadmap_request","p3_issue","summarized","ubuntu_16_04_lts","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"ubuntu_16_04_lts"},{"id":33020448,"value":"kafka_connect__s3_connector"},{"id":47641647,"value":"non_technical_request__roadmap_request"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"1715"},{"id":34347728,"value":"17"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"ubuntu_16_04_lts"},{"id":33020448,"value":"kafka_connect__s3_connector"},{"id":47641647,"value":"non_technical_request__roadmap_request"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"1715"},{"id":34347728,"value":"17"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1945.json","id":1945,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-12T16:21:01Z","updated_at":"2017-07-14T15:03:37Z","type":"incident","subject":"The User / Pass are in Plain Text in Kafka connectors","raw_subject":"The User / Pass are in Plain Text in Kafka connectors","description":"The User / Pass are in Plain Text in Kafka connectors. And the logs show this User / Pass information. This is a big NO NO from our Cyber Security team.\r\n\r\nJust wondering, are there any options to hide the User  / Pass both in the connectors and in the logs ?\r\n\r\nThanks-\r\nSiva Nagisetty.","priority":null,"status":"solved","recipient":null,"requester_id":5991633766,"submitter_id":5991633766,"assignee_id":5907439417,"organization_id":6328931306,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","configuration_issue","confluent__3_2_1","enterprise","gold","jdbc_connector","jdk_1_8","jeremy_custenborder","p3_issue","production","summarized","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"jdbc_connector"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"1540"},{"id":34347728,"value":"100"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"good","id":1751268926,"comment":null,"reason":"No reason provided","reason_id":332227},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"jdbc_connector"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"1540"},{"id":34347728,"value":"100"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1943.json","id":1943,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-12T10:06:42Z","updated_at":"2017-07-13T14:16:48Z","type":"incident","subject":"How to set 'acks' values on REST Proxy Producer API","raw_subject":"How to set 'acks' values on REST Proxy Producer API","description":"We have an requirement to set 'acks' producer property through Kafka REST Producer API (same as kafka native producer client). This acks property should override the 'acks' settings configured at kafka rest proxy configuration .\r\n\r\nCan you please let me know respective Rest Proxy API Producer config parameter.\r\n\r\n\r\nRegards\r\nMahesh","priority":null,"status":"pending","recipient":null,"requester_id":18368692907,"submitter_id":18368692907,"assignee_id":5907439417,"organization_id":14045283907,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_6","confluent__3_2_1","gold","jdk_1_8","p3_issue","recommendation___best_practices","rest_proxy","staging","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_6"},{"id":33020448,"value":"rest_proxy"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"staging"},{"id":77414608,"value":null},{"id":34347708,"value":"692"},{"id":34347728,"value":"268"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_6"},{"id":33020448,"value":"rest_proxy"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"staging"},{"id":77414608,"value":null},{"id":34347708,"value":"692"},{"id":34347728,"value":"268"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1941.json","id":1941,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-12T01:46:50Z","updated_at":"2017-07-13T16:51:34Z","type":"incident","subject":"Error recreating topic, Leader not assigned","raw_subject":"Error recreating topic, Leader not assigned","description":"Hi,\r\n\r\nSince we are not able to produce to a topic cdh.confdba.holding_trans_activity.fcr we did force delete (from zk and commit logs) and recreated it even then we dont see Leader assigned to this topic, can you please tell us how we can proceed?\r\n\r\nslckafkacdh01a:~/kafka_2.10-0.10.2.0/bin$ ./kafka-topics.sh --desc --zookeeper 10.76.140.32:2181 --topic cdh.confdba.holding_trans_activity.fcr\r\nTopic:cdh.confdba.holding_trans_activity.fcr\tPartitionCount:1\tReplicationFactor:3\tConfigs:retention.ms=86400000\r\n\tTopic: cdh.confdba.holding_trans_activity.fcr\tPartition: 0\tLeader: none\tReplicas: 11,10,0\tIsr: \r\n\r\n","priority":null,"status":"solved","recipient":null,"requester_id":16162852587,"submitter_id":16162852587,"assignee_id":21324568227,"organization_id":14010977147,"group_id":29623388,"collaborator_ids":[16162878107,16233911168,16260667548],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["apache_kafka__0_10_2_0","broker","configuration_issue","gold","jdk_1_8","p1_issue","production","rhel_6","summarized","us_canada"],"custom_fields":[{"id":24843497,"value":"apache_kafka__0_10_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"broker"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p1_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"5473"},{"id":34347728,"value":"44"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"good","id":1739825063,"comment":null,"reason":"No reason provided","reason_id":332227},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"apache_kafka__0_10_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"broker"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p1_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"5473"},{"id":34347728,"value":"44"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1940.json","id":1940,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-11T23:52:01Z","updated_at":"2017-07-12T00:04:00Z","type":"incident","subject":"Is it possible to Enable the Replicator in the live clusters","raw_subject":"Is it possible to Enable the Replicator in the live clusters","description":"Hi Team\r\n\r\nI am planning build the Kafka cluster without Replicator now. Is it possible to enable the replicator(if I want) later (after live) without any disturbance/outage?\r\n\r\nIf there is an outage or downtime required, how much time we need to bring the service down for 5 ZK / 5 Broker Cluster?\r\n\r\nThanks\r\nSankara","priority":null,"status":"pending","recipient":null,"requester_id":15953327587,"submitter_id":15953327587,"assignee_id":13678049447,"organization_id":1853286568,"group_id":29623388,"collaborator_ids":[3661547758,22085958348,22085978368],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["confluent__3_2_1","development","gold","jdk_1_7","jeremy_custenborder","p3_issue","replicator","rhel_7","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_7"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"replicator"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"437"},{"id":34347728,"value":"409"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_7"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"replicator"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"437"},{"id":34347728,"value":"409"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1937.json","id":1937,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-11T21:06:12Z","updated_at":"2017-07-14T01:40:51Z","type":"incident","subject":"C3 went  down with Failed while executing StreamTask 7_3 due to flush state error","raw_subject":"C3 went  down with Failed while executing StreamTask 7_3 due to flush state error","description":"We installed C3 y'day with Hans's help for our production 6 node kafka cluster, it was running fine for around 24 hours.\r\nToday it went down errors related to statestore, can you please take look attached shutdown log, c3 is not  reporting correct data, also it goes down after few minutes.\r\n\r\nThis ticket includes a secure attachment. Use this link to access the attached files:\r\n https://confluent.sendsafely.com/receive/?thread=18TS-GPCS&packageCode=fivjun295yQCxnGvBfeaLGKr17cuIt3AmF6gGJwbRHE#keyCode=E_mQHa808Dy2koGbJ9qMAK0ZfrpU_iE28zTe4-Ag2SI","priority":null,"status":"pending","recipient":null,"requester_id":6056401923,"submitter_id":6056401923,"assignee_id":5907439417,"organization_id":6805216766,"group_id":29623388,"collaborator_ids":[13186800408,19850841687,5907439417,21324568227],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_6","confluent__3_2_2","confluent_control_center","enterprise","gold","hans_jespersen","jdk_1_8","jira_escalated","p1_issue","production","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_6"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":""},{"id":33471847,"value":"p1_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"16418"},{"id":34347728,"value":"4"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_6"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":""},{"id":33471847,"value":"p1_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"16418"},{"id":34347728,"value":"4"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1935.json","id":1935,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-11T14:40:37Z","updated_at":"2017-07-13T08:01:02Z","type":"incident","subject":"Recreating sink connector","raw_subject":"Recreating sink connector","description":"Dear support,\r\n\r\nWe are using the S3SinkConnector to save messages to S3. \r\n\r\nDuring development we need to recreate our sink connectors because of changes in configuration or tranformers. In such cases we would like to start processing the messages from the beginning. \r\n\r\nWe tried deleting and recreating the connector using the REST API, but if we use the same connector name, the new connector will still continue the processing from the last processed message.\r\n\r\nIs there a possibility to tell the newly created sink connector to start processing the messages from the beginning? We tried adding the \"consumer.auto.offset.reset\": \"earliest\" setting to the config, but it did not help. I attached the REST API call we execute.\r\n\r\nDo you have any suggestion?\r\n\r\nThanks,\r\nAttila\r\n\r\nThis ticket includes a secure attachment. Use this link to access the attached files:\r\n https://confluent.sendsafely.com/receive/?thread=Y44L-366K&packageCode=NFORdo4QHxzHy3U7lCi5KAtTqeTjLUSOAbm5FVS4x5Q#keyCode=ZDPEqDUJnsnWGnfGINndlvXNz-WHxDMVEBKCq9tP5Ds","priority":null,"status":"solved","recipient":null,"requester_id":5958117683,"submitter_id":5958117683,"assignee_id":5930716698,"organization_id":6138039563,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["confluent__3_2_2","development","jdk_1_8","kafka_connect__s3_connector","p3_issue","recommendation___best_practices","summarized","ubuntu_16_04_lts"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"ubuntu_16_04_lts"},{"id":33020448,"value":"kafka_connect__s3_connector"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"3989"},{"id":34347728,"value":"17"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"ubuntu_16_04_lts"},{"id":33020448,"value":"kafka_connect__s3_connector"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"3989"},{"id":34347728,"value":"17"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1931.json","id":1931,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-11T08:19:54Z","updated_at":"2017-07-13T13:59:08Z","type":"incident","subject":"Confluent Control Center crash Kafka cluster","raw_subject":"Confluent Control Center crash Kafka cluster","description":"Hi,\r\nwe have two Problem with Confluent Control Center:\r\na) It produces a lot of log output which rapidly fills up our disks\r\nb) It store huge amount of data into Kafka topics which crashed the cluster\r\n\r\nPlease get in Contact with Sebastian Jackel <sebastian.jackel@codecentric.de>, he can provide more details.","priority":null,"status":"pending","recipient":null,"requester_id":21511830228,"submitter_id":21511830228,"assignee_id":5930716698,"organization_id":16373013568,"group_id":29623388,"collaborator_ids":[21436518967,6067595446,6067597106],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","configuration_issue","confluent__3_2_2","confluent_control_center","europe","jdk_1_8","p2_issue","production","silver"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"7852"},{"id":34347728,"value":"172"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"7852"},{"id":34347728,"value":"172"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1930.json","id":1930,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-11T01:29:51Z","updated_at":"2017-07-13T21:01:04Z","type":"incident","subject":"encryption on wire and rest","raw_subject":"encryption on wire and rest","description":"We are looking for ways to encrypt data on wire as well as at rest because of security requirements. Its ideal to do SSL on top of kerberos for wire encryption but it doesn't solve at-rest encryption issue. Do you support any kafka client level encryption and decryption for ease of use without SSL Certificates?  ","priority":null,"status":"solved","recipient":null,"requester_id":5766348623,"submitter_id":5766348623,"assignee_id":21324568227,"organization_id":5273937083,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["confluent__3_2_1","gold","jdk_1_8","jeremy_custenborder","multiple","p4_issue","recommendation___best_practices","rhel_7","security","summarized","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"security"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p4_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"1069"},{"id":34347728,"value":"44"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"security"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p4_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"1069"},{"id":34347728,"value":"44"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1928.json","id":1928,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-10T23:02:08Z","updated_at":"2017-07-12T17:56:44Z","type":"incident","subject":"high replica fetch request rates in production cluster","raw_subject":"high replica fetch request rates in production cluster","description":"Hi Sachin,\n\nI spoke with Hans and he mentioned that you have an issue that our support team needs to take a look at.  I'm opening this ticket so we can pick up the conversation here.  \n\nBest,\nSam","priority":null,"status":"pending","recipient":null,"requester_id":6056401923,"submitter_id":3324019678,"assignee_id":5699232346,"organization_id":6805216766,"group_id":29623388,"collaborator_ids":[3324019678,8327796688],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["consumer","development","p2_issue"],"custom_fields":[{"id":24843497,"value":""},{"id":26235617,"value":""},{"id":26235607,"value":""},{"id":33020448,"value":"consumer"},{"id":47641647,"value":""},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"7074"},{"id":34347728,"value":"231"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":""},{"id":26235617,"value":""},{"id":26235607,"value":""},{"id":33020448,"value":"consumer"},{"id":47641647,"value":""},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"7074"},{"id":34347728,"value":"231"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1922.json","id":1922,"external_id":null,"via":{"channel":"email","source":{"from":{"address":"shaun.x.wanford@kp.org","name":"Shaun X. Wanford"},"to":{"name":"Confluent","address":"support@confluent.io"},"rel":null}},"created_at":"2017-07-10T19:00:39Z","updated_at":"2017-07-15T15:01:01Z","type":"incident","subject":"Tried it - RE: One question though - RE: FW: I was sketching out the Kafka/Confluent Stack","raw_subject":"Tried it - RE: One question though - RE: FW: I was sketching out the Kafka/Confluent Stack","description":"Hey dude, can you help me make a support ticket for Kaiser for the below?\n\n\n---------- Forwarded message ---------\nFrom: Alex Loddengaard <alex@confluent.io>\nDate: Mon, Jul 10, 2017 at 12:54 PM\nSubject: Re: Tried it - RE: One question though - RE: FW: I was sketching out the Kafka/Confluent Stack\nTo: Shaun X. Wanford <Shaun.X.Wanford@kp.org>\n\n\nI'm with a customer today and tomorrow (lunch break now). But I'll forward this to Sam. He can do it. Stay tuned\n\nOn Mon, Jul 10, 2017 at 12:53 PM Shaun X. Wanford <Shaun.X.Wanford@kp.org> wrote:\n\nHey Alex, if it’s easy for you could you do it? Thanks!\n\n \n\n \n\n---------------------------------------------------------------------------------\n\nShaun Wanford\n\nIntegration Architect, EIS Innovation and Product Management \nLake Oswego, OR\n503-309-8849\n\nshaun.x.wanford@kp.org\n\n \n\nFrom: Alex Loddengaard [mailto:alex@confluent.io]\nSent: Monday, July 10, 2017 11:48 AM\n\n\nTo: Shaun X. Wanford <Shaun.X.Wanford@kp.org>\n\nCc: Dennis T. Siao <Dennis.T.Siao@kp.org>\nSubject: Re: Tried it - RE: One question though - RE: FW: I was sketching out the Kafka/Confluent Stack\n\n \n\nThat sounds good. Do you want me to open the ticket for you or can you open it? Let me know what's best, and thanks for your patience\n\nOn Mon, Jul 10, 2017 at 9:36 AM Shaun X. Wanford <Shaun.X.Wanford@kp.org> wrote:\n\nHey Alex!\n\n \n\nMaybe we should transition this to a Support Ticket? Then we can track it and the supporting Jetty Documentation.\n\n \n\nThanks!\n\n \n\nShaun.\n\n \n\n \n\n---------------------------------------------------------------------------------\n\nShaun Wanford\n\nIntegration Architect, EIS Innovation and Product Management \nLake Oswego, OR\n503-309-8849\n\nshaun.x.wanford@kp.org\n\n \n\nFrom: Alex Loddengaard [mailto:alex@confluent.io]\nSent: Friday, July 07, 2017 5:03 PM\n\n\nTo: Shaun X. Wanford <Shaun.X.Wanford@kp.org>\nCc: Dennis T. Siao <Dennis.T.Siao@kp.org>\n\nSubject: Re: Tried it - RE: One question though - RE: FW: I was sketching out the Kafka/Confluent Stack\n\n \n\nHi Shaun,\n\n \n\nSorry for my delay. I've been with a customer this week. I'm with one next week, too, so I won't have a chance to look at this unfortunately.\n\n \n\nMoving forward, do you want me to transition this challenge to a support ticket so they can help? Or would you rather we dive into this during an office hours session?\n\n \n\nLet me know what's best. Thanks for your patience. And have a nice weekend.\n\n \n\nAlex\n\n \n\nOn Thu, Jul 6, 2017 at 10:03 AM, Shaun X. Wanford <Shaun.X.Wanford@kp.org> wrote:\n\nHey Alex, it looks like the documentation changed.\n\n \n\nhttps://github.com/rundeck/rundeck/issues/1222\n\n \n\n \n\nThis works for the password obfuscation\n\n \n\nC:\\eis>java -cp jetty-http-9.2.12.v20150709.jar;jetty-util-9.2.12.v20150709.jar org.eclipse.jetty.util.security.Password me blah\n\n2017-07-06 09:24:45.837:INFO::main: Logging initialized @123ms\n\nblah\n\nOBF:1t2x1toq1to41t39\n\nMD5:6f1ed002ab5595859014ebf0951522d9\n\nCRYPT:me/DjMjPzbKG.\n\n \n\nSo I tried it with the service account we have for LDAP. I’m hiding the real values ;-)\n\n \n\n  bindDn=\"xxx\"\n\n  bindPassword=\"yyy\"\n\n \n\nC:\\eis>java -cp jetty-http-9.2.12.v20150709.jar;jetty-util-9.2.12.v20150709.jar org.eclipse.jetty.util.security.Password xxx yyy\n\n2017-07-06 09:57:25.813:INFO::main: Logging initialized @128ms\n\nyyy\n\nOBF:20zj20zj20zj\n\nMD5:f0a4058fd33489695d53df156b77c724\n\nCRYPT:xxJykgWx5uWZM\n\n \n\nGives us this\n\n \n\nc3 {\n\norg.eclipse.jetty.jaas.spi.LdapLoginModule required\n\n   debug=\"true\"\n\n   useLdaps=\"false\"\n\n   contextFactory=\"com.sun.jndi.ldap.LdapCtxFactory\"\n\n   hostname=\"CS.MSDS.KP.ORG\"\n\n   port=\"389\"\n\n   bindDn=\"xxx\"\n\n   bindPassword=\"CRYPT:xxJykgWx5uWZM\n\n   authenticationMethod=\"simple\"\n\n   forceBindingLogin=\"true\"\n\n   userBaseDn=\"DC=cs,DC=msds,DC=kp,DC=org\"\n\n   userRdnAttribute=\"sAMAccountName\"\n\n   userIdAttribute=\"sAMAccountName\"\n\n   userPasswordAttribute=\"userPassword\"\n\n   userObjectClass=\"user\"\n\n   roleBaseDn=\"ou=Groups,DC=cs,DC=msds,DC=kp,DC=org\"\n\n   roleNameAttribute=\"cn\"\n\n   roleMemberAttribute=\"member\"\n\n   roleObjectClass=\"group\";\n\n \n\n};\n\n \n\nIf I fire everything up, and try and login into to CCC that fails. I’m guessing it’s not decrypting the bindpassword ?\n\n \n\n[2017-07-06 09:53:19,950] WARN  (org.eclipse.jetty.jaas.JAASLoginService:251)\n\njavax.security.auth.login.LoginException: java.lang.IllegalStateException: Unabl\n\ne to establish root context\n\n        at org.eclipse.jetty.jaas.spi.LdapLoginModule.initialize(LdapLoginModule\n\n.java:577)\n\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.\n\njava:62)\n\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAcces\n\nsorImpl.java:43)\n\n        at java.lang.reflect.Method.invoke(Method.java:498)\n\n        at javax.security.auth.login.LoginContext.invoke(LoginContext.java:736)\n\n        at javax.security.auth.login.LoginContext.access$000(LoginContext.java:1\n\n95)\n\n        at javax.security.auth.login.LoginContext$4.run(LoginContext.java:682)\n\n        at javax.security.auth.login.LoginContext$4.run(LoginContext.java:680)\n\n        at java.security.AccessController.doPrivileged(Native Method)\n\n        at javax.security.auth.login.LoginContext.invokePriv(LoginContext.java:6\n\n80)\n\n        at javax.security.auth.login.LoginContext.login(LoginContext.java:587)\n\n        at org.eclipse.jetty.jaas.JAASLoginService.login(JAASLoginService.java:2\n\n41)\n\n \n\n---------------------------------------------------------------------------------\n\nShaun Wanford\n\nIntegration Architect, EIS Innovation and Product Management \nLake Oswego, OR\n503-309-8849\n\nshaun.x.wanford@kp.org\n\n \n\nFrom: Shaun X. Wanford\nSent: Thursday, July 06, 2017 8:43 AM\nTo: 'Alex Loddengaard' <alex@confluent.io>\nCc: Dennis T. Siao <Dennis.T.Siao@kp.org>\nSubject: RE: One question though - RE: FW: I was sketching out the Kafka/Confluent Stack\n\n \n\nHey Alex, no worries!\n\n \n\nI’ll give it a spin and get back to you.\n\n \n\nCheers\n\n \n\n \n\n---------------------------------------------------------------------------------\n\nShaun Wanford\n\nIntegration Architect, EIS Innovation and Product Management \nLake Oswego, OR\n503-309-8849\n\nshaun.x.wanford@kp.org\n\n \n\nFrom: Alex Loddengaard [mailto:alex@confluent.io]\nSent: Wednesday, July 05, 2017 6:12 PM\nTo: Shaun X. Wanford <Shaun.X.Wanford@kp.org>\nCc: Dennis T. Siao <Dennis.T.Siao@kp.org>\nSubject: Re: One question though - RE: FW: I was sketching out the Kafka/Confluent Stack\n\n \n\nHi Shaun,\n\n \n\nFirst, sorry for my delay, I was traveling for the long weekend and been busy with other customers since.\n\n \n\nThat sounds right in theory but I've never tested it. Did you give it a try? If so, let me know how it went and if I can help with anything else.\n\n \n\nThanks, Shaun.\n\n \n\nAlex\n\n \n\nOn Mon, Jul 3, 2017 at 9:22 AM, Shaun X. Wanford <Shaun.X.Wanford@kp.org> wrote:\n\nThanks Alex!\n\n \n\nThe documentation is a little sparse. I’m hoping it’s as easy as this.\n\n \n\nhttps://wiki.eclipse.org/Jetty/Howto/Secure_Passwords\n\n \n\nand then just using the\n\n \n\nMD5:639bae9ac6b3e1a84cebb7b403297b79\n\nCRYPT:me/ks90E221EY\n\n \n\nMD5 or CRYPT prefixed obscured passwords in the ldap conf file ?\n\n \n\n \n\n \n\n \n\n---------------------------------------------------------------------------------\n\nShaun Wanford\n\nIntegration Architect, EIS Innovation and Product Management \nLake Oswego, OR\n503-309-8849\n\nshaun.x.wanford@kp.org\n\n \n\nFrom: Alex Loddengaard [mailto:alex@confluent.io]\nSent: Friday, June 30, 2017 6:20 PM\n\n\nTo: Shaun X. Wanford <Shaun.X.Wanford@kp.org>\nCc: Dennis T. Siao <Dennis.T.Siao@kp.org>\nSubject: Re: One question though - RE: FW: I was sketching out the Kafka/Confluent Stack\n\n \n\nHi Shaun, this method could be helpful, actually:\n\n \n\nhttp://download.eclipse.org/jetty/7.6.17.v20150415/apidocs/org/eclipse/jetty/plus/jaas/spi/LdapLoginModule.html#convertCredentialJettyToLdap(java.lang.String)\n\n \n\nI haven't had a chance to explore this deeply, but wanted to at least forward this suggestion that came from one of our engineers.\n\n \n\nAlex\n\n \n\nOn Fri, Jun 30, 2017 at 12:58 PM, Alex Loddengaard <alex@confluent.io> wrote:\n\nIf the password is sent over SSL, you're good. But there's no way around the password in the file unfortunately.\n\n \n\nOn Fri, Jun 30, 2017 at 12:08 PM Shaun X. Wanford <Shaun.X.Wanford@kp.org> wrote:\n\nThanks Alex! Even if we use ldap over SSL, the password goes in plaintext? That piece I think we can handle, passwords sitting in plaintext in config files is a deal-breaker.\n\n \n\nCheers.\n\n \n\n \n\n \n\n---------------------------------------------------------------------------------\n\nShaun Wanford\n\nIntegration Architect, EIS Innovation and Product Management \nLake Oswego, OR\n503-309-8849\n\nshaun.x.wanford@kp.org\n\n \n\nFrom: Alex Loddengaard [mailto:alex@confluent.io]\nSent: Friday, June 30, 2017 12:05 PM\n\n\nTo: Shaun X. Wanford <Shaun.X.Wanford@kp.org>\n\nCc: Dennis T. Siao <Dennis.T.Siao@kp.org>\nSubject: Re: One question though - RE: FW: I was sketching out the Kafka/Confluent Stack\n\n \n\nHi Shaun, I've confirmed with our team: unfortunately there's no way to get rid of the plaintext password in the configuration file. Also, know that it's transmitted in plaintext to the server, too.\n\n \n\nAlex\n\n \n\nOn Fri, Jun 30, 2017 at 10:43 AM, Alex Loddengaard <alex@confluent.io> wrote:\n\nHi Shaun, unfortunately I think there's no way around this. Let me ask our engineering team to confirm.\n\n \n\nAlex\n\n \n\nOn Thu, Jun 29, 2017 at 4:27 PM, Shaun X. Wanford <Shaun.X.Wanford@kp.org> wrote:\n\n \n\nHey Alex,\n\n \n\nOne thing that that will be roadblock is that the ldap password is in plain-text? Anything we can do about that? See ** below.\n\n \n\nThanks!\n\n \n\nc3 {\n\norg.eclipse.jetty.jaas.spi.LdapLoginModule required\n\n   debug=\"false\"\n\n   useLdaps=\"false\"\n\n   contextFactory=\"com.sun.jndi.ldap.LdapCtxFactory\"\n\n   hostname=\"CS.MSDS.KP.ORG\"\n\n   port=\"389\"\n\n   bindDn=\"service account here\"\n\n   bindPassword=\"**service account password here \"\n\n   authenticationMethod=\"simple\"\n\n   forceBindingLogin=\"true\"\n\n   userBaseDn=\"DC=cs,DC=msds,DC=kp,DC=org\"\n\n   userRdnAttribute=\"sAMAccountName\"\n\n   userIdAttribute=\"sAMAccountName\"\n\n   userPasswordAttribute=\"userPassword\"\n\n   userObjectClass=\"user\"\n\n   roleBaseDn=\"ou=Groups,DC=cs,DC=msds,DC=kp,DC=org\"\n\n   roleNameAttribute=\"cn\"\n\n   roleMemberAttribute=\"member\"\n\n   roleObjectClass=\"group\";\n\n \n\n};\n\n \n\n \n\n \n\n---------------------------------------------------------------------------------\n\nShaun Wanford\n\nIntegration Architect, EIS Innovation and Product Management \nLake Oswego, OR\n503-309-8849\n\nshaun.x.wanford@kp.org\n\n \n\nFrom: Alex Loddengaard [mailto:alex@confluent.io]\nSent: Thursday, June 29, 2017 11:25 AM\nTo: Shaun X. Wanford <Shaun.X.Wanford@kp.org>\nSubject: Re: FW: I was sketching out the Kafka/Confluent Stack\n\n \n\nWow that's a great tool! Yeah I had to try extra hard to make my handwriting legible for Dennis. It's very, very bad. I bookmarked your tool, though, so that problem has now been solved. I love how simple it is.\n\n \n\nThanks, Shaun, and talk soon!\n\n \n\nAlex\n\n \n\nOn Thu, Jun 29, 2017 at 11:21 AM, Shaun X. Wanford <Shaun.X.Wanford@kp.org> wrote:\n\nHey Alex! I think we’re good now. You made me smile yesterday when you said you would draw a picture and then email a photo of it.\n\n \n\nMy drawings are so bad that I use this tool. I have a background with Graphs, so it’s a cool tool.\n\n \n\nhttp://www.apcjones.com/arrows/# (http://www.apcjones.com/arrows/)\n\n \n\n \n\nMy hand sketches are terrible. See attached.\n\n \n\nCheers!\n\n \n\n \n\n \n\n \n\n \n\n---------------------------------------------------------------------------------\n\nShaun Wanford\n\nIntegration Architect, EIS Innovation and Product Management \nLake Oswego, OR\n503-309-8849\n\nshaun.x.wanford@kp.org\n\n \n\nFrom: Alex Loddengaard [mailto:alex@confluent.io]\nSent: Thursday, June 29, 2017 10:54 AM\nTo: Shaun X. Wanford <Shaun.X.Wanford@kp.org>\nSubject: Re: FW: I was sketching out the Kafka/Confluent Stack\n\n \n\nCaution: This email came from outside Kaiser Permanente. Do not open attachments or click on links if you do not recognize the sender.\n\n-------------------------------\n\nHi Shaun,\n\n \n\nThank you. Your SSL help was very, very appreciated. And your patience.\n\n \n\nThanks for sharing this. This is helpful to understand the broad picture of how and where Kafka fits in.\n\n \n\nLet me know if you'd like me to give any feedback on it, or if I can help with anything else.\n\n \n\nAlex\n\n \n\nOn Thu, Jun 29, 2017 at 10:34 AM, Shaun X. Wanford <Shaun.X.Wanford@kp.org> wrote:\n\nHey Alex! Thanks for all your help and patience yesterday. Was a good day.\n\n \n\nI was sketching out where we are , if you’re interested.\n\n \n\nCheers\n\n \n\nShaun.\n\n \n\n \n\n---------------------------------------------------------------------------------\n\nShaun Wanford\n\nIntegration Architect, EIS Innovation and Product Management \nLake Oswego, OR\n503-309-8849\n\nshaun.x.wanford@kp.org\n\n \n\nFrom: Shaun X. Wanford\nSent: Thursday, June 29, 2017 10:08 AM\nTo: Dennis T. Siao <Dennis.T.Siao@kp.org>\nCc: James X. Cheung <james.ws.cheung@kp.org>\nSubject: I was sketching out the Kafka/Confluent Stack\n\n \n\nHey Dennis, I think what I wanted to point out was that we’ll need a lot of Unique SSL Key-stores. Every Kafka Producer/consumer will need an SSL Cert (and key-store) that uniquely identifies it.\n\n \n\nThis may help picture stuff. Cheers.\n\n \n\n \n\n \n\n---------------------------------------------------------------------------------\n\nShaun Wanford\n\nIntegration Architect, EIS Innovation and Product Management \nLake Oswego, OR\n503-309-8849\n\nshaun.x.wanford@kp.org\n\n \n\nNOTICE TO RECIPIENT:  If you are not the intended recipient of this e-mail, you are prohibited from sharing, copying, or otherwise using or disclosing its contents.  If you have received this e-mail in error, please notify the sender immediately by reply e-mail and permanently delete this e-mail and any attachments without reading, forwarding or saving them.  Thank you.\n\n \n\nNOTICE TO RECIPIENT:  If you are not the intended recipient of this e-mail, you are prohibited from sharing, copying, or otherwise using or disclosing its contents.  If you have received this e-mail in error, please notify the sender immediately by reply e-mail and permanently delete this e-mail and any attachments without reading, forwarding or saving them.  Thank you.\n\n \n\nNOTICE TO RECIPIENT:  If you are not the intended recipient of this e-mail, you are prohibited from sharing, copying, or otherwise using or disclosing its contents.  If you have received this e-mail in error, please notify the sender immediately by reply e-mail and permanently delete this e-mail and any attachments without reading, forwarding or saving them.  Thank you.\n\n \n\n \n\nNOTICE TO RECIPIENT:  If you are not the intended recipient of this e-mail, you are prohibited from sharing, copying, or otherwise using or disclosing its contents.  If you have received this e-mail in error, please notify the sender immediately by reply e-mail and permanently delete this e-mail and any attachments without reading, forwarding or saving them.  Thank you.\n\n--\n\nSent from mobile\n\n \n\nNOTICE TO RECIPIENT:  If you are not the intended recipient of this e-mail, you are prohibited from sharing, copying, or otherwise using or disclosing its contents.  If you have received this e-mail in error, please notify the sender immediately by reply e-mail and permanently delete this e-mail and any attachments without reading, forwarding or saving them.  Thank you.\n\n \n\nNOTICE TO RECIPIENT:  If you are not the intended recipient of this e-mail, you are prohibited from sharing, copying, or otherwise using or disclosing its contents.  If you have received this e-mail in error, please notify the sender immediately by reply e-mail and permanently delete this e-mail and any attachments without reading, forwarding or saving them.  Thank you.\n\n \n\nNOTICE TO RECIPIENT:  If you are not the intended recipient of this e-mail, you are prohibited from sharing, copying, or otherwise using or disclosing its contents.  If you have received this e-mail in error, please notify the sender immediately by reply e-mail and permanently delete this e-mail and any attachments without reading, forwarding or saving them.  Thank you.\n\n--\n\nSent from mobile\n\nNOTICE TO RECIPIENT:  If you are not the intended recipient of this e-mail, you are prohibited from sharing, copying, or otherwise using or disclosing its contents.  If you have received this e-mail in error, please notify the sender immediately by reply e-mail and permanently delete this e-mail and any attachments without reading, forwarding or saving them.  Thank you.\n\n--\nSent from mobile\n--\nSent from mobile\n\n\n\n--\nSam Hecht | Customer Operations | Confluent | 804.694.7411  \nDownload Apache Kafka and Confluent Platform: www.confluent.io/download","priority":null,"status":"solved","recipient":"support@confluent.io","requester_id":18968473288,"submitter_id":3324019678,"assignee_id":5907439417,"organization_id":14121536228,"group_id":29623388,"collaborator_ids":[3324019678,13784284948],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["configuration_issue","confluent__3_2_1","confluent_control_center","development","gold","jdk_1_8","p3_issue","rhel_6","summarized","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"5084"},{"id":34347728,"value":"18"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"5084"},{"id":34347728,"value":"18"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1919.json","id":1919,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-10T15:53:00Z","updated_at":"2017-07-14T17:41:28Z","type":"incident","subject":"Connect - S3 connector dies/doesn't connect at all. ","raw_subject":"Connect - S3 connector dies/doesn't connect at all. ","description":"Hi Ben, can we please pass this on to confluent – the Kafka Connect specialist.\r\n\r\nDear Confluent,\r\n\r\nI am currently attempting to use the S3 connector to send Kafka events to our company’s AWS S3 storage bucket.\r\n\r\nProblem description:\r\n\r\nThe S3 connectors initially perform as expected – the files are uploaded to S3. However, eventually (and always) the connectors silently fail – with their status displaying as “running” but the files no longer being sent up to S3. The time the connectors work for seems to be correlated to the number of topics in the config. With < 2 topics, then I’ve had the tasks run as expected for a day before silently failing. With >5 topics, the tasks rarely run longer than 10 minutes before silently failing. \r\n\r\nBackground:\r\n\r\n-\tWe’re using avro schemas\r\n-\tWe’re our connect service in distributed mode, with two nodes.\r\n-\tWe know that there should be many more events than we’ve received in S3, because also save some of these events to a SQL database. \r\n\r\nHere is a sample config:\r\n\r\n{ \r\n  \"name\": \"S3-logs-Monday-X\",\r\n    \"config\": {\r\n        \"connector.class\": \"io.confluent.connect.s3.S3SinkConnector\",\r\n        \"s3.region\": \"eu-west-1\",\r\n       \"partition.duration.ms\": \"50\",\r\n        \"topics.dir\": \"S3-logs-Monday-X\",\r\n        \"flush.size\": \"50\",\r\n        \"tasks.max\": \"1\",\r\n        \"topics\": \"zopa-origination-policyphase-PrevettingEvaluated-by-requestId,#\",\r\n        \"s3.part.size\": \"5242880\",\r\n        \"timezone\": \"UTC\",\r\n        \"retry.backoff.ms\": \"20000\",\r\n        \"locale\": \"US\",\r\n        \"value.converter.schema.registry.url\": ,\r\n        \"format.class\": \"io.confluent.connect.s3.format.avro.AvroFormat\",\r\n        \"partitioner.class\": \"io.confluent.connect.storage.partitioner.TimeBasedPartitioner\",\r\n        \"schema.generator.class\": \"io.confluent.connect.storage.hive.schema.TimeBasedSchemaGenerator\",\r\n        \"value.converter\": \"io.confluent.connect.avro.AvroConverter\",\r\n        \"storage.class\": \"io.confluent.connect.s3.storage.S3Storage\",\r\n        \"s3.bucket.name\": \"zopa-staging-uat\",\r\n        \"key.converter\": \"org.apache.kafka.connect.storage.StringConverter\",\r\n        \"path.format\": \"'year'=YYYY/'month'=MM/'day'=dd/'hour'=HH\"\r\n  }\r\n}\r\n\r\n\r\n\r\n\r\nI attach log files for few seconds around errors that the connector task has actually registered:\r\n\r\n\"tasks\": [\r\n        {\r\n            \"state\": \"FAILED\",\r\n            \"trace\": \"org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.\\n\\tat org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:451)\\n\\tat org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:250)\\n\\tat org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:179)\\n\\tat org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:148)\\n\\tat org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:139)\\n\\tat org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:182)\\n\\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\\n\\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\\n\\tat java.lang.Thread.run(Thread.java:745)\\n\",\r\n            \"id\": 0,\r\n            \"worker_id\": \"localhost:8083\"\r\n        },\r\n        {\r\n\r\n\r\nI notice:\r\n\r\n2017-07-10T11:56:41+0100 {\"log\":\"java.lang.OutOfMemoryError: Java heap space\\n\",\"stream\":\"stdout\",\"attrs\":{\"app\":\"connect\",\r\n\"node\":\"connect-kafkasbx-1\"},\"time\":\"2017-07-10T10:56:41.842182975Z\"} \r\n\r\nAnd \r\n\r\n2017-07-10T11:56:40+0100 {\"log\":\"[2017-07-10 10:56:40,568] DEBUG Ignoring fetched records for connect-status-2 at offset 700\r\nsince the current position is 701 (org.apache.kafka.clients.consumer.internals.Fetcher)\\n\",\"stream\":\"stdout\",\r\n\"attrs\":{\"app\":\"connect\",\"node\":\"connect-kafkasbx-2\"},\"time\":\"2017-07-10T10:56:40.568798485Z\"}\r\n\r\n\r\nAs though the offsets are suddenly get off track.\r\n\r\nCould you please advise on potential causes of this issue and how we should proceed. We have >30 topics, and all the events need to be stored in S3, so we need to resolve this.\r\n\r\nDon’t hesitate to let me know if you need any other information.\r\n\r\nKind regards,\r\n\r\n\r\nThis ticket includes a secure attachment. Use this link to access the attached files:\r\n https://confluent.sendsafely.com/receive/?thread=MR6M-3LMU&packageCode=0kBKAnzaOu_7rFPCgbVRoVsAsXwqa_aFIP-e-73wbag#keyCode=wGMv2nvwuasskvFhMCN8wBGQ1_83U4rpm8QhoUG2wcU","priority":null,"status":"pending","recipient":null,"requester_id":20513997487,"submitter_id":20513997487,"assignee_id":5907439417,"organization_id":14302137927,"group_id":29623388,"collaborator_ids":[21095585667,6078520403],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","configuration_issue","confluent__3_2_0","europe","jdk_1_8","kafka_connect__s3_connector","p2_issue","platinum","production"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"kafka_connect__s3_connector"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"3632"},{"id":34347728,"value":"665"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"kafka_connect__s3_connector"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"3632"},{"id":34347728,"value":"665"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1918.json","id":1918,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-10T15:52:37Z","updated_at":"2017-07-13T14:02:46Z","type":"incident","subject":"Confluent Control Center - Kafka Connect Delete Capability","raw_subject":"Confluent Control Center - Kafka Connect Delete Capability","description":"Just wondering, is there a way to disable the delete the Kafka connector capability from Control Center ?\r\n\r\nThanks-\r\nSiva Nagisetty.","priority":null,"status":"solved","recipient":null,"requester_id":5991633766,"submitter_id":5991633766,"assignee_id":5907439417,"organization_id":6328931306,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","confluent__3_2_1","confluent_control_center","enterprise","gold","jdk_1_8","jeremy_custenborder","jira_escalated","non_technical_request__roadmap_request","p3_issue","production","summarized","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":"non_technical_request__roadmap_request"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"520"},{"id":34347728,"value":"53"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"good","id":1739395203,"comment":null,"reason":"No reason provided","reason_id":332227},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":"non_technical_request__roadmap_request"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"520"},{"id":34347728,"value":"53"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1916.json","id":1916,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-10T15:50:11Z","updated_at":"2017-07-15T17:01:04Z","type":"incident","subject":"Zombie consumer in production after cluster turbulences","raw_subject":"Zombie consumer in production after cluster turbulences","description":"Hi,\r\n\r\nA few days ago we noticed that one of our consumers had gone \"zombie\". It happened in production.\r\n\r\nWe have an application called Kashmir that spins up a bunch of consumers for various topics. At the time of this problem, we had around seven consumers for different topics running in Kashmir.\r\n\r\nSome event happened in the cluster, but I'm not sure what it was. Among other things, I believe we may have had two leaders running at the same time. You can see in the image \"two-leaders\" some metrics from our Prometheus server that seem to suggest we had two of them running at the same time, for a moment.\r\n\r\nWhat triggered this situation, I don't know. I think it was organic since we don't mess around with the production cluster. You can find the logs from all the brokers in the cluster in the all-broker-logs.csv file. It's huge, though.\r\n\r\nOut of the various consumers that Kashmir run, only one got stuck. It's the consumer with the following \"logger\" value:\r\n\r\nKashmir.Messaging.Kafka.KafkaMessageConsumer`1[[Com.Zopa.Events.Origination.Policyphase.PrevettingEvaluated, Zopa.AvroSchemas, Version=0.18.0.0, Culture=neutral, PublicKeyToken=null]]\r\n\r\nYou can find all of the log entries that came from both Kashmir instances running in PROD around the time in the all-kashmir-logs.csv file. We run all apps with informational log level, so we are missing most librdkafka log entries, unfortunately. We do have the errors that it reported.\r\n\r\nLet me know if there is any more data I can provide.\r\n\r\nThanks.\r\n\r\nThis ticket includes a secure attachment. Use this link to access the attached files:\r\n https://confluent.sendsafely.com/receive/?thread=482M-JPE3&packageCode=FqxTESS68GG7wXHh3GKPjMN4SXDw_h_gPTXPCnUABAE#keyCode=oQqKfPHeiGQbUeDlZEOh71yHKlitmQZ3ikIPpmc_nig","priority":null,"status":"solved","recipient":null,"requester_id":22293456287,"submitter_id":22293456287,"assignee_id":5907439417,"organization_id":14302137927,"group_id":29623388,"collaborator_ids":[19548920387,20513997487],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","configuration_issue","confluent__3_2_1","consumer","europe","jdk_1_8","p2_issue","platinum","production","summarized"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"consumer"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"10540"},{"id":34347728,"value":"4"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"consumer"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"10540"},{"id":34347728,"value":"4"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1915.json","id":1915,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-10T15:42:11Z","updated_at":"2017-07-13T13:31:07Z","type":"incident","subject":"Confluent Upgrade","raw_subject":"Confluent Upgrade","description":"we went to Production with Confluent version 3.2.1. We are planning on upgrading our environment to version 3.2.2. Just wondering, is there any documentation on how to do the upgrade without destructing the existing Production ? ","priority":null,"status":"solved","recipient":null,"requester_id":5991633766,"submitter_id":5991633766,"assignee_id":5907439417,"organization_id":6328931306,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","confluent__3_2_1","enterprise","general_question","gold","jdk_1_8","jeremy_custenborder","p3_issue","production","recommendation___best_practices","summarized","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"general_question"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"323"},{"id":34347728,"value":"22"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"good","id":1747651506,"comment":null,"reason":"No reason provided","reason_id":332227},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"general_question"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"323"},{"id":34347728,"value":"22"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1913.json","id":1913,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-10T13:26:47Z","updated_at":"2017-07-14T14:01:04Z","type":"incident","subject":"Kafka Connect Security","raw_subject":"Kafka Connect Security","description":"Hi,\r\nI was reading the documentation and digging through the code regarding kafka connect to investigate security options. I can see information with regards to securing connects access to the kafka cluster but am unable to find anything with regards to securing the connect REST API. Given that this is the primary means of confugring a distributed connect installation is there anything I can do to secure it?\r\n\r\nThanks,\r\nMatt","priority":null,"status":"solved","recipient":null,"requester_id":4989318888,"submitter_id":4989318888,"assignee_id":5907439417,"organization_id":2603470857,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["apache_kafka__0_10_2_1","centos_7","development","europe","gold","jdk_1_8","kafka_connect","p3_issue","recommendation___best_practices","summarized"],"custom_fields":[{"id":24843497,"value":"apache_kafka__0_10_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"kafka_connect"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"1095"},{"id":34347728,"value":"48"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"apache_kafka__0_10_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"kafka_connect"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"1095"},{"id":34347728,"value":"48"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1912.json","id":1912,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-10T13:26:19Z","updated_at":"2017-07-15T17:01:03Z","type":"incident","subject":"Documentation for librdkafka debug contexts","raw_subject":"Documentation for librdkafka debug contexts","description":"Hi,\r\n\r\nWe have enabled debug logging level for librdkafka in some environments (previous to production) and they're very helpful to identify complicated issues.\r\n\r\nHowever, these logs are quite verbose. We know that we can configure what contexts we want to log. The problem is the documentation is non-existent, AFAIK.\r\n\r\nThe contexts are described here:\r\nhttps://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md\r\n\r\nWhat everybody one of them logs is a bit of a mystery. Some names are more indicative than others, but still it would be useful to have a clear description of every single one of them so we can disable those that are causing noise.\r\n\r\nThanks.","priority":null,"status":"solved","recipient":null,"requester_id":22293456287,"submitter_id":22293456287,"assignee_id":5907439417,"organization_id":14302137927,"group_id":29623388,"collaborator_ids":[19548920387],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","client__other","confluent__3_2_1","development","europe","jdk_1_8","jira_escalated","p3_issue","platinum","recommendation___best_practices","summarized"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"client__other"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"4511"},{"id":34347728,"value":"610"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"client__other"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"4511"},{"id":34347728,"value":"610"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1911.json","id":1911,"external_id":null,"via":{"channel":"email","source":{"from":{"address":"bjacob@tekion.com","name":"Blessen Jacob"},"to":{"name":"Confluent","address":"support@confluent.io"},"rel":null}},"created_at":"2017-07-09T11:32:30Z","updated_at":"2017-07-14T21:01:04Z","type":"incident","subject":"Tekion :- Prod vs NonProd confluent Kafka","raw_subject":"Tekion :- Prod vs NonProd confluent Kafka","description":"Hi ,\n\n    Please assign a support request for the following\n\nWe are in need to maintain a non-prod along with the existing prod cluster, we would like to know the following\n\n1. Do we need to maintain a isolated prod and non-prod clusters ( separate-end points )\n2. Is there a possibility to use the same cluster for non-prod and prod\n3. If in case #2  , how does confluent keep the prod data secured from non-prod and without any data corruption or manipulation\n4.please advise the best practices in such case.\n5. Is there any cost difference between non-prod asset vs prod asset.\n\nThanks.\nBlessen","priority":null,"status":"solved","recipient":"support@confluent.io","requester_id":5980441463,"submitter_id":5980441463,"assignee_id":5930716698,"organization_id":6321634186,"group_id":29623388,"collaborator_ids":[5715446723,5881647326,5980463903,5980462583,3324019678,5715438023,19281148107],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["ccloud","confluent__3_2_2","jdk_1_8","multiple","p3_issue","recommendation___best_practices","summarized"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":""},{"id":33020448,"value":"ccloud"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"1440"},{"id":34347728,"value":"203"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":""},{"id":33020448,"value":"ccloud"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"1440"},{"id":34347728,"value":"203"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1908.json","id":1908,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-08T14:17:38Z","updated_at":"2017-07-11T20:35:26Z","type":"incident","subject":"Production Data Missing ","raw_subject":"Production Data Missing ","description":"we are doing the initial loads using Kafka in Production and we are seeing some data missing from our source to target.\r\n\r\nNeed help in figuring out what is going on..!","priority":null,"status":"pending","recipient":null,"requester_id":5991633766,"submitter_id":5991633766,"assignee_id":21324568227,"organization_id":6328931306,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["broker","centos_7","confluent__3_2_1","enterprise","gold","jdk_1_8","jeremy_custenborder","p1_issue","production","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"broker"},{"id":47641647,"value":""},{"id":33471847,"value":"p1_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"7877"},{"id":34347728,"value":"476"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"broker"},{"id":47641647,"value":""},{"id":33471847,"value":"p1_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"7877"},{"id":34347728,"value":"476"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1747.json","id":1747,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-06-20T16:38:53Z","updated_at":"2017-06-20T16:55:12Z","type":"incident","subject":"Kafka JDBC connect source failing on validation for as400 database","raw_subject":"Kafka JDBC connect source failing on validation for as400 database","description":"We have a kafka connect source that works for SQL database. When we update the same to point to an as400 database the validation fails always in kafka connect. We found that there is a call as below being made to as400 to get the table names for whitelist column prompt however it fails there since the syntax is wrong. The 'JDBC' should really be JDBC without quotes for as400 and we don't know how to change that call parameters. We also need to pass it a schema name for parameter 2 so please help us identify and resolve this issue. \r\n\r\nCALL SYSIBM/SQLTABLES(NULL,NULL,'%','','DATATYPE='JDBC';DYNAMIC=0;REPORTPUBLICPRIVILEGES=1;CURSORHOLD=1');\r\n\r\nThis ticket includes a secure attachment. Use this link to access the attached files:\r\n https://confluent.sendsafely.com/receive/?thread=4EY7-MBEL&packageCode=2Dif3jrmEPtF_2caYFfSRGYpTI9TY0yxZaSE6zLIsKA#keyCode=M_5JslnbVFl1mlk0W5Z2Lhyr3W8OZv8zJHqAZtZW8sw","priority":null,"status":"closed","recipient":null,"requester_id":5921452743,"submitter_id":5921452743,"assignee_id":5699232346,"organization_id":15296963048,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["closed_by_merge","confluent__3_2_1","dc_os","development","gold","jdk_1_8","p3_issue","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"dc_os"},{"id":33020448,"value":""},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"83"},{"id":34347728,"value":"83"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"dc_os"},{"id":33020448,"value":""},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"83"},{"id":34347728,"value":"83"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"followup_ids":[],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1907.json","id":1907,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-07T19:16:44Z","updated_at":"2017-07-13T22:01:03Z","type":"incident","subject":"Does JDBC Connect - Sink support Redshift?","raw_subject":"Does JDBC Connect - Sink support Redshift?","description":"Does JDBC Connect - Sink support Redshift?","priority":null,"status":"solved","recipient":null,"requester_id":5766348623,"submitter_id":5766348623,"assignee_id":21324568227,"organization_id":5273937083,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["confluent__3_2_2","gold","jdbc_connector","jdk_1_8","jeremy_custenborder","multiple","p3_issue","recommendation___best_practices","rhel_7","summarized","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"jdbc_connector"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"2456"},{"id":34347728,"value":"68"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"jdbc_connector"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"2456"},{"id":34347728,"value":"68"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1905.json","id":1905,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-07T16:42:39Z","updated_at":"2017-07-13T17:01:03Z","type":"incident","subject":"Hooks into offset commits","raw_subject":"Hooks into offset commits","description":"Is there any mechanism for overriding the default offset commit behavior? Ideally Im interested in decrementing the offsets committed, eg if the default code is:\r\n\r\ncommit(desiredOffsetForPartition1)\r\n\r\nI want to override this with:\r\n\r\ncommit(max(0, desiredOffsetForPartition1 - SOME_CONSTANT))\r\n\r\nWhere SOME_CONSTANT is a cache size. The idea being that rather than worrying about having state stores which are restored from topics for FT, we just let the state store data evaporate on shut down and just reprocess any potentially lost message data on startup.\r\n\r\nAlternatively, is there any way to hook into the offset loading behavior on startup so that I could decrement by a constant amount on startup to achieve the same effect?\r\n\r\nThanks,\r\n-Tony","priority":null,"status":"solved","recipient":null,"requester_id":5694286066,"submitter_id":5694286066,"assignee_id":21324568227,"organization_id":10885029188,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["confluent__3_2_2","dc_os","gold","jdk_1_8","kafka_streams","p3_issue","qa","recommendation___best_practices","streams_escalated","summarized","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"dc_os"},{"id":33020448,"value":"kafka_streams"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"qa"},{"id":77414608,"value":null},{"id":34347708,"value":"4174"},{"id":34347728,"value":"67"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"dc_os"},{"id":33020448,"value":"kafka_streams"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"qa"},{"id":77414608,"value":null},{"id":34347708,"value":"4174"},{"id":34347728,"value":"67"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1904.json","id":1904,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-07T09:29:14Z","updated_at":"2017-07-14T15:01:01Z","type":"incident","subject":"GC log removal","raw_subject":"GC log removal","description":"Hi\r\n\r\nWe are using the java startup options to rotate the GC log (for testing -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=4 -XX:GCLogFileSize=10M).    \r\n\r\nThis creates the GC log as kafkaServer-gc.log.X where X is a number, starting at 0, with the current file having a suffix of .current\r\n\r\nIs it safe to remove old files (i.e. with those that have not been written for a few days) ?\r\n\r\nIan","priority":null,"status":"solved","recipient":null,"requester_id":10713580267,"submitter_id":10713580267,"assignee_id":13678049447,"organization_id":2603470857,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["broker","centos_7","confluent__3_2_2","europe","gold","jdk_1_8","multiple","p3_issue","recommendation___best_practices","summarized"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"broker"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"226"},{"id":34347728,"value":"53"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"broker"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"226"},{"id":34347728,"value":"53"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1902.json","id":1902,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-07T08:41:30Z","updated_at":"2017-07-10T15:21:42Z","type":"incident","subject":"JMS Client","raw_subject":"JMS Client","description":"Hi\r\n\r\nWe need to use kafka-jms-client to connect a XFB monitor to kafka topics both as producer and consumer.\r\nSo far we have made some tests with the version 3.2.0 of the confluent platform and the jms-client available as a maven dependency.\r\n\r\nHere are the problems we’ve encountered :\r\n-\tThe initial context factory is not implemented and returns “null”. The client library is therefore not usable in a jndi fashion, which is the only thing XFB can do.\r\n-\tIt seems the configurations are hardcoded. We’ve been unable to change the serialiers and deserializers and are stuck with the avro ones.\r\n-\tFor the same reason, we’ve been unable to set the auto.offset.reset value do earliest, so we can’t get messages already in the topic, which incurs message loss from a functional point of view.\r\n-\tWe’ve been unable to consume in a jms-client messages that have not been produced by another jms-client or to consume in a standard client messages that have been generated by a jms-client. We suspect it’s a side effect of being stuck with the avro serializers/deserializers.\r\n-\tThe packaging downloaded from the maven repository is an uber jar which is complex to integrate in the project, we have to strip all duplicate dependencies.\r\n \r\nSince most of those problems seem to root in the fact the jms-client available on the repository is flawed, we’d like to obtain the latest correct production-ready library.\r\n\r\nBest Regards;\r\n","priority":null,"status":"pending","recipient":null,"requester_id":5940247203,"submitter_id":5940247203,"assignee_id":13678049447,"organization_id":6107119566,"group_id":29623388,"collaborator_ids":[5940240383,5947960906],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["clients__jms_client","confluent__3_2_0","development","enterprise","europe","jdk_1_8","p3_issue","silver","ubuntu_14_04_lts"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"ubuntu_14_04_lts"},{"id":33020448,"value":"clients__jms_client"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"1571"},{"id":34347728,"value":"9"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"ubuntu_14_04_lts"},{"id":33020448,"value":"clients__jms_client"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"1571"},{"id":34347728,"value":"9"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1901.json","id":1901,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-06T23:17:41Z","updated_at":"2017-07-10T21:03:05Z","type":"incident","subject":"Error: stale out-of-order record","raw_subject":"Error: stale out-of-order record","description":"We currently have an issue where we noticed one partition in one topic is not being written to S3.\r\n\r\nI've tried restarted the task and the worker but it still won't write to S3.\r\nIt shows this in the logs:\r\nJul 06 23:10:45 cf-kafka-wr2-prod.prod.dse.mb-internal.com connect-distributed[15685]: [2017-07-06 23:10:45,948] INFO Fetch offset 137649618 is out of range for partition v3_shuriken_request-5, resetting offset (org.apache.kafka.clients.consumer.internals.Fetcher:820)\r\nJul 06 23:10:46 cf-kafka-wr2-prod.prod.dse.mb-internal.com connect-distributed[15685]: [2017-07-06 23:10:46,007] INFO Ignoring stale out-of-order record in v3_shuriken_request-5. Has offset 475110571 instead of expected offset 137649618 (io.confluent.connect.hdfs.TopicPartitionWriter:531)\r\n\r\nBut it shows the lag for that partition is inline with the other partitions even though the data isn't being commited to S3:\r\nTOPIC                          PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG        CONSUMER-ID                                       HOST                           CLIENT-ID\r\nv3_shuriken_request            0          488772928       488773595       667        consumer-10-6442961a-0be5-4229-96f5-d400f2e54fc7  /10.117.12.40                  consumer-10\r\nv3_shuriken_request            1          488774811       488775478       667        consumer-11-969ad61c-335d-4acf-a9c3-f25427f1d11c  /10.117.12.40                  consumer-11\r\nv3_shuriken_request            2          488622953       488624416       1463       consumer-13-bc033bba-6d74-45cd-86ae-67084f1eb546  /10.117.12.40                  consumer-13\r\nv3_shuriken_request            3          488619317       488619974       657        consumer-4-9b251381-7517-41be-ac55-6077219f1e76   /10.117.13.41                  consumer-4\r\nv3_shuriken_request            5          488615042       488615696       654        consumer-6-bbce4ec7-b372-4c99-b959-66b130f2c671   /10.117.13.41                  consumer-6\r\nv3_shuriken_request            4          488767954       488768609       655        consumer-5-416be400-6036-4637-989f-203372a038c4   /10.117.13.41                  consumer-5","priority":null,"status":"pending","recipient":null,"requester_id":12495406047,"submitter_id":12495406047,"assignee_id":5699232346,"organization_id":10848328548,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","confluent__3_2_1","gold","jdk_1_8","kafka_connect__s3_connector","p2_issue","production","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"kafka_connect__s3_connector"},{"id":47641647,"value":""},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"2686"},{"id":34347728,"value":"65"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"kafka_connect__s3_connector"},{"id":47641647,"value":""},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"2686"},{"id":34347728,"value":"65"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1900.json","id":1900,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-06T22:43:32Z","updated_at":"2017-07-13T09:24:03Z","type":"incident","subject":"ActiveController changed without reason and caused connection rejected to consumer","raw_subject":"ActiveController changed without reason and caused connection rejected to consumer","description":"Active controller changed around 10 am from brokerId 7 to 2 to 3 and offline partition count increased to 79.\r\nAfter restarting kafka broker 3, Active controller changed to 4 and offline partition count reduced to 2.\r\nNo restarts done around 10 am, but why is Active controller changed its course of action.\r\nAttached screenshot.\r\n\r\nThis ticket includes a secure attachment. Use this link to access the attached files:\r\n https://confluent.sendsafely.com/receive/?thread=517M-18VX&packageCode=FP125qeV_V3HV5C1muV0wZT7l5Zjf_hxLqxY39NJbcY#keyCode=tUNARc92sLSQgVI0JSbfFpzbtFzgzMQYAXaKLi9QRDM","priority":null,"status":"pending","recipient":null,"requester_id":16260692888,"submitter_id":16260692888,"assignee_id":5699232346,"organization_id":14010977147,"group_id":29623388,"collaborator_ids":[16162906007,16260667548,21011992308],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["apache_kafka__0_10_2_0","broker__controller","gold","jdk_1_8","non_technical_request__other","p3_issue","production","rhel_6","us_canada"],"custom_fields":[{"id":24843497,"value":"apache_kafka__0_10_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"broker__controller"},{"id":47641647,"value":"non_technical_request__other"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"8536"},{"id":34347728,"value":"370"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"apache_kafka__0_10_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"broker__controller"},{"id":47641647,"value":"non_technical_request__other"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"8536"},{"id":34347728,"value":"370"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1899.json","id":1899,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-06T21:34:09Z","updated_at":"2017-07-13T09:17:44Z","type":"incident","subject":"Negative message latency","raw_subject":"Negative message latency","description":"The worker logs are getting filled with these messages:\r\nIs there anyway to fix this or tune the threshold of the warning?\r\n\r\n\r\n:21 cf-kafka-wr1-prod.prod.dse.mb-internal.com connect-distributed[26282]: [2017-07-06 21:31:21,177] WARN Negative message latency=-9 ms (io.confluent.monitoring.clients.interceptor.MonitoringMetrics:56)\r\nJul 06 21:31:21 cf-kafka-wr1-prod.prod.dse.mb-internal.com connect-distributed[26282]: [2017-07-06 21:31:21,177] WARN Negative message latency=-9 ms (io.confluent.monitoring.clients.interceptor.MonitoringMetrics:56)\r\nJul 06 21:31:21 cf-kafka-wr1-prod.prod.dse.mb-internal.com connect-distributed[26282]: [2017-07-06 21:31:21,173] WARN Negative message latency=-9 ms (io.confluent.monitoring.clients.interceptor.MonitoringMetrics:56)\r\nJul 06 21:31:21 cf-kafka-wr1-prod.prod.dse.mb-internal.com connect-distributed[26282]: [2017-07-06 21:31:21,177] WARN Negative message latency=-5 ms (io.confluent.monitoring.clients.interceptor.MonitoringMetrics:56)\r\nJul 06 21:31:21 cf-kafka-wr1-prod.prod.dse.mb-internal.com connect-distributed[26282]: [2017-07-06 21:31:21,177] WARN Negative message latency=-6 ms (io.confluent.monitoring.clients.interceptor.MonitoringMetrics:56)\r\nJul 06 21:31:21 cf-kafka-wr1-prod.prod.dse.mb-internal.com connect-distributed[26282]: [2017-07-06 21:31:21,177] WARN Negative message latency=-6 ms (io.confluent.monitoring.clients.interceptor.MonitoringMetrics:56)\r\nJul 06 21:31:21 cf-kafka-wr1-prod.prod.dse.mb-internal.com connect-distributed[26282]: [2017-07-06 21:31:21,177] WARN Negative message latency=-6 ms (io.confluent.monitoring.clients.interceptor.MonitoringMetrics:56)\r\nJul 06 21:31:21 cf-kafka-wr1-prod.prod.dse.mb-internal.com connect-distributed[26282]: [2017-07-06 21:31:21,177] WARN Negative message latency=-7 ms (io.confluent.monitoring.clients.interceptor.MonitoringMetrics:56)\r\nJul 06 21:31:21 cf-kafka-wr1-prod.prod.dse.mb-internal.com connect-distributed[26282]: [2017-07-06 21:31:21,177] WARN Negative message latency=-7 ms (io.confluent.monitoring.clients.interceptor.MonitoringMetrics:56)\r\nJul 06 21:31:21 cf-kafka-wr1-prod.prod.dse.mb-internal.com connect-distributed[26282]: [2017-07-06 21:31:21,177] WARN Negative message latency=-8 ms (io.confluent.monitoring.clients.interceptor.MonitoringMetrics:56)\r\nJul 06 21:31:21 cf-kafka-wr1-prod.prod.dse.mb-internal.com connect-distributed[26282]: [2017-07-06 21:31:21,173] WARN Negative message latency=-4 ms (io.confluent.monitoring.clients.interceptor.MonitoringMetrics:56)\r\nJul 06 21:31:21 cf-kafka-wr1-prod.prod.dse.mb-internal.com connect-distributed[26282]: [2017-07-06 21:31:21,177] WARN Negative message latency=-1 ms (io.confluent.monitoring.clients.interceptor.MonitoringMetrics:56)\r\nJul 06 21:31:21 cf-kafka-wr1-prod.prod.dse.mb-internal.com connect-distributed[26282]: [2017-07-06 21:31:21,177] WARN Negative message latency=-1 ms (io.confluent.monitoring.clients.interceptor.MonitoringMetrics:56)\r\nJul 06 21:31:21 cf-kafka-wr1-prod.prod.dse.mb-internal.com connect-distributed[26282]: [2017-07-06 21:31:21,178] WARN Negative message latency=-1 ms (io.confluent.monitoring.clients.interceptor.MonitoringMetrics:56)\r\nJul 06 21:31:21 cf-kafka-wr1-prod.prod.dse.mb-internal.com connect-distributed[26282]: [2017-07-06 21:31:21,178] WARN Negative message latency=-1 ms (io.confluent.monitoring.clients.interceptor.MonitoringMetrics:56)\r\nJul 06 21:31:21 cf-kafka-wr1-prod.prod.dse.mb-internal.com connect-distributed[26282]: [2017-07-06 21:31:21,178] WARN Negative message latency=-2 ms (io.confluent.monitoring.clients.interceptor.MonitoringMetrics:56)\r\nJul 06 21:31:21 cf-kafka-wr1-prod.prod.dse.mb-internal.com connect-distributed[26282]: [2017-07-06 21:31:21,178] WARN Negative message latency=-2 ms (io.confluent.monitoring.clients.interceptor.MonitoringMetrics:56)","priority":null,"status":"pending","recipient":null,"requester_id":12495406047,"submitter_id":12495406047,"assignee_id":5699232346,"organization_id":10848328548,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","configuration_issue","confluent__3_2_1","consumer","gold","jdk_1_8","p3_issue","production","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"consumer"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"1386"},{"id":34347728,"value":"236"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"consumer"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"1386"},{"id":34347728,"value":"236"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1743.json","id":1743,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-06-19T19:22:13Z","updated_at":"2017-07-14T15:37:06Z","type":"incident","subject":"Vertafore Issue with Under-replicated partitions in Test environment","raw_subject":"Vertafore Issue with Under-replicated partitions in Test environment","description":"Hi Ernest,\n\nIt was a pleasure speaking with you and your team.  Per our conversation, I'm opening up this support case so we can continue our investigation of the issue you're running into in your test environment.  \n\nAlla is going to follow-up shortly with a list of things we need you to provide so we can continue our investigation.  In the meantime, here are my notes from our call for reference:\n\n- Vertafore is checking for under replicated partitions every five minutes.  monitoring for cases where that is greater than zero.  usually the condition only persisted for a few seconds and they just happened to have the check happen in the middle of that.\nin some cases partitions get under-replicated and stay that way indefinitely.  The only thing that corrects it restarting one of the brokers.\n- Running kafka-topics CLI tool to get the list of topics and vertafore has a shell script that takes the output and looks at where there are under-replicated partitions.\n- on average this happens once a day.\n- the number of brokers they have to restart in order to fix the issue varies.\n- Vertafore typically sees one broker in particular that’s missing from the ISR and they start w/ that when restarting.\n- several environments w/ identical configurations - 3 brokers and 3 ZK instances.\n\nWarm Regards,\nSam","priority":null,"status":"open","recipient":null,"requester_id":5915258463,"submitter_id":3324019678,"assignee_id":5699232346,"organization_id":13395394727,"group_id":29623388,"collaborator_ids":[3324019678,15528190768,15528198688,15528119848],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["broker__replication_manager","confluent__3_1_2","development","gold","jdk_1_8","p3_issue","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_1_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":""},{"id":33020448,"value":"broker__replication_manager"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"16527"},{"id":34347728,"value":"7620"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_1_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":""},{"id":33020448,"value":"broker__replication_manager"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"16527"},{"id":34347728,"value":"7620"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1896.json","id":1896,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-06T20:24:32Z","updated_at":"2017-07-07T19:16:01Z","type":"incident","subject":"Kafka connect warning messages","raw_subject":"Kafka connect warning messages","description":"Seeing a lot of messaging as follows - any advice on resolving this so we don't get the warnings?  This fills the log up very quickly:\r\n\r\n[2017-07-06 16:09:55,123] WARN Ignoring invalid task provided offset uat-connect-logs-2017.06.30-16/OffsetAndMetadata{offset=600332, metadata=''} -- partition not assigned (org.apache.kafka.connect.runtime.WorkerSinkTask)\r\n[2017-07-06 16:09:55,123] WARN Ignoring invalid task provided offset sit-connect-logs-2017.07.03-16/OffsetAndMetadata{offset=11929273, metadata=''} -- partition not assigned (org.apache.kafka.connect.runtime.WorkerSinkTask)\r\n[2017-07-06 16:09:55,123] WARN Ignoring invalid task provided offset sit-connect-logs-2017.06.29-16/OffsetAndMetadata{offset=1324608, metadata=''} -- partition not assigned (org.apache.kafka.connect.runtime.WorkerSinkTask)\r\n[2017-07-06 16:09:55,123] WARN Ignoring invalid task provided offset pplt-connect-logs-2017.06.29-19/OffsetAndMetadata{offset=20762747, metadata=''} -- partition not assigned (org.apache.kafka.connect.runtime.WorkerSinkTask)\r\n\r\n\r\nConfig as follows:\r\n\r\n\"config\": {\r\n        \"batch.size\": \"5000\",\r\n        \"connection.url\": \"http://sitesc111w88m7.etrade.com:9200\",\r\n        \"connector.class\": \"io.confluent.connect.elasticsearch.ElasticsearchSinkConnector\",\r\n        \"flush.timeout.ms\": \"30000\",\r\n        \"key.ignore\": \"true\",\r\n        \"max.retries\": \"60\",\r\n        \"name\": \"elasticsearch_sink\",\r\n        \"retry.backoff.ms\": \"10000\",\r\n        \"schema.ignore\": \"true\",\r\n        \"tasks.max\": \"5\",\r\n        \"topics\": \"sit-cisco_audit-logs,sit-bitbucket-logs,dit-tomcat-logs-raw,sit-tomcat-logs-raw,pplt-tomcat-logs-raw,uat-tomcat-logs-raw,dit-performance-logs-raw,sit-performance-logs-raw,pplt-performance-logs-raw,uat-performance-logs-raw,dit-default-logs-raw,sit-default-logs-raw,pplt-default-logs-raw,uat-default-logs-raw\",\r\n        \"transforms\": \"MessageTypeRouter, TimestampRouter\",\r\n        \"transforms.MessageTypeRouter.regex\": \"^(dit|sit|uat|pplt)-.*\",\r\n        \"transforms.MessageTypeRouter.replacement\": \"$1-connect-logs\",\r\n        \"transforms.MessageTypeRouter.type\": \"org.apache.kafka.connect.transforms.RegexRouter\",\r\n        \"transforms.TimestampRouter.timestamp.format\": \"yyyy.MM.dd\",\r\n        \"transforms.TimestampRouter.topic.format\": \"${topic}-${timestamp}\",\r\n        \"transforms.TimestampRouter.type\": \"org.apache.kafka.connect.transforms.TimestampRouter\",\r\n        \"type.name\": \"true\"\r\n    },\r\n\r\n","priority":null,"status":"pending","recipient":null,"requester_id":21000116327,"submitter_id":21000116327,"assignee_id":21324568227,"organization_id":15862541148,"group_id":29623388,"collaborator_ids":[21000058107],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["bug","centos_6","confluent__3_2_1","gold","jdk_1_8","kafka_connect__elasticsearch_connector","p3_issue","qa","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_6"},{"id":33020448,"value":"kafka_connect__elasticsearch_connector"},{"id":47641647,"value":"bug"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"qa"},{"id":77414608,"value":null},{"id":34347708,"value":"2567"},{"id":34347728,"value":"57"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_6"},{"id":33020448,"value":"kafka_connect__elasticsearch_connector"},{"id":47641647,"value":"bug"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"qa"},{"id":77414608,"value":null},{"id":34347708,"value":"2567"},{"id":34347728,"value":"57"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1895.json","id":1895,"external_id":null,"via":{"channel":"email","source":{"from":{"address":"atulya.bhimarasetty@macys.com","name":"Atulya Bhimarasetty"},"to":{"name":"Confluent","address":"support@confluent.io"},"rel":null}},"created_at":"2017-07-06T20:20:17Z","updated_at":"2017-07-15T00:28:37Z","type":"incident","subject":"Kafka Docker Questions","raw_subject":"Kafka Docker Questions","description":"Hi Support,\nI've gone through the Kafka Docker documentation on your website, and I've a few questions w.r.t the best practices when setting up a cluster. I've attached the Docker Compose YAML file your reference.\n\n1.      In the docker-compose.yml file, I have KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://jcia9134:39092 mentioned. But when I actually log into the container and check server.properties under /etc/kafka, I see that both #advertised.listeners=PLAINTEXT://your.host.name:9092 and #listeners=PLAINTEXT://:9092 are commented out. My assumption is the underlying container's server.properties should reflect jcia9134:39092. Why is this?\n\n2.      Also in the docker-compose.yml file under volumes, I have /appsdata/osp/kafka/datastore mounted to /var/lib/kafka/data and /applogs/osp/kafka mounted to /var/log/kafka/, but I don't see this in the container's server.properties file. The container's server.properties file shows log.dirs=/var/lib/kafka. And does log.retention.hours=168 mentioned in the container's server.properties file take affect when creating a new topic (when retention period is not specified?).\n\n3.      With respect to log files, in the docker-compose.yml file under volumes, I have /applogs/osp/kafka mapped to /var/log/kafka/, but I only see zookeeper-gc.log and kafkaServer-gc.log. Why aren't server.log, controller.log, etc. being written to the /applogs/osp/kafka dir?\n\n4.      In your documentation (http://docs.confluent.io/current/cp-docker-images/docs/tutorials/clustered-deployment-ssl.html) at Step 4, you are mounting a new directory: -v ${KAFKA_SSL_SECRETS_DIR}:/etc/kafka/secrets, and before that you are exposing this entry: -e KAFKA_SSL_KEYSTORE_FILENAME=kafka.broker1.keystore.jks. How does Docker Compose know where kafka.broker1.keystore.jks is located?  If it does know, can this location be changed?\n\n5.      And how do I add the below 3 entries in log4j.properties file to the Docker Compose YAML file?\na.      log4j.appender.kafkaAppender=org.apache.log4j.RollingFileAppender\nb.      log4j.appender.kafkaAppender.MaxBackupIndex=10\nc.      log4j.appender.kafkaAppender.MaxFileSize=5MB\n\n6.      And an extension to question 5 would be how do you turn on and off DEBUG in the log4j.properties?\n\n7.      Your documentation also lists a long command (docker run --net=host --rm confluentinc/cp-kafka:3.2.1 kafka-topics --create --topic test.docker.topic --partitions 1 --replication-factor 1 --if-not-exists --zookeeper localhost:32181). Is there a shorter or easier way of doing this? And finally, the examples on your website don't list instructions for starting mirror maker. Are there limitations on running mirror maker via Docker?\n\nAtulya B | IFS TIBCO+ | Macy's Systems and Technology\n5985 State Bridge Road  | Johns Creek, GA 30097 | 312-929-5416\n [cid:image001.png@01D2B2D6.17DD72E0]","priority":null,"status":"pending","recipient":"support@confluent.io","requester_id":21787299508,"submitter_id":21787299508,"assignee_id":21324568227,"organization_id":16542134308,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["confluent__3_2_1","docker","gold","jdk_1_8","p3_issue","qa","recommendation___best_practices","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":""},{"id":33020448,"value":"docker"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"qa"},{"id":77414608,"value":null},{"id":34347708,"value":"1884"},{"id":34347728,"value":"83"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":""},{"id":33020448,"value":"docker"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"qa"},{"id":77414608,"value":null},{"id":34347708,"value":"1884"},{"id":34347728,"value":"83"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1894.json","id":1894,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-06T19:28:08Z","updated_at":"2017-07-13T13:32:21Z","type":"incident","subject":"Issue with Kafka Broker","raw_subject":"Issue with Kafka Broker","description":"Hi Ram,\n\nPer our email conversation, I'm opening up this support ticket for you.  One of our support engineers will follow up.\n\nBest,\nSam\n\n======\n\nChris/Jeff, we have an issue going on with one of our Kafka cluster, where the Kafka log rotation is not working as expected on one of the brokers of the Kafka cluster. The retention period of the topics is 7 days; however, we can see the much older logs too, and this is specific to a single broker; on the other hand, the other 4 brokers of the same cluster are working fine. Due to this we have reached the 100% disk usage for this node.\n \nPrasad and Brian are out this week and we do not have access to open a support ticket, can we please get someone to look into this issue?\n \nThanks,\nRam Boppana.","priority":null,"status":"pending","recipient":null,"requester_id":6030648626,"submitter_id":3324019678,"assignee_id":5930716698,"organization_id":1316277618,"group_id":29623388,"collaborator_ids":[3324019678,6146643037],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["apache_kafka__0_8_2_0","broker__replication_manager","configuration_issue","gold","jdk_1_7","p3_issue","production","rhel_6","us_canada"],"custom_fields":[{"id":24843497,"value":"apache_kafka__0_8_2_0"},{"id":26235617,"value":"jdk_1_7"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"broker__replication_manager"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"10631"},{"id":34347728,"value":"317"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"apache_kafka__0_8_2_0"},{"id":26235617,"value":"jdk_1_7"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"broker__replication_manager"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"10631"},{"id":34347728,"value":"317"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1893.json","id":1893,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-06T18:38:44Z","updated_at":"2017-07-11T20:27:22Z","type":"incident","subject":"Unable to download Confluent 3.2.2 v from www.confluent.io","raw_subject":"Unable to download Confluent 3.2.2 v from www.confluent.io","description":"Hi Team\r\n\r\nwe are unable to download Confluent 3.2.2 v package from confluent.io portal https://www.confluent.io/download-center/. Could you please share us the link to download 3.2.2 enterprise edition or look into this issue\r\n\r\nIt took almost an hour and half to see that nothing is downloading from the site. we tried in different machines. nothing is working. please provide us a link to donwload the 3.2.2 v \r\n\r\nthanks, Bala","priority":null,"status":"pending","recipient":null,"requester_id":5711963503,"submitter_id":5711963503,"assignee_id":21324568227,"organization_id":16959616467,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["broker","confluent__3_2_2","development","gold","jdk_1_8","jeremy_custenborder","p3_issue","recommendation___best_practices","rhel_7","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"broker"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"951"},{"id":34347728,"value":"74"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"broker"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"951"},{"id":34347728,"value":"74"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1891.json","id":1891,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-06T17:44:14Z","updated_at":"2017-07-14T16:01:02Z","type":"incident","subject":"CCloud Welcome Packet & Credentials","raw_subject":"CCloud Welcome Packet & Credentials","description":"Hi Jeff and Sanjay,\n\nWe're opening up this support case to provide you with the information you'll need to start using Confluent Cloud. We look forward to discussing all of this with you during our kick-off call!\n\nBefore we get started, one pre-requisite is that you'll need to have Java installed on your computer in advance of the call.  If you're using a Mac, you can go to [this link](https://www.java.com/en/download/help/mac_install.xml) to download it.  On the call, we'll walk through the process of getting started and using the CCloud CLI following the steps below.  \n\nFirst, follow the link below to download a file containing your CCloud access credentials:\n\nhttps://confluent.sendsafely.com/receive/?thread=LY21-X6J7&packageCode=MDEU5xy7MBIi4tCCh_2xMnBtFoevhPT8HYY3vFKFDA8#keyCode=FPFB8fwLF65wbwNWANq6CQIZhm7a7G4xsWlGanXc-40\n\nFor Java clients, you can configure your application to include your access credentials as follows:\n\n```\nbootstrap.servers=<your_broker_list>\nsecurity.protocol=SASL_SSL\nsasl.mechanism=PLAIN\nsasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=\"<your_username>\"\npassword=\"<your_password>\";\n```\n\nI also wanted to provide you with the links that we'll discuss on the kick-off call:\n\n- Confluent Cloud CLI: To get started, you'll first need to download the CCloud CLI. It can be downloaded at: https://s3-us-west-2.amazonaws.com/confluent.cloud/cli/ccloud-latest.tar.gz. NOTE: you'll first need to ensure that you have Java installed.\n- Confluent Support Operations Guide: This document will provide you with an overview of the support process, instructions for filing cases (by email or via the portal), including best practices for filing cases, escalation process, etc. Click here to review the document: https://support.confluent.io/hc/en-us/articles/115002941683.\n- CCloud Status Page: As discussed on the call and in the Operations Guide above, you can check the health of the Confluent Cloud systems and see metrics on your usage via the Confluent Cloud Status Page. This page can be accessed at https://confluent.statuspage.io. If you haven't already, you should soon receive an email with instructions to set your password and log in to the status page.\n- Best Practices for Providing Logs to Confluent: When you file a support case, you can reduce the turnaround time by providing the correct logs and data that our support team will need to help troubleshoot the issue. Please review this guide for more information: https://support.confluent.io/hc/en-us/articles/227184847-Best-Practices-for-Providing-Logs-to-Support.\n\nPlease let us know if you have any questions about any of this!\n\nBest,\nSam\n \nThis ticket includes a secure attachment. Use this link to access the attached files: \nhttps://confluent.sendsafely.com/receive/?thread=LY21-X6J7&packageCode=MDEU5xy7MBIi4tCCh_2xMnBtFoevhPT8HYY3vFKFDA8#keyCode=FPFB8fwLF65wbwNWANq6CQIZhm7a7G4xsWlGanXc-40","priority":null,"status":"solved","recipient":null,"requester_id":6022858183,"submitter_id":3324019678,"assignee_id":3324019678,"organization_id":6638527023,"group_id":29623388,"collaborator_ids":[5715446723,6022861203],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["ccloud","chris_matta","confluent__3_2_2","jdk_1_8","multiple","non_technical_request__account_admin","p3_issue","summarized"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":""},{"id":33020448,"value":"ccloud"},{"id":47641647,"value":"non_technical_request__account_admin"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"1866"},{"id":34347728,"value":"54"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":""},{"id":33020448,"value":"ccloud"},{"id":47641647,"value":"non_technical_request__account_admin"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"1866"},{"id":34347728,"value":"54"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1890.json","id":1890,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-06T17:18:43Z","updated_at":"2017-07-14T15:01:01Z","type":"incident","subject":"LOG4J Config Docker","raw_subject":"LOG4J Config Docker","description":"Hi Justin, \r\n\r\nPlease see config below, we were unable to get this working today, \r\n\r\nKR, \r\n\r\nBen\r\n\r\n \r\ncore@ip-10-16-9-42 ~ $ sudo cat /opt/instance.env\r\nKAFKA_JMX_OPTS=-javaagent:/etc/jmx/jmx_prometheus_javaagent-0.8.jar=9998:/etc/jmx/kafka_jmx_config.yaml -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.local.only=false -Djava.rmi.server.hostname=127.0.0.1\r\nZOOKEEPER_CLIENT_PORT=2181\r\nZOOKEEPER_DEBUG=1\r\nZOOKEEPER_INIT_LIMIT=10\r\nZOOKEEPER_SERVERS=zookeeper00.kafkauat.uat.aws.ad.zopa.com:2888:3888;zookeeper01.kafkauat.uat.aws.ad.zopa.com:2888:3888;zookeeper02.kafkauat.uat.aws.ad.zopa.com:2888:3888;zookeeper03.kafkauat.uat.aws.ad.zopa.com:2888:3888;zookeeper04.kafkauat.uat.aws.ad.zopa.com:2888:3888\r\nZOOKEEPER_SYNC_LIMIT=5\r\nZOOKEEPER_TICK_TIME=2000\r\nKAFKA_LOG4J_OPTS=\"-Dlog4j.configuration=file:/opt/kafka-config/zklog4j.properties\"\r\ncluster_name=kafkauat\r\ndocker_image=confluentinc/cp-zookeeper:3.2.0\r\ndocker_registry_base=dockerhub.packages.dns.ad.zopa.com:5000\r\nsplunk_index=kafkauat\r\ncomponent_name=zookeeper\r\ncluster_name=kafkauat\r\nenvironment=uat\r\ncore@ip-10-16-9-42 ~ $\r\n\r\n\r\n\r\n-----------------------\r\n\r\n\r\ncore@ip-10-16-9-42 ~ $ sudo cat /opt/kafka-config/zklog4j.properties\r\n#logging settings for zk\r\nlog4j.rootlogger=INFO,zkAppender\r\n\r\nlog4j.appender.zkAppender=org.apache.log4j.DailyRollingFileAppender\r\nlog4j.appender.zkAppender.DatePattern='.'yyyy-MM-dd-HH\r\nlog4j.appender.zkAppender.File=/var/lib/zookeeper/zkserver.log\r\nlog4j.appender.zkAppender.layout=org.apache.log4j.PatternLayout\r\nlog4j.appender.zkAppender.layout.ConversionPattern=[%%d] %p %m (%c)%n\r\ncore@ip-10-16-9-42 ~ $\r\n\r\n\r\n____________________\r\n\r\ncore@ip-10-16-9-42 ~ $ sudo cat /etc/systemd/system/zookeeper.service\r\n[Unit]\r\nDescription=zookeeper container\r\nRequires=docker.service smilodon.service opt-ebs.mount\r\n\r\n[Service]\r\nTimeoutSec=1m\r\nRestart=always\r\nRestartSec=30s\r\n\r\nEnvironmentFile=/run/smilodon/environment\r\nEnvironmentFile=/opt/instance.env\r\n\r\nLimitNOFILE=100000\r\nLimitNPROC=1048576\r\nExecStartPre=-/usr/bin/docker rm zookeeper\r\nExecStartPre=/usr/bin/docker pull ${docker_registry_base}/${docker_image}\r\nExecStartPre=/usr/bin/bash -c \"echo ZOOKEEPER_SERVER_ID=$(echo $${NODE_ID} | grep -P '\\d+$' -o) > /run/zookeeper_server_id.env\"\r\n\r\nExecStart=/usr/bin/docker run \\\r\n  --name zookeeper \\\r\n  --label app=\"zookeeper\" \\\r\n  --label node=${NODE_ID} \\\r\n  --log-opt labels=app,node \\\r\n  --ulimit nofile=100000:100000 \\\r\n  -v /opt/kafka-config:/opt/kafka-config \\\r\n  -v /opt/jmx:/etc/jmx \\\r\n  -v /opt/ebs/zookeeper:/var/lib/zookeeper \\\r\n  --env-file /run/zookeeper_server_id.env \\\r\n  --env-file /opt/instance.env \\\r\n  --network host -p \"9999:9999\" -p \"9998:9998\" \\\r\n  ${docker_registry_base}/${docker_image}\r\n\r\nExecStop=/usr/bin/docker stop -t 60 zookeeper\r\n\r\n[Install]\r\nWantedBy=multi-user.target\r\ncore@ip-10-16-9-42 ~ $\r\n","priority":null,"status":"solved","recipient":null,"requester_id":20513997487,"submitter_id":20513997487,"assignee_id":13678049447,"organization_id":14302137927,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["broker__tools_scripts","centos_7","configuration_issue","confluent__3_2_0","europe","jdk_1_8","multiple","p2_issue","platinum","summarized"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"broker__tools_scripts"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"9597"},{"id":34347728,"value":"89"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"broker__tools_scripts"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"9597"},{"id":34347728,"value":"89"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1887.json","id":1887,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-06T14:00:52Z","updated_at":"2017-07-14T21:01:04Z","type":"incident","subject":"Installation Issues","raw_subject":"Installation Issues","description":"Hi Sylvain,\n\nPer our email conversation, I'm opening up this support case so we can follow up on the issues you're having.  Once you get logged into the portal, can you please provide us with an overview of the problem?\n\nThanks,\nSam","priority":null,"status":"solved","recipient":null,"requester_id":6021477203,"submitter_id":3324019678,"assignee_id":5930716698,"organization_id":6606900206,"group_id":29623388,"collaborator_ids":[6021510663,6028646246,3324019678],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["broker","confluent__3_2_2","development","jdk_1_8","non_technical_request","p3_issue","summarized"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":""},{"id":33020448,"value":"broker"},{"id":47641647,"value":"non_technical_request"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"1092"},{"id":34347728,"value":"59"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":""},{"id":33020448,"value":"broker"},{"id":47641647,"value":"non_technical_request"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"1092"},{"id":34347728,"value":"59"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1886.json","id":1886,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-06T11:06:41Z","updated_at":"2017-07-14T08:02:50Z","type":"incident","subject":"Kafka ACLs for SchemaRegistry and C3","raw_subject":"Kafka ACLs for SchemaRegistry and C3","description":"Hello,\r\nwe plan to enable authorization on all cluster topics, including topics used internally by SchemaRegistry (_schemas) and C3 (__confluent.support.metrics, _confluent-command, _confluent-metrics, _confluent-monitoring and _confluent-controlcenter*).\r\n\r\nFor SchemaRegistry I assume that SchemaRegistry principal should have consumer and producer rights for _schemas topic and it works properly. Should kafka broker principal be also entered as consumer for _schemas or the services communicate using API only?\r\n\r\nFor C3 I used control-center-set-acls (as described in http://docs.confluent.io/current/control-center/docs/security.html#kafka) for C3 principal, but the service cannot start anymore. During startup I see on stdout/stderr:\r\n--------\r\nException in thread \"StreamThread-1\" org.apache.kafka.common.errors.GroupAuthorizationException: Not authorized to access group: _confluent-controlcenter-3-2-1-3-command\r\n--------\r\nAnd in logs a lot of:\r\n---------\r\n[2017-07-06 10:38:46,047] INFO unable to get command store (io.confluent.command\r\n.CommandStore:86)\r\norg.apache.kafka.streams.errors.InvalidStateStoreException: the state store, com\r\nmander, may have migrated to another instance.\r\n        at org.apache.kafka.streams.state.internals.StreamThreadStateStoreProvid\r\ner.stores(StreamThreadStateStoreProvider.java:42)\r\n        at org.apache.kafka.streams.state.internals.QueryableStoreProvider.getSt\r\nore(QueryableStoreProvider.java:55)\r\n        at org.apache.kafka.streams.KafkaStreams.store(KafkaStreams.java:709)\r\n        at io.confluent.command.CommandStore.getStore(CommandStore.java:141)\r\n        at io.confluent.command.CommandStore.start(CommandStore.java:84)\r\n        at io.confluent.controlcenter.ControlCenter.main(ControlCenter.java:117)\r\n---------\r\n\r\nWhen I go through logs of control-center-set-acls tools I don't see setting any ACLs on the _confluent-controlcenter-3-2-1-3-command topic. Could you please provide fixed version of the acl script or maybe list of additionals ACLs to set?\r\n\r\nKind regards,\r\nMariusz Strzelecki","priority":null,"status":"solved","recipient":null,"requester_id":5979417006,"submitter_id":5979417006,"assignee_id":13678049447,"organization_id":6312218263,"group_id":29623388,"collaborator_ids":[17825563008],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","configuration_issue","confluent__3_2_1","development","enterprise","europe","gold","jdk_1_8","kai_waehner","p3_issue","security","summarized"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"security"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"8570"},{"id":34347728,"value":"120"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"good","id":1741812583,"comment":null,"reason":"No reason provided","reason_id":332227},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"security"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"8570"},{"id":34347728,"value":"120"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1882.json","id":1882,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-05T21:22:47Z","updated_at":"2017-07-14T00:01:02Z","type":"incident","subject":"Topic Names with Special Characters","raw_subject":"Topic Names with Special Characters","description":"\r\nThe Kafka documentation states that dots, dashes, and underscores are valid special characters for topic names.   Are there any known issues with mixing and matching all three in the same topic name?  \r\n\r\nA quick search online indicates that at some time in the past, metric gathering could have name collisions when there is a mix of some of these special characters.   Is this still an issue we should be concerned about?","priority":null,"status":"solved","recipient":null,"requester_id":5711987303,"submitter_id":5711987303,"assignee_id":5699232346,"organization_id":16959616467,"group_id":29623388,"collaborator_ids":[5717919786,22473596987],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["confluent__3_2_0","documentation_issue","general_question","gold","jdk_1_7","jeremy_custenborder","multiple","p3_issue","rhel_7","summarized","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":"jdk_1_7"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"general_question"},{"id":47641647,"value":"documentation_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"2295"},{"id":34347728,"value":"150"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":"jdk_1_7"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"general_question"},{"id":47641647,"value":"documentation_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"2295"},{"id":34347728,"value":"150"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1881.json","id":1881,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-05T20:16:35Z","updated_at":"2017-07-13T21:01:04Z","type":"incident","subject":"Creating and Connecting with Keytab","raw_subject":"Creating and Connecting with Keytab","description":"We have gone through the initial steps and connected using the Confluent Cloud CLI and are now wanting to connect and use Kafka in our applications. We are primarily a Ruby company and are looking at this Gem: https://github.com/zendesk/ruby-kafka\r\n\r\nThere is a section on Authentication using SASL and they instantiate a Kafka client with a Principal and Keytab: \r\n```\r\nkafka = Kafka.new(\r\n  sasl_gssapi_principal: 'kafka/kafka.example.com@EXAMPLE.COM',\r\n  sasl_gssapi_keytab: '/etc/keytabs/kafka.keytab',\r\n  # ...\r\n)\r\n```\r\n\r\nAny suggestions on what the Principal should be and generating the Keytab would be great!\r\nWe are hosting Kafka through you so just selected CentOS7 as the OS/version below.","priority":null,"status":"solved","recipient":null,"requester_id":5922446483,"submitter_id":5922446483,"assignee_id":21324568227,"organization_id":6011151106,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["ccloud","centos_7","configuration_issue","confluent__3_2_1","development","jdk_1_8","p3_issue","summarized"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"ccloud"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"1861"},{"id":34347728,"value":"170"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"ccloud"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"1861"},{"id":34347728,"value":"170"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1879.json","id":1879,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-05T19:21:33Z","updated_at":"2017-07-13T14:13:37Z","type":"incident","subject":"unable to view data streams graph in c3 through distributed source/sink connectors","raw_subject":"unable to view data streams graph in c3 through distributed source/sink connectors","description":"We have been configured JDBC Source Connector successfully but we couldn't see incoming/outgoing msg flow through c3 - data streams monitoring graphs. \r\nBut When we ran simple kafka producer/consumer we can see data stream graph results in c3 console successfully.\r\n\r\nRequest you review attached distributed connector configuration file and let me know if any connector interceptor configurations are missed.\r\n\r\n\r\nThis ticket includes a secure attachment. Use this link to access the attached files:\r\n https://confluent.sendsafely.com/receive/?thread=SMLZ-0CGS&packageCode=k27JXndtlMWJnBNEfSL_t07e071WpSEevJpmQjW2bXM#keyCode=os7RS1XHasLQi6rSaB5akX8q0LivqrRO3i3dYDefpww","priority":null,"status":"pending","recipient":null,"requester_id":18368692907,"submitter_id":18368692907,"assignee_id":13678049447,"organization_id":14045283907,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_6","confluent__3_2_0","confluent_control_center","gold","jdk_1_8","p3_issue","production","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_6"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"824"},{"id":34347728,"value":"37"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_6"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"824"},{"id":34347728,"value":"37"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1878.json","id":1878,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-05T18:47:39Z","updated_at":"2017-07-14T01:01:03Z","type":"incident","subject":"topic offset without supplying consumer group name","raw_subject":"topic offset without supplying consumer group name","description":"We are looking for  a command utility or REST API to get the latest offset of a particular topic without supplying consumer group name.\r\n\r\ni.e, we don't want to run kafka-console-consumer command to view topic offsets.\r\n\r\nPlease share the details ..","priority":null,"status":"solved","recipient":null,"requester_id":18368692907,"submitter_id":18368692907,"assignee_id":5699232346,"organization_id":14045283907,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["broker__tools_scripts","bug","centos_6","confluent__3_2_0","gold","jdk_1_8","p3_issue","staging","summarized","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_6"},{"id":33020448,"value":"broker__tools_scripts"},{"id":47641647,"value":"bug"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"staging"},{"id":77414608,"value":null},{"id":34347708,"value":"3549"},{"id":34347728,"value":"194"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_6"},{"id":33020448,"value":"broker__tools_scripts"},{"id":47641647,"value":"bug"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"staging"},{"id":77414608,"value":null},{"id":34347708,"value":"3549"},{"id":34347728,"value":"194"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1877.json","id":1877,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-05T18:41:19Z","updated_at":"2017-07-11T23:06:40Z","type":"incident","subject":"Kafka Streams processes die when leader for topic is unavailable","raw_subject":"Kafka Streams processes die when leader for topic is unavailable","description":"We have encountered an issue multiple times where Kafka Streams processes will die if they can't write to a topic leader. \r\nIs this expected behavior or are there any configs that can be adjusted to try and mitigate this?\r\n\r\nAttached is the log from a Kafka Streams job when it failed.\r\n\r\nThis ticket includes a secure attachment. Use this link to access the attached files:\r\n https://confluent.sendsafely.com/receive/?thread=887D-7D8Z&packageCode=fWbFFTnKJ81fYf0WFKnQ6XPsb3Od7eHu7aN_N2OPJPA#keyCode=-xgx-huy0j1Sq88go-JdPBOt2UKOYu3aefp3nJQJ2nY","priority":null,"status":"pending","recipient":null,"requester_id":12495406047,"submitter_id":12495406047,"assignee_id":5699232346,"organization_id":10848328548,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","confluent__3_2_1","gold","jdk_1_8","kafka_streams","p3_issue","production","streams_escalated","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"kafka_streams"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"8649"},{"id":34347728,"value":"3327"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"kafka_streams"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"8649"},{"id":34347728,"value":"3327"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1873.json","id":1873,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-05T16:12:32Z","updated_at":"2017-07-16T01:01:03Z","type":"incident","subject":"Log-end offset decreased for some partitions","raw_subject":"Log-end offset decreased for some partitions","description":"We have a Kafka Streams application where the latest consumer offset suddenly decreased for some partitions. For instance, for one of the partitions, the offset decreased from ~2.56 billion to ~2.34 billion, and there was this log message:\r\n\r\n2017-06-28 22:37:44 [INFO] Fetcher:714 - Fetch offset 2561028661 is out of range for partition users.behaviors.CustomEvent-5, resetting offset\r\n\r\nIt seems like a possible explanation is that the broker lost some data or wasn't in sync for that topic-partition. As a result, the latest consumer offset was \"out of range\" because it was too large, and so the consumer reset its offset back to the beginning (since we have auto.offset.reset=earliest).\r\n\r\nI couldn't find anything in the broker logs from around that time indicating anything that might lead to data loss (under-replicated partitions, elections, etc.). Is this a broker problem? At the time, we were also running the Confluent data rebalancer, so it seems possible that this was caused by partitions moving between brokers.","priority":null,"status":"solved","recipient":null,"requester_id":17092335008,"submitter_id":17092335008,"assignee_id":5930716698,"organization_id":14109642148,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["broker","chris_matta","configuration_issue","confluent__3_1_2","gold","jdk_1_8","p2_issue","production","summarized","ubuntu_14_04_lts","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_1_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"ubuntu_14_04_lts"},{"id":33020448,"value":"broker"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"3531"},{"id":34347728,"value":"166"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_1_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"ubuntu_14_04_lts"},{"id":33020448,"value":"broker"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"3531"},{"id":34347728,"value":"166"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1871.json","id":1871,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-05T13:27:21Z","updated_at":"2017-07-15T05:33:51Z","type":"incident","subject":"Confluent Control Center Data Streams is not working","raw_subject":"Confluent Control Center Data Streams is not working","description":"we have configured the Control Center and it is showing all the information about system health and Kafka Connects. For some reason, it is not showing the Data Streams. we are going to Production this weekend and it is very important for us to have Data Streams working for us.\r\n\r\nPlease advise.\r\n\r\nThanks-\r\nSiva Nagisetty,\r\n\r\nThis ticket includes a secure attachment. Use this link to access the attached files:\r\n https://confluent.sendsafely.com/receive/?thread=2ZGK-PC3E&packageCode=4Q46LodbaNiUL-oP0RegsQikT9klbRhhmGL29wAiPnY#keyCode=nWdBlPGFS10QKVzXeG7p_xGLJFNcA5sT3AELsM8C4Rs","priority":null,"status":"solved","recipient":null,"requester_id":5991633766,"submitter_id":5991633766,"assignee_id":5930716698,"organization_id":6328931306,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","configuration_issue","confluent__3_2_2","confluent_control_center","development","enterprise","gold","jdk_1_8","jeremy_custenborder","p2_issue","summarized","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"5534"},{"id":34347728,"value":"201"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"good","id":1753370006,"comment":null,"reason":"No reason provided","reason_id":332227},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"5534"},{"id":34347728,"value":"201"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1865.json","id":1865,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-04T14:04:22Z","updated_at":"2017-07-05T15:34:57Z","type":"incident","subject":"Request timeouts coming from librdkafka","raw_subject":"Request timeouts coming from librdkafka","description":"Hi,\r\n\r\nI already implemented a change recommended in a previous ticket where we would \"rebrand\" a certain type of error as INFO. Basically, we check with the following regex all errors and change their severity to INFO if they match:\r\n\r\n\"^.*: Receive failed: Disconnected.*$\"\r\n\r\nThis has reduced the level of noise in the logs, which is good. However, we still a few errors like the following, per hour:\r\n\r\nError | Local | Error Local_MsgTimedOut - ssl://10.30.9.112:9092/1001: 1 request(s) timed out: disconnect\r\n\r\nI've attached logs before and after the time this error occurred the last time (2017-07-04 11:21:43.349)\r\n\r\nBy the way, this is in our microservice using dotnet-confluent and librdkafka.\r\n\r\nThanks.\r\n\r\nThis ticket includes a secure attachment. Use this link to access the attached files:\r\n https://confluent.sendsafely.com/receive/?thread=3CA3-L4EV&packageCode=vx2Gz98l4i964YmidAW9cczUTtUaogaaCSuIsh8M6jk#keyCode=2KtTYgStVWPNMYW9hovY1a_XJaSWE8YnpncFBx7Vgws","priority":null,"status":"pending","recipient":null,"requester_id":22293456287,"submitter_id":22293456287,"assignee_id":13678049447,"organization_id":14302137927,"group_id":29623388,"collaborator_ids":[20774761647],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","client__c_","confluent__3_2_1","development","europe","jdk_1_8","p3_issue","platinum"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"client__c_"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"3715"},{"id":34347728,"value":"3"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"client__c_"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"3715"},{"id":34347728,"value":"3"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1821.json","id":1821,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-06-28T04:28:37Z","updated_at":"2017-07-14T23:53:23Z","type":"incident","subject":"kafka Brokers are getting down every now and then with Below errors","raw_subject":"kafka Brokers are getting down every now and then with Below errors","description":"Our QC and Prod Kafka Brokers Servers are getting down with Below errors :\r\n\r\nCan you Please check and help us in fixing this issue permamnently ?\r\n\r\nEverytime we need to restart the broker server to fix the issue \r\n\r\nAtttaced are the logs from broker Server \r\n\r\n[2017-06-27 23:19:41,137] WARN [ReplicaFetcherThread-0-1], Error in fetch kafka.server.ReplicaFetcherThread$FetchRequest@4bb8b7d1 (kafka.server.ReplicaFetcherThread)\r\njava.net.SocketTimeoutException: Failed to connect within 30000 ms\r\n        at kafka.server.ReplicaFetcherThread.sendRequest(ReplicaFetcherThread.scala:249)\r\n        at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:238)\r\n        at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:42)\r\n        at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:118)\r\n        at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:103)\r\n        at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)\r\n[2017-06-27 23:20:13,144] WARN [ReplicaFetcherThread-0-1], Error in fetch kafka.server.ReplicaFetcherThread$FetchRequest@2bd41124 (kafka.server.ReplicaFetcherThread)\r\njava.net.SocketTimeoutException: Failed to connect within 30000 ms\r\n        at kafka.server.ReplicaFetcherThread.sendRequest(ReplicaFetcherThread.scala:249)\r\n        at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:238)\r\n        at kafka.server.ReplicaFetcherThread.fetch(ReplicaFetcherThread.scala:42)\r\n        at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:118)\r\n        at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:103)\r\n        at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:63)","priority":null,"status":"pending","recipient":null,"requester_id":18100431827,"submitter_id":18100431827,"assignee_id":5930716698,"organization_id":14099815888,"group_id":29623388,"collaborator_ids":[18100485847,5733100823,18181306768,18181061128],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["broker","bug","cc_added_here","confluent__3_1_2","gold","jdk_1_8","jira_escalated","p2_issue","production","rhel_7","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_1_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"broker"},{"id":47641647,"value":"bug"},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"22361"},{"id":34347728,"value":"62"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_1_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"broker"},{"id":47641647,"value":"bug"},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"22361"},{"id":34347728,"value":"62"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1816.json","id":1816,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-06-27T16:36:07Z","updated_at":"2017-07-12T17:02:21Z","type":"incident","subject":"Streams applications appear to be bursting messages and then stalling completely","raw_subject":"Streams applications appear to be bursting messages and then stalling completely","description":"Hi Ben  and Steven,\n\nI have created this new ticket for the Streams Application issue we are seeing. \n\nI just received the logs from Ben from the Brokers.\n\nSteven if you can send me the logs from the application side, I will have the Streams team review and see if we can come up with what is happening.\n\nAs stated, we may want to look into a session with the Streams team directly depending on what this logging tells us.\n\nThanks again for your patience guys!  Really appreciate it!","priority":null,"status":"pending","recipient":null,"requester_id":20513997487,"submitter_id":13678049447,"assignee_id":13678049447,"organization_id":14302137927,"group_id":29623388,"collaborator_ids":[19547059967],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_6","confluent__3_2_1","europe","jdk_1_8","jira_escalated","kafka_streams","multiple","p2_issue","platinum","streams_escalated"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_6"},{"id":33020448,"value":"kafka_streams"},{"id":47641647,"value":""},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"11084"},{"id":34347728,"value":"121"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_6"},{"id":33020448,"value":"kafka_streams"},{"id":47641647,"value":""},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"11084"},{"id":34347728,"value":"121"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1815.json","id":1815,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-06-27T13:59:49Z","updated_at":"2017-07-13T14:16:48Z","type":"incident","subject":"Authentication and authorization for C3","raw_subject":"Authentication and authorization for C3","description":"We will need to restrict access to the C3 console to the handful of users and we are curious of what options did Confluent foresee/envision for this?","priority":null,"status":"pending","recipient":null,"requester_id":17825563008,"submitter_id":17825563008,"assignee_id":13678049447,"organization_id":6312218263,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","confluent__3_2_1","confluent_control_center","jdk_1_8","multiple","p3_issue"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"873"},{"id":34347728,"value":"16"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"873"},{"id":34347728,"value":"16"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1813.json","id":1813,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-06-27T11:26:08Z","updated_at":"2017-07-07T11:28:53Z","type":"incident","subject":"SCRAM documentaion","raw_subject":"SCRAM documentaion","description":"I understand that SCRAM is now supported within the Confluent Kafka environment, however I have been unable to find the documentation which describes how Kafka (and zookeeper) should be configured to use SCRAM.\r\n\r\nPlease provide details of the documentation.\r\n\r\nPLEASE NOTE we are using confluent 3.2.2 (your pick list of versions on this page does not list that version).\r\n\r\nThanks\r\nIan","priority":null,"status":"hold","recipient":null,"requester_id":10713580267,"submitter_id":10713580267,"assignee_id":13678049447,"organization_id":2603470857,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","confluent__3_2_2","europe","gold","jdk_1_8","multiple","p3_issue","security"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"security"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"7803"},{"id":34347728,"value":"11"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"security"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"7803"},{"id":34347728,"value":"11"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1656.json","id":1656,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-06-09T14:47:45Z","updated_at":"2017-07-15T00:30:24Z","type":"incident","subject":"Control Center not responding","raw_subject":"Control Center not responding","description":"Hi ,\r\n\r\nFrom last few week we are facing many issue with Control Center.\r\nEither it goes down and doesn't respond normal.\r\n\r\nCurrently our control center in Dev env is not responding.\r\nEven after restart it throwing below error and exception.\r\nI have turned on DEBUG log for control center.\r\nAttaching complete log for your reference.\r\n\r\n[2017-06-09 09:38:12,408] DEBUG shutdown already commenced (org.eclipse.jetty.util.thread.ShutdownThread:83)\r\n[2017-06-09 09:38:12,408] WARN FAILED io.confluent.rest.Application$1@15fdd1f2: java.util.concurrent.TimeoutException (org.eclipse.jetty.util.component.AbstractLifeCycle:212)\r\njava.util.concurrent.TimeoutException\r\n\tat org.eclipse.jetty.util.FutureCallback.get(FutureCallback.java:128)\r\n\tat org.eclipse.jetty.util.FutureCallback.get(FutureCallback.java:30)\r\n\tat org.eclipse.jetty.server.Server.doStop(Server.java:426)\r\n\tat io.confluent.rest.Application$1.doStop(Application.java:158)\r\n\tat org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:89)\r\n\tat org.eclipse.jetty.util.thread.ShutdownThread.run(ShutdownThread.java:138)\r\n[2017-06-09 09:38:12,409] DEBUG  (org.eclipse.jetty.util.thread.ShutdownThread:150)\r\njava.util.concurrent.TimeoutException\r\n\tat org.eclipse.jetty.util.FutureCallback.get(FutureCallback.java:128)\r\n\tat org.eclipse.jetty.util.FutureCallback.get(FutureCallback.java:30)\r\n\r\nThanks,\r\nChandan","priority":null,"status":"open","recipient":null,"requester_id":17349031828,"submitter_id":17349031828,"assignee_id":21324568227,"organization_id":14020674447,"group_id":29623388,"collaborator_ids":[16668887327,16689202308,17426700748,19850841687,3324019678,21324568227,13186800408],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["confluent__3_2_1","confluent_control_center","development","gold","jdk_1_8","jira_escalated","p3_issue","rhel_7","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"13089"},{"id":34347728,"value":"99"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"13089"},{"id":34347728,"value":"99"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1642.json","id":1642,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-06-08T09:18:59Z","updated_at":"2017-07-06T06:59:23Z","type":"incident","subject":"Improved performance of 10MB messages","raw_subject":"Improved performance of 10MB messages","description":"Hi,\r\n\r\nWe were told that the performance of handling messages up to 10MB was improved. We have conducted some tests, but unfortunately the results are not showing any improvement.\r\n\r\nWe compared versions 0.10.2.1 and 0.10.0.1. The tests were performed on a single Kafka instance with a topic containing 1 partition and obviously replication factor set to 1. I have put server configuration in the attachments.\r\n\r\nThis is the command that was run for testing producer performance:\r\n./bin/kafka-producer-perf-test.sh --num-records 1000 --record-size 10485560 --throughput 1000000000 \\\r\n--topic emb_test --producer-props bootstrap.servers=localhost:9093 \\\r\nacks=all security.protocol=SSL ssl.truststore.location=/kafka/config/servercerts/trust.jks \\\r\nssl.truststore.password=emb123 ssl.keystore.location=/kafka/config/servercerts/server.jks \\\r\nssl.keystore.password=emb123 ssl.key.password=emb123 max.request.size=10485760\r\n\r\n...and here were the results:\r\n0.10.0.1\r\n1000 records sent, 1.340233 records/sec (13.40 MB/sec), 2934.21 ms avg latency, 6382.00 ms max latency, 2746 ms 50th, 4343 ms 95th, 5496 ms 99th, 6382 ms 99.9th.\r\n0.10.2.1\r\n1000 records sent, 1.071158 records/sec (10.71 MB/sec), 3670.70 ms avg latency, 12760.00 ms max latency, 3054 ms 50th, 6264 ms 95th, 9800 ms 99th, 12760 ms 99.9th.\r\n\r\nPerformance degradated slighly and it should not matter, but we have expected a better result.\r\n\r\nWe also tried running performance tests for the consumer:\r\nprintf \"security.protocol=SSL\\n\\\r\nssl.truststore.location=/kafka/config/servercerts/trust.jks\\n\\\r\nssl.truststore.password=emb123\\n\\\r\nssl.keystore.location=/kafka/config/servercerts/server.jks\\n\\\r\nssl.keystore.password=emb123\\n\\\r\nssl.key.password=emb123\\n\\\r\nmax.partition.fetch.bytes=10485760\\n\" > consumer-perf-config.properties\r\n\r\n./bin/kafka-consumer-perf-test.sh --messages 1000 --message-size 10485560 --topic emb_test \\\r\n--group emb_test_group --broker-list localhost:9093 --new-consumer \\\r\n--consumer.config consumer-perf-config.properties --fetch-size 10485760\r\n\r\nUnfortunately the test tool displayed some unreliable results, e.g.:\r\nstart.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec\r\n2017-06-08 10:43:39:952, 2017-06-08 10:43:49:806, 69.9987, 7.1036, 7, 0.7104\r\n\r\nIt looks like only 7 messages were read and the test completes sooner that it should.\r\n\r\nI assume we are missing something in our configuration, which causes poor performance and missing messages in the consumer performance tool. Any tips?","priority":null,"status":"open","recipient":null,"requester_id":11172175927,"submitter_id":11172175927,"assignee_id":5699232346,"organization_id":2798102687,"group_id":29623388,"collaborator_ids":[5780723263,6009169018,822936898,8327796688,5907439417,21324568227,5785958626,21100642187,3324019678],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["apache_kafka__0_10_2_0","centos_7","development","europe","gold","jdk_1_8","p3_issue","producer"],"custom_fields":[{"id":24843497,"value":"apache_kafka__0_10_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"producer"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"21289"},{"id":34347728,"value":"148"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"apache_kafka__0_10_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"producer"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"21289"},{"id":34347728,"value":"148"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1800.json","id":1800,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-06-23T20:57:52Z","updated_at":"2017-07-15T07:01:01Z","type":"incident","subject":"Connect WARNINGS after upgrade from 3.1.2 to 3.2.1","raw_subject":"Connect WARNINGS after upgrade from 3.1.2 to 3.2.1","description":"Hello, we've recently upgrade our connect machines from confluent 3.1.2 to 3.2.1, and we're seeing a large spam of WARNINGs like this on one of the machines, and I was wondering what can be done to resolve them:\r\n\r\nJun 23 16:16:11 connect-a-001.production-east-1.appboy.com kafka-connect.log: 2017-06-23 20:16:11 [WARN] WorkerSinkTask:337 - Ignoring invalid task provided offset dataexport.Amplitude.all-7/OffsetAndMetadata{offset=3227261, metadata=''} -- partition not assigned\r\nJun 23 16:16:11 connect-a-001.production-east-1.appboy.com kafka-connect.log: 2017-06-23 20:16:11 [WARN] WorkerSinkTask:337 - Ignoring invalid task provided offset dataexport.Amplitude.all-6/OffsetAndMetadata{offset=215046, metadata=''} -- partition not assigned\r\nJun 23 16:16:11 connect-a-001.production-east-1.appboy.com kafka-connect.log: 2017-06-23 20:16:11 [WARN] WorkerSinkTask:337 - Ignoring invalid task provided offset dataexport.Amplitude.all-7/OffsetAndMetadata{offset=3227264, metadata=''} -- partition not assigned\r\nJun 23 16:16:11 connect-a-001.production-east-1.appboy.com kafka-connect.log: 2017-06-23 20:16:11 [WARN] WorkerSinkTask:337 - Ignoring invalid task provided offset dataexport.Amplitude.all-6/OffsetAndMetadata{offset=215046, metadata=''} -- partition not assigned\r\nJun 23 16:16:12 connect-a-001.production-east-1.appboy.com kafka-connect.log: 2017-06-23 20:16:12 [WARN] WorkerSinkTask:337 - Ignoring invalid task provided offset dataexport.Amplitude.all-7/OffsetAndMetadata{offset=3227265, metadata=''} -- partition not assigned\r\nJun 23 16:16:12 connect-a-001.production-east-1.appboy.com kafka-connect.log: 2017-06-23 20:16:12 [WARN] WorkerSinkTask:337 - Ignoring invalid task provided offset dataexport.Amplitude.all-6/OffsetAndMetadata{offset=215046, metadata=''} -- partition not assigned\r\nJun 23 16:16:12 connect-a-001.production-east-1.appboy.com kafka-connect.log: 2017-06-23 20:16:12 [WARN] WorkerSinkTask:337 - Ignoring invalid task provided offset dataexport.Amplitude.all-7/OffsetAndMetadata{offset=3227265, metadata=''} -- partition not assigned\r\nJun 23 16:16:12 connect-a-001.production-east-1.appboy.com kafka-connect.log: 2017-06-23 20:16:12 [WARN] WorkerSinkTask:337 - Ignoring invalid task provided offset dataexport.Amplitude.all-6/OffsetAndMetadata{offset=215050, metadata=''} -- partition not assigned","priority":null,"status":"solved","recipient":null,"requester_id":19981454047,"submitter_id":19981454047,"assignee_id":21324568227,"organization_id":14109642148,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["chris_matta","configuration_issue","confluent__3_2_1","gold","jdk_1_8","kafka_connect","p2_issue","production","summarized","ubuntu_14_04_lts","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"ubuntu_14_04_lts"},{"id":33020448,"value":"kafka_connect"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"12598"},{"id":34347728,"value":"71"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"ubuntu_14_04_lts"},{"id":33020448,"value":"kafka_connect"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"12598"},{"id":34347728,"value":"71"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1779.json","id":1779,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-06-22T19:35:45Z","updated_at":"2017-07-12T23:36:07Z","type":"incident","subject":"Kafka connector and Elasticsearch ingest pipeline","raw_subject":"Kafka connector and Elasticsearch ingest pipeline","description":"I am trying to setup connect to use ingest pipeline(https://www.elastic.co/guide/en/elasticsearch/reference/master/ingest.html).  Is there config format I will need to follow to support ingesting via connect?\r\n\r\nMy connect config:\r\n{\r\n    \"name\": \"salesforce_elf_elasticsearch_sink\",\r\n    \"config\": {\r\n        \"connector.class\": \"io.confluent.connect.elasticsearch.ElasticsearchSinkConnector\",\r\n        \"type.name\": \"true\",\r\n        \"transforms.MessageTypeRouter.type\": \"org.apache.kafka.connect.transforms.RegexRouter\",\r\n        \"transforms.TimestampRouter.timestamp.format\": \"yyyy.MM.dd\",\r\n        \"tasks.max\": \"1\",\r\n        \"topics\": \"sit-salesforce-logs-json\",\r\n        \"transforms\": \"MessageTypeRouter, TimestampRouter\",\r\n        \"key.ignore\": \"true\",\r\n        \"schema.ignore\": \"true\",\r\n        \"transforms.TimestampRouter.topic.format\": \"${topic}-${timestamp}\",\r\n        \"flush.timeout.ms\": \"30000\",\r\n        \"transforms.MessageTypeRouter.replacement\": \"salesforce-elf\",\r\n        \"name\": \"salesforce_elf_elasticsearch_sink\",\r\n        \"transforms.TimestampRouter.type\": \"org.apache.kafka.connect.transforms.TimestampRouter\",\r\n        \"connection.url\": \"http://elasticsearch-rtoi.dit.etrade.com:9200/_ingest/pipeline/message_json_m\",\r\n        \"transforms.MessageTypeRouter.regex\": \"^\\\\w{3,4}-salesforce-logs-json\"\r\n    }\r\n}","priority":null,"status":"pending","recipient":null,"requester_id":21163439167,"submitter_id":21163439167,"assignee_id":5699232346,"organization_id":15862541148,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","confluent__3_2_1","development","gold","jdk_1_8","jira_escalated","kafka_connect__elasticsearch_connector","p3_issue","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"kafka_connect__elasticsearch_connector"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"8874"},{"id":34347728,"value":"38"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"kafka_connect__elasticsearch_connector"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"8874"},{"id":34347728,"value":"38"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1773.json","id":1773,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-06-22T09:33:09Z","updated_at":"2017-07-13T14:27:26Z","type":"incident","subject":"Kafka connect Rebalancing","raw_subject":"Kafka connect Rebalancing","description":"Hi there, \r\n\r\nWe have a few dev's now who are using Kafka connect to create connections,and to create and retrieve messages from Kafka. \r\n\r\nThe issue they seem to be consistently hitting is as follows. \r\n\r\n1 - user sends request to create connector. \r\n\r\n2 - Error: the Kafka Connect API returned: Cannot complete request because of a conflicting operation (e.g. worker rebalance) (409)\r\n\r\n3 - user repeats for up to 15 minutes. \r\n\r\n4- without warning the message succeeds. \r\n\r\nIs there a better way to go about this? this could take 10/15 minutes before any app can start up, if we had a backlog of requests to process, and a time limit on any re-balancing session, we could pass in the request and be reasonably sure that it will create the connector within a few minutes. ","priority":null,"status":"pending","recipient":null,"requester_id":20513997487,"submitter_id":20513997487,"assignee_id":13678049447,"organization_id":14302137927,"group_id":29623388,"collaborator_ids":[21095585667],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","confluent__3_2_1","europe","jdk_1_8","jira_escalated","kafka_connect","multiple","p3_issue","platinum"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"kafka_connect"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"7407"},{"id":34347728,"value":"168"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"kafka_connect"},{"id":47641647,"value":""},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"7407"},{"id":34347728,"value":"168"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1938.json","id":1938,"external_id":null,"via":{"channel":"email","source":{"from":{"address":"atulya.bhimarasetty@macys.com","name":"Atulya Bhimarasetty"},"to":{"name":"Confluent","address":"support@confluent.io"},"rel":null}},"created_at":"2017-07-11T21:42:18Z","updated_at":"2017-07-16T00:01:02Z","type":"incident","subject":"Typo In Control Center Documentation","raw_subject":"Typo In Control Center Documentation","description":"Hi Support,\nJust wanted to draw your attention to the Control Center documentation where the below step is repeated twice.\n\nconfluent.controlcenter.streams.ssl.truststore.location\n         The location of the trust store file.\n*       Type: string\n*       Default: None\n*       Importance: low\n   confluent.controlcenter.streams.ssl.truststore.location\n         The location of the trust store file.\n*       Type: string\n*       Default: None\n*       Importance: low\n\n\nAtulya B | IFS TIBCO+ | Macy's Systems and Technology\n5985 State Bridge Road  | Johns Creek, GA 30097 | 312-929-5416\n [cid:image001.png@01D2B2D6.17DD72E0]","priority":null,"status":"closed","recipient":"support@confluent.io","requester_id":21787299508,"submitter_id":21787299508,"assignee_id":13678049447,"organization_id":16542134308,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["confluent__3_2_0","documentation_issue","general_question","gold","jdk_1_8","multiple","p4_issue","rhel_6","summarized","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"general_question"},{"id":47641647,"value":"documentation_issue"},{"id":33471847,"value":"p4_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"2267"},{"id":34347728,"value":"1396"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"good","id":1738177603,"comment":null,"reason":"No reason provided","reason_id":332227},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"general_question"},{"id":47641647,"value":"documentation_issue"},{"id":33471847,"value":"p4_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"2267"},{"id":34347728,"value":"1396"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"followup_ids":[],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1934.json","id":1934,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-11T13:24:16Z","updated_at":"2017-07-15T16:01:02Z","type":"incident","subject":"safe to add partition on semantic partionned topic?","raw_subject":"safe to add partition on semantic partionned topic?","description":"Hi, \r\nWe have at PMI confluent-platform-2.11, and we have currently in production a set of topics with 6 partitions each, and using semantic partition (an alphanumeric 32 chars string) as key. We use a consumer group hosted on a single Ec2, using spring-kafka framework, with 6 threads/consumers. We need to increase partitions to many more,  to increase parallelism (i.e. 30 partitions). If we use the add partition tools on live brokers, we understand that we would not get the re partitioning of existing messages already in the the log file prior to adding partition. \r\nBut beside this impact, which we can accept, are you aware of any other risks with described configurations?  This post relates a stalling and need of restart of consumers upon adding partitions: https://stackoverflow.com/questions/36114221/is-it-safe-to-add-partition-or-broker-online-for-kafka\r\nIs this a risk you know about? Have you encountered problems with customers adding partitions that stopped or corrupted consumption of messages (post add partition). Thanks","priority":null,"status":"closed","recipient":null,"requester_id":6067782226,"submitter_id":6067782226,"assignee_id":5907439417,"organization_id":15762686747,"group_id":29623388,"collaborator_ids":[6067782226],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["confluent__3_2_0","consumer","europe","jdk_1_8","p3_issue","platinum","production","recommendation___best_practices","summarized","ubuntu_16_04_lts"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"ubuntu_16_04_lts"},{"id":33020448,"value":"consumer"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"1673"},{"id":34347728,"value":"48"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"ubuntu_16_04_lts"},{"id":33020448,"value":"consumer"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"1673"},{"id":34347728,"value":"48"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"followup_ids":[],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1933.json","id":1933,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-11T12:14:25Z","updated_at":"2017-07-15T13:01:02Z","type":"incident","subject":"enable Yves.Chophel@contracted.pmi.com to access support portal","raw_subject":"enable Yves.Chophel@contracted.pmi.com to access support portal","description":"please enable Yves.Chophel@contracted.pmi.com to access support portal and submit request","priority":null,"status":"closed","recipient":null,"requester_id":20978318847,"submitter_id":20978318847,"assignee_id":5930716698,"organization_id":15762686747,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["confluent__3_2_1","europe","general_question__account_admin","jdk_1_7","multiple","non_technical_request__account_admin","p3_issue","platinum","summarized","ubuntu_12_04_lts"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_7"},{"id":26235607,"value":"ubuntu_12_04_lts"},{"id":33020448,"value":"general_question__account_admin"},{"id":47641647,"value":"non_technical_request__account_admin"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"94"},{"id":34347728,"value":"23"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"good","id":1744136566,"comment":null,"reason":"No reason provided","reason_id":332227},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_7"},{"id":26235607,"value":"ubuntu_12_04_lts"},{"id":33020448,"value":"general_question__account_admin"},{"id":47641647,"value":"non_technical_request__account_admin"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"94"},{"id":34347728,"value":"23"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"followup_ids":[],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1768.json","id":1768,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-06-21T20:53:07Z","updated_at":"2017-07-12T16:59:11Z","type":"incident","subject":"Control Center Upgrade 3.1.2 -> 3.2.1 unable to check license ","raw_subject":"Control Center Upgrade 3.1.2 -> 3.2.1 unable to check license ","description":"After restarting control center post upgrade, it works for about a minute or two then says it is unable to check license. Nothing works after that.\r\n\r\nI tried to restart the service but it did the exact same thing.","priority":null,"status":"pending","recipient":null,"requester_id":20715096987,"submitter_id":20715096987,"assignee_id":5930716698,"organization_id":14109642148,"group_id":29623388,"collaborator_ids":[3324019678,13186800408,19850841687,21324568227,17086175628,17086180208,17086429088,17092335008,19688247508,19981454047],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["chris_matta","confluent__3_2_1","confluent_control_center","gold","jdk_1_8","jira_escalated","p1_issue","production","ubuntu_14_04_lts","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"ubuntu_14_04_lts"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":""},{"id":33471847,"value":"p1_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"24507"},{"id":34347728,"value":"515"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"ubuntu_14_04_lts"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":""},{"id":33471847,"value":"p1_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"24507"},{"id":34347728,"value":"515"},{"id":47825548,"value":false},{"id":25241186,"value":false}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1929.json","id":1929,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-10T23:37:54Z","updated_at":"2017-07-15T01:01:02Z","type":"incident","subject":"Enabling SSL in Kafka Cluster","raw_subject":"Enabling SSL in Kafka Cluster","description":"I am enabling SSL security in a Kafka cluster. I used kafka-generate-ssl.sh from GitHub as suggested in the Confluent documentation to generate my certs and keys. The attached spreadsheet provides details of what certs are in broker and client keystore and truststore files.\r\n\r\nIf I have no ACLs defined on my topic, I can run the kafka-console-producer and kafka-console-consumer successfully. If I add ACLs, the producer does not commit messages to the topic and the consumer returns no data. I suspect I am not identifying the principal correctly in the ACL.\r\n\r\n~~~ Transcript ~~~\r\n[kafka@ushapld00119la ~]$ bin/kafka-console-producer --broker-list SSL://ushapld00119la:9093 --topic ssl-test --producer.config /kafka/data/client/ssl/client.properties\r\n[2017-07-10 16:10:08,268] WARN The configuration group.id = ssl-test-group was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig)\r\n7/10/17\r\n[kafka@ushapld00119la ~]$ /kafka/confluent-3.0.1/bin/kafka-console-consumer --bootstrap-server SSL://ushapld00119la:9093 --zookeeper ushapld00119la:2181/kafka --topic ssl-test --from-beginning --new-consumer --consumer.config /kafka/data/client/ssl/client.properties\r\nz\r\nM2\r\nM3\r\nb\r\ne\r\ni\r\nj\r\nl\r\no\r\nq\r\ny\r\nssl no acls\r\n7/10/17\r\nM1\r\n^CProcessed a total of 14 messages\r\n[kafka@ushapld00119la ~]$ bin/kafka-acls --authorizer-properties zookeeper.connect=localhost:2181/kafka --add --allow-principal User:\"CN=Test Client,OU=Test Client Unit,O=Test Client Org,L=LA,ST=CA,C=US\" --consumer --topic ssl-test --group ssl-test-group\r\nAdding ACLs for resource `Topic:ssl-test`:\r\n        User:CN=Test Client,OU=Test Client Unit,O=Test Client Org,L=LA,ST=CA,C=US has Allow permission for operations: Read from hosts: *\r\n        User:CN=Test Client,OU=Test Client Unit,O=Test Client Org,L=LA,ST=CA,C=US has Allow permission for operations: Describe from hosts: *\r\n\r\nAdding ACLs for resource `Group:ssl-test-group`:\r\n        User:CN=Test Client,OU=Test Client Unit,O=Test Client Org,L=LA,ST=CA,C=US has Allow permission for operations: Read from hosts: *\r\n\r\nCurrent ACLs for resource `Topic:ssl-test`:\r\n        User:CN=Test Client,OU=Test Client Unit,O=Test Client Org,L=LA,ST=CA,C=US has Allow permission for operations: Read from hosts: *\r\n        User:CN=Test Client,OU=Test Client Unit,O=Test Client Org,L=LA,ST=CA,C=US has Allow permission for operations: Describe from hosts: *\r\n\r\nCurrent ACLs for resource `Group:ssl-test-group`:\r\n        User:CN=Test Client,OU=Test Client Unit,O=Test Client Org,L=LA,ST=CA,C=US has Allow permission for operations: Read from hosts: *\r\n\r\n[kafka@ushapld00119la ~]$ /kafka/confluent-3.0.1/bin/kafka-console-consumer --bootstrap-server SSL://ushapld00119la:9093 --zookeeper ushapld00119la:2181/kafka --topic ssl-test --from-beginning --new-consumer --consumer.config /kafka/data/client/ssl/client.properties\r\n^CProcessed a total of 0 messages\r\n[kafka@ushapld00119la ~]$\r\n~~~ End Transcript ~~~\r\n\r\nI am able to connect ","priority":null,"status":"closed","recipient":null,"requester_id":6021608663,"submitter_id":6021608663,"assignee_id":13678049447,"organization_id":6607631286,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["configuration_issue","confluent__3_0_1","development","jdk_1_7","p3_issue","rhel_6","security","summarized"],"custom_fields":[{"id":24843497,"value":"confluent__3_0_1"},{"id":26235617,"value":"jdk_1_7"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"security"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"1034"},{"id":34347728,"value":"36"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_0_1"},{"id":26235617,"value":"jdk_1_7"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"security"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"1034"},{"id":34347728,"value":"36"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"followup_ids":[],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1927.json","id":1927,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-10T22:37:13Z","updated_at":"2017-07-15T19:01:04Z","type":"incident","subject":"Kafka disk IO performance in VMs (OpenNebula)","raw_subject":"Kafka disk IO performance in VMs (OpenNebula)","description":"Hi!\r\n\r\nI'm doing a POC project, we're running dockerized (Ubuntu 16) Kafka and Zookkeeper in OpenNebula VMs on top of LVM and XFS in our own data center.\r\n\r\nI know that it's strongly recommend to configure Kafka with dedicated volumes (and this is what we do in AWS, for example), but we have to go with just one volume for OS and Kafka data/logs in this particular setup. \r\n\r\nWe did a small loadtest and Kafka didn't show any issues with 40k messages per second for a medium-sized cluster (Zookeeper x 3: 4 CPUs, 16 GB RAM, 20GB, Kafka x 9: 4 CPUs, 16 GB RAM, 100GB disk). \r\n\r\nSo, we haven't seen any issues with Kafka, but at the same time IO disk performance is a bit concerning. I've attached two screenshots with metrics, one for 5-15k messages per second and another for 20k - 40k messages per second. \r\n\r\nCPU iowait and System io wait are high, but not very high comparing to a similar msg/s rate for AWS cluster (~50% higher, which is not a lot in absolute numbers)\r\n\r\nSystem IO Avg Queue Size is way higher comparing to AWS. \r\n\r\nI do understand that dedicated volumes for Kafka data might improve the numbers, but I want to understand if, in your opinion, our current setup with one shared volume can be sufficient for this rate based on your experience. \r\n\r\nThanks!\r\n\r\nThis ticket includes a secure attachment. Use this link to access the attached files:\r\n https://confluent.sendsafely.com/receive/?thread=B8KL-R6AA&packageCode=E_joasZ3UYbZvWpQ4baXvOxWoaT8hsxsoDI3mg72OCE#keyCode=ShW70_fU28agqDq3V7F81EfxYY99qVkzQiZojFlrpfw","priority":null,"status":"closed","recipient":null,"requester_id":6035854666,"submitter_id":6035854666,"assignee_id":5699232346,"organization_id":906142867,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["configuration_issue","confluent__3_0_0","general_question","gold","jdk_1_8","multiple","p3_issue","summarized","ubuntu_16_04_lts","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_0_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"ubuntu_16_04_lts"},{"id":33020448,"value":"general_question"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"5918"},{"id":34347728,"value":"4"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"good","id":1737377163,"comment":null,"reason":"No reason provided","reason_id":332227},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_0_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"ubuntu_16_04_lts"},{"id":33020448,"value":"general_question"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"5918"},{"id":34347728,"value":"4"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"followup_ids":[],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1926.json","id":1926,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-10T21:21:58Z","updated_at":"2017-07-15T02:01:00Z","type":"incident","subject":"Your license has expired. Sign up for a subscription","raw_subject":"Your license has expired. Sign up for a subscription","description":"we are getting the following error in all the environments. Please share the correct config or the correct lic file please.\r\n\r\nI have the following property in /etc/confluent-control-center/control-center.properties \r\n\r\nconfluent.controlcenter.license=/etc/confluent-control-center/lic.key\r\n\r\nbelow is th key file content\r\n\r\n[root@qat-din-kaf-w2a-cc ~]# cat /etc/confluent-control-center/lic.key\r\neyJhbGciOiJSUzI1NiJ9.eyJpc3MiOiJDb25mbHVlbnQiLCJhdWQiOiJDMDAwMDAiLCJleHAiOjE1Mjc4MTEyMDAsImp0aSI6Ikcya1hWUUVsV3RLbDJIdERhbzFyOVEiLCJpYXQiOjE0OTYxODY4MjAsIm5iZiI6MTQ5NjE4NjcwMCwic3ViIjoiY29udHJvbC1jZW50ZXIiLCJtb25pdG9yaW5nIjp0cnVlfQ.fceFgvArQyhD3aGRgtAbHZcXrN1UzJ_PgZxKeZXYeadH3nnt75eCu1wvxkWKqyIGF_b6-WoBNE4GTzKPRYRxXlqi3c-KF00BxsRlfn-QUg0bpWljsiScXmSVL-e-_QEzVuzPVpWGxxPd-sASkuEkZxrdxRtNu07AXQnfAjUMZMhswjgWM9t6QiOXlbKKXJaeYMPomnrMhZ0QWQRCi5GMvQIwoANnjhXV5cA95f2AtGOguT62NWm5wBkTIUJpZ4KnwuLQ91Q83-zLS3EcUx1c9FTmhaNbYKoVecMkuxlo5Etk3pft3HB0TP1z4BzWSAmz25virbu0JKx3UH2QJd9yqw\r\n\r\nLet me know if you see any issue?","priority":null,"status":"closed","recipient":null,"requester_id":5766348623,"submitter_id":5766348623,"assignee_id":21324568227,"organization_id":5273937083,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["bug","confluent__3_2_1","confluent_control_center","gold","jdk_1_8","jeremy_custenborder","p1_issue","production","rhel_7","summarized","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":"bug"},{"id":33471847,"value":"p1_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"403"},{"id":34347728,"value":"22"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_7"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":"bug"},{"id":33471847,"value":"p1_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"403"},{"id":34347728,"value":"22"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"followup_ids":[],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1925.json","id":1925,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-10T21:12:24Z","updated_at":"2017-07-15T00:01:03Z","type":"incident","subject":"Create a connector using JSON","raw_subject":"Create a connector using JSON","description":"I am learning about connectors and APIs following the instructions at docs.confluent.io regarding creating a connector in Distributed Mode. I am not able to specify a JSON file as the data payload. Please help me get the correct format of data in the JSON data file.\r\n\r\nThis works:\r\ncurl -X POST localhost:8083/connectors -d '{\"name\":\"test-sqlite-jdbc-autoincrement\",\"config\":{\"connector.class\":\"io.confluent.connect.jdbc.JdbcSourceConnector\",\"tasks.max\":\"1\",\"connection.url\":\"jdbc:sqlite:demo.db\",\"mode\":\"incrementing\",\"incrementing.column.name\":\"id\",\"topic.prefix\":\"demo-test-\"}}' --header \"Content-Type: application/json\"\r\n\r\nHowever, this does not:\r\n[206047844@ashaplq00003 ~]$ cat demo.json\r\n'{\"name\":\"test-sqlite-jdbc-autoincrement\",\"config\":{\"connector.class\":\"io.confluent.connect.jdbc.JdbcSourceConnector\",\"tasks.max\":\"1\",\"connection.url\":\"jdbc:sqlite:demo.db\",\"mode\":\"incrementing\",\"incrementing.column.name\":\"id\",\"topic.prefix\":\"demo-test-\"}}\r\n[206047844@ashaplq00003 ~]$ curl -X POST localhost:8083/connectors -d @demo.json --header \"Content-Type: application/json\"\r\n<html>\r\n<head>\r\n<meta http-equiv=\"Content-Type\" content=\"text/html;charset=ISO-8859-1\"/>\r\n<title>Error 500 </title>\r\n</head>\r\n<body>\r\n<h2>HTTP ERROR: 500</h2>\r\n<p>Problem accessing /connectors. Reason:\r\n<pre>    Request failed.</pre></p>\r\n<hr /><i><small>Powered by Jetty://</small></i>\r\n</body>\r\n</html>\r\n","priority":null,"status":"closed","recipient":null,"requester_id":6021608663,"submitter_id":6021608663,"assignee_id":5699232346,"organization_id":6607631286,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["configuration_issue","confluent__3_0_1","development","jdbc_connector","jdk_1_7","p3_issue","rhel_6","summarized"],"custom_fields":[{"id":24843497,"value":"confluent__3_0_1"},{"id":26235617,"value":"jdk_1_7"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"jdbc_connector"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"763"},{"id":34347728,"value":"5"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_0_1"},{"id":26235617,"value":"jdk_1_7"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"jdbc_connector"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"763"},{"id":34347728,"value":"5"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"followup_ids":[],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1924.json","id":1924,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-10T19:54:21Z","updated_at":"2017-07-15T20:01:03Z","type":"incident","subject":"Kafka Streams partitioning for data locality","raw_subject":"Kafka Streams partitioning for data locality","description":"Hi, slightly urgent (but not prod) question. I want to use Kafka Streams for a use case and am unclear if I can from the docs. I need to route messages for a topic where each kstreams instance can only consume from a specific range of partitions and other instances on other nodes should not receive events from those partitions (unless some failover is happening). Is that possible? I see the StreamsPartitioner, and I have custom sharding logic for producers to access which provides the shard key for a message. ","priority":null,"status":"closed","recipient":null,"requester_id":6062320326,"submitter_id":6062320326,"assignee_id":21324568227,"organization_id":15608702368,"group_id":29623388,"collaborator_ids":[3324019678,20311193547],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["apache_kafka__0_10_2_1","centos_7","gold","jdk_1_8","kafka_streams","multiple","p3_issue","recommendation___best_practices","streams_escalated","summarized","us_canada"],"custom_fields":[{"id":24843497,"value":"apache_kafka__0_10_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"kafka_streams"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"1291"},{"id":34347728,"value":"47"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"apache_kafka__0_10_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"kafka_streams"},{"id":47641647,"value":"recommendation___best_practices"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"1291"},{"id":34347728,"value":"47"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"followup_ids":[],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1923.json","id":1923,"external_id":null,"via":{"channel":"email","source":{"from":{"address":"bharroff@theocc.com","name":"Brandon Harroff"},"to":{"name":"Confluent","address":"support@confluent.io"},"rel":null}},"created_at":"2017-07-10T19:34:08Z","updated_at":"2017-07-14T20:01:04Z","type":"incident","subject":"FW: Welcome to Confluent","raw_subject":"FW: Welcome to Confluent","description":"Hello,\n\n \n\nPlease create support accounts for the following OCC resources.\n\n \n\nAri Silverman, Satya Gunampalli and Greg Hanson.  They are copied on this email.\n\n \n\n \n\nThanks\n\n \n\n  2016 Clearinghouse of the Year by Global Investor/ISF Magazine\n\n \n\nFrom: Confluent [mailto:support@confluent.io]\nSent: Thursday, July 06, 2017 8:51 AM\nTo: Brandon Harroff <BHarroff@theocc.com>\nSubject: Welcome to Confluent\n\n \n\nA Confluent Support Portal account has been created for you. Please click the link at the bottom of this email to create a password and sign-in.\n\nOnce you've completed your account setup by logging in, you will be able to begin filing support cases via the web UI at https://support.confluent.io or via email at support@confluent.io (only for P3 and P4 cases). Before getting started, please take a moment to review the following resources:\n\n- Confluent Support Operations Guide: This document will provide you with an overview of the support process, instructions for filing cases (by phone, email or via the portal), including best practices for filing cases, escalation process, etc. Click here to review the document: https://support.confluent.io/hc/en-us/articles/228363028-Confluent-Support-Operations-Guide (https://support.confluent.io/hc/en-us/articles/228363028-Confluent-Support-Operations-Guide) .\n- The Knowledge Base: The Knowledge Base contains best practices guides and tutorials. For example, you will find our best practices guide on setting up Kafka monitoring or on running in AWS. Click here to see the KB: https://support.confluent.io/hc/en-us/sections/204418567-Operation-Guides (https://support.confluent.io/hc/en-us/sections/204418567-Operation-Guides) .\n- Best Practices for Providing Logs to Confluent: When you file a support case, you can reduce the turnaround time by providing the correct logs and data that our support team will need to help troubleshoot the issue. Please review this guide for more information: https://support.confluent.io/hc/en-us/articles/227184847-Best-Practices-for-Providing-Logs-to-Support (https://support.confluent.io/hc/en-us/articles/227184847-Best-Practices-for-Providing-Logs-to-Support) .\n\nIf you have any questions about the support process, please feel free to reach out to our team by emailing support@confluent.io!\n\nhttps://support.confluent.io/verification/email/d8N8C17HrGNB764ofIbYqmEYX\n\nThis email is a service from Confluent. Delivered by Zendesk (https://www.zendesk.com/product/tour/?utm_campaign=text&utm_content=Confluent&utm_medium=poweredbyzendesk&utm_source=email-notification)\n\nThis message may contain information that is privileged or confidential. If you are not the intended recipient, please advise the sender immediately by reply email and delete this message and any attachments without retaining a copy.","priority":null,"status":"closed","recipient":"support@confluent.io","requester_id":6021443643,"submitter_id":6021443643,"assignee_id":3324019678,"organization_id":6606691126,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["confluent__3_2_2","general_question__account_admin","jdk_1_8","multiple","non_technical_request__account_admin","p3_issue","summarized"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":""},{"id":33020448,"value":"general_question__account_admin"},{"id":47641647,"value":"non_technical_request__account_admin"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"51"},{"id":34347728,"value":"5"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":""},{"id":33020448,"value":"general_question__account_admin"},{"id":47641647,"value":"non_technical_request__account_admin"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"51"},{"id":34347728,"value":"5"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"followup_ids":[],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1758.json","id":1758,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-06-21T08:54:58Z","updated_at":"2017-07-13T16:01:03Z","type":"incident","subject":"Removing corrupted checkpoint files ","raw_subject":"Removing corrupted checkpoint files ","description":"Hi,\r\n\r\nWe have recently run into an issue with corrupted checkpoint files (recovery-point-offset-checkpoint and replication-offset-checkpoint). We were running back up tests where we tried to recover from backed up Kafka logs. At some point we  have noticed that not all partitions were listed in the checkpoint files, which probalby means they got corrupted. Kafka was unable to recover, because there were lots of underreplicated partitions. We also got such errors:\r\n\r\n2017-06-20 12:26:57,668 198323 [ReplicaFetcherThread-3-3] WARN  kafka.server.ReplicaFetcherThread - [ReplicaFetcherThread-3-3], Error in fetch kafka.server.ReplicaFetcherThread$FetchRequest@1f0f1b2c\r\njava.io.IOException: Connection to ap-cl5d.oneadr.net:9093 (id: 3 rack: null) failed \r\n\r\nWhat we did is we have stopped all the Kafka nodes and removed checkpoint files. After we started Kafka brokers once again it took some time to recreate the checkpoint files, but after a while everything stabilized and it seems we have not lost much data.\r\n\r\nWe are aware we may lose some messages, but we would like it to be rather deterministic. If replica X has 10 messages and replica Y has 11 messages we are fine with losing this 1 message, because X was chosen as the leader. Or maybe Kafka is clever enough to pick Y as the leader, because it has the most fresh data?\r\n\r\nCould you advise us whether we are doing something entirely wrong or maybe provide some insights on possible caveats of removing the checkpoint files? Please help us understand how it works and learn about the possible problems we may experience.\r\n\r\nKind regards,\r\n\r\nMateusz Bukowicz","priority":null,"status":"solved","recipient":null,"requester_id":11172175927,"submitter_id":11172175927,"assignee_id":13678049447,"organization_id":2798102687,"group_id":29623388,"collaborator_ids":[20922759567,5780723263,6009169018,21100642187,13678049447,3324019678],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["apache_kafka__0_10_0_1","broker","centos_7","europe","gold","improper_use","jdk_1_8","p3_issue","staging","summarized"],"custom_fields":[{"id":24843497,"value":"apache_kafka__0_10_0_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"broker"},{"id":47641647,"value":"improper_use"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"staging"},{"id":77414608,"value":null},{"id":34347708,"value":"8239"},{"id":34347728,"value":"377"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"apache_kafka__0_10_0_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"broker"},{"id":47641647,"value":"improper_use"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"staging"},{"id":77414608,"value":null},{"id":34347708,"value":"8239"},{"id":34347728,"value":"377"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1921.json","id":1921,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-10T17:37:38Z","updated_at":"2017-07-14T19:01:02Z","type":"incident","subject":"loggc flag in kafka-server-start","raw_subject":"loggc flag in kafka-server-start","description":"Currently the kafka start script passes a `-loggc` flag as extra_args. This leads to a creation of massive a massive log file, and causes a lot of headaches with alerts and emails for us.\r\n\r\nQuestion:\r\nCan we stop logging GC or is that in any way useful when it comes to Confluent support tickets?","priority":null,"status":"closed","recipient":null,"requester_id":20715096987,"submitter_id":20715096987,"assignee_id":5699232346,"organization_id":14109642148,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["chris_matta","configuration_issue","confluent__3_2_1","general_question","gold","jdk_1_8","multiple","p3_issue","summarized","ubuntu_14_04_lts","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"ubuntu_14_04_lts"},{"id":33020448,"value":"general_question"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"2092"},{"id":34347728,"value":"150"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"ubuntu_14_04_lts"},{"id":33020448,"value":"general_question"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"2092"},{"id":34347728,"value":"150"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"followup_ids":[],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1920.json","id":1920,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-10T16:23:36Z","updated_at":"2017-07-15T14:01:03Z","type":"incident","subject":"Where are the JVM settings for Control Center?","raw_subject":"Where are the JVM settings for Control Center?","description":"Out of heap error on C3.\r\n\r\nThe docs never show where to put the JVM settings for more heap, though they spend a significant amount of time explaining the settings.\r\n\r\nWhere can I find this? \r\n\r\nCan you update your docs to clearly show where to set these?\r\n\r\n====================\r\nJVM\r\nWe recommend running the latest version of JDK 1.8 with the G1 collector (older freely available versions have disclosed security vulnerabilities).\r\n\r\nIf you are still on JDK 1.7 (which is also supported) and you are planning to use G1 (the current default), make sure you’re on u51. We tried out u21 in testing, but we had a number of problems with the GC implementation in that version.\r\n\r\nOur recommended GC tuning (tested on a large deployment with JDK 1.8 u5) looks like this:\r\n\r\n-Xms6g -Xmx6g -XX:MetaspaceSize=96m -XX:+UseG1GC -XX:MaxGCPauseMillis=20\r\n       -XX:InitiatingHeapOccupancyPercent=35 -XX:G1HeapRegionSize=16M\r\n              -XX:MinMetaspaceFreeRatio=50 -XX:MaxMetaspaceFreeRatio=80\r\n\r\n\r\n\r\nhttp://docs.confluent.io/3.0.0/schema-registry/docs/deployment.html?highlight=jvm%20heap%20size\r\n\r\nhttp://docs.confluent.io/3.0.0/control-center/docs/configuration.html\r\n","priority":null,"status":"closed","recipient":null,"requester_id":21241013828,"submitter_id":21241013828,"assignee_id":5907439417,"organization_id":15862746548,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_7","configuration_issue","confluent__3_2_2","confluent_control_center","jdk_1_8","p2_issue","production","silver","summarized","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"1331"},{"id":34347728,"value":"80"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"good","id":1736484383,"comment":"Though the Heap setting was too low, I had to increase it to 16GB instead of 6GB. Not sure why there was a need for such a large heap for C3.\r\n","reason":"No reason provided","reason_id":332227},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_2"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"confluent_control_center"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p2_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"1331"},{"id":34347728,"value":"80"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"followup_ids":[],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1914.json","id":1914,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-10T15:17:59Z","updated_at":"2017-07-14T18:01:03Z","type":"incident","subject":"Additional Confluent Support Website Accounts","raw_subject":"Additional Confluent Support Website Accounts","description":"Hi guys,\r\n\r\nlast week I had a meeting with your colleague Falko Schwarz and was told that there no longer is a limit on the number of accounts on support.confluent.io and that our current subscription now also includes developer support.\r\n\r\nIn order to be able to make use of the developer support for our Kafa installation as well as increase the coverage of operations colleagues with accounts on this website, I'd like to ask you to generate accounts for the following colleagues.\r\n\r\nNote: some of them might already have an account here (I am not sure how I could check that), in those cases just continue with the next ones.\r\n\r\nEmail addresses to add:\r\nBraun, Michael <michael.braun@sap.com>\r\nKohl, Oliver <o.kohl@sap.com>\r\nFriedrich, Mirko <mirko.friedrich@sap.com>\r\nUnnewehr, Johannes <johannes.unnewehr@sap.com>\r\nWolf, Sebastian <sebastian.wolf@sap.com>\r\nSpichale, Kai <kai.spichale@sap.com>\r\nDraeger, Thorsten <thorsten.draeger@sap.com>\r\nKukushkin, Boris (external - Project) <boris.kukushkin@sap.com>\r\nShut, Aliaksandr (external - Project) <aliaksandr.shut@sap.com>\r\nZaprudskiy, Stanislav (external - Project) <stanislav.zaprudskiy@sap.com>\r\nBar, Yaniv <yaniv.bar@sap.com>\r\nKrakower, Shmuel (external - Project) <shmuel.krakower@sap.com>\r\nLeonovich, Evgeniya (external - Project) <evgeniya.leonovich@sap.com>\r\nKhoghevets, Alexei (external - Project) <alexei.khoghevets@sap.com>\r\nHaladko, Maryia (external - Project) <maryia.haladko@sap.com>\r\nKharytonenka, Igar (external - Project) <igar.kharytonenka@sap.com>\r\nKulsha, Pavel (external - Project) <pavel.kulsha@sap.com>\r\nMalko, Uladzimir (external - Project) <uladzimir.malko@sap.com>\r\nShakavin, Maksim (external - Project) <maksim.shakavin@sap.com>\r\nShymanovich, Ivan (external - Project) <ivan.shymanovich@sap.com>\r\nSidorkin, Dzmitry (external - Project) <dzmitry.sidorkin@sap.com>\r\nVarabei, Siarhei (external - Project) <siarhei.varabei@sap.com>\r\n\r\nThanks!\r\n\r\nGreetings\r\nValentin","priority":null,"status":"closed","recipient":null,"requester_id":7664002548,"submitter_id":7664002548,"assignee_id":5907439417,"organization_id":6979871967,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["apache_kafka__0_10_2_1","cc_added_here","enterprise","europe","general_question__account_admin","gold","jdk_1_8","multiple","non_technical_request__account_admin","p3_issue","rhel_6","summarized","support_cust"],"custom_fields":[{"id":24843497,"value":"apache_kafka__0_10_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"general_question__account_admin"},{"id":47641647,"value":"non_technical_request__account_admin"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"672"},{"id":34347728,"value":"667"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"apache_kafka__0_10_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"rhel_6"},{"id":33020448,"value":"general_question__account_admin"},{"id":47641647,"value":"non_technical_request__account_admin"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"672"},{"id":34347728,"value":"667"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"followup_ids":[],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1739.json","id":1739,"external_id":null,"via":{"channel":"web","source":{"to":{},"from":{"ticket_id":null,"subject":null},"rel":"follow_up"}},"created_at":"2017-06-19T18:33:00Z","updated_at":"2017-06-27T14:54:26Z","type":"incident","subject":"Re: Re: [Confluent] Re: Confluent Kafka Connect S3 tasks killed over time","raw_subject":"Re: Re: [Confluent] Re: Confluent Kafka Connect S3 tasks killed over time","description":"This is a follow-up to your previous request #1563 \"Re: [Confluent] Re: Confluent Kafka Connect S3 tasks killed over time\"\r\n\r\nThis ticket includes a secure attachment. Use this link to access the attached files:\r\n https://confluent.sendsafely.com/receive/?thread=ZLSM-D8A3&packageCode=8H8JXM6TT7KqJ4WDUJETkW7_gF3d0_BVyJ1nGhlM_qs#keyCode=RA5sG8MYOvuNCtlNTlbJT7NAltwhRejeh3XcMlgHa3c","priority":null,"status":"hold","recipient":null,"requester_id":12508964568,"submitter_id":12508964568,"assignee_id":5930716698,"organization_id":10848328548,"group_id":29623388,"collaborator_ids":[12495406047,20503734328,21366152747],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["bug","case_handoff","centos_7","confluent__3_2_0","development","gold","jdk_1_8","jira_escalated","kafka_connect__s3_connector","p3_issue","summarized","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"kafka_connect__s3_connector"},{"id":47641647,"value":"bug"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"18613"},{"id":34347728,"value":"1227"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"unoffered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"kafka_connect__s3_connector"},{"id":47641647,"value":"bug"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"development"},{"id":77414608,"value":null},{"id":34347708,"value":"18613"},{"id":34347728,"value":"1227"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1910.json","id":1910,"external_id":null,"via":{"channel":"web","source":{"to":{},"from":{"ticket_id":null,"subject":null},"rel":"follow_up"}},"created_at":"2017-07-08T21:17:34Z","updated_at":"2017-07-14T17:01:03Z","type":"incident","subject":"Re: Streams 0.10.2.0 + RocksDB + Avro","raw_subject":"Re: Streams 0.10.2.0 + RocksDB + Avro","description":"This is a follow-up to your previous request #1028 \"Streams 0.10.2.0 + RocksDB + Avro\"\r\n\r\nHi Justin,\r\n\r\nCCing Ben as I mentioned this to him on Friday.\r\n\r\nI just wanted to follow up on this issue as I have just tracked down the fact that it was fixed in streams release 0.10.2.1.\r\n\r\nThe fix was committed here:\r\nhttps://github.com/apache/kafka/blame/0.10.2.1/streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBStore.java#L146\r\n\r\nAnd as mentioned by davispw in the conversation for the PR (https://github.com/apache/kafka/pull/2776), notably the first bullet point; it missed a shoutout in any release notes including the Confluent ones. While I appreciate Matthias' point of view in those comments it definitely should have been mentioned on the CP release notes; unfortunately we missed it.\r\n\r\nThat being said, glad it is finally resolved!\r\n\r\nMany thanks\r\nAdrian","priority":null,"status":"closed","recipient":null,"requester_id":19548920387,"submitter_id":19548920387,"assignee_id":13678049447,"organization_id":14302137927,"group_id":29623388,"collaborator_ids":[5979261663],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["apache_kafka__0_10_2_0","bug","debian_8","europe","jdk_1_8","kafka_streams","p3_issue","platinum","staging","streams_escalated","summarized"],"custom_fields":[{"id":24843497,"value":"apache_kafka__0_10_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"debian_8"},{"id":33020448,"value":"kafka_streams"},{"id":47641647,"value":"bug"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"staging"},{"id":77414608,"value":""},{"id":34347708,"value":"958"},{"id":34347728,"value":"55"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"apache_kafka__0_10_2_0"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"debian_8"},{"id":33020448,"value":"kafka_streams"},{"id":47641647,"value":"bug"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"staging"},{"id":77414608,"value":""},{"id":34347708,"value":"958"},{"id":34347728,"value":"55"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"followup_ids":[],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1909.json","id":1909,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-08T14:17:40Z","updated_at":"2017-07-12T15:01:01Z","type":"incident","subject":"Production Data Missing ","raw_subject":"Production Data Missing ","description":"we are doing the initial loads using Kafka in Production and we are seeing some data missing from our source to target.\r\n\r\nNeed help in figuring out what is going on..!","priority":null,"status":"closed","recipient":null,"requester_id":5991633766,"submitter_id":5991633766,"assignee_id":21324568227,"organization_id":6328931306,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["broker","centos_7","confluent__3_2_1","enterprise","gold","jdk_1_8","jeremy_custenborder","non_technical_request","p1_issue","production","summarized","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"broker"},{"id":47641647,"value":"non_technical_request"},{"id":33471847,"value":"p1_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"84"},{"id":34347728,"value":"34"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"good","id":1729025623,"comment":null,"reason":"No reason provided","reason_id":332227},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_7"},{"id":33020448,"value":"broker"},{"id":47641647,"value":"non_technical_request"},{"id":33471847,"value":"p1_issue"},{"id":33029747,"value":"production"},{"id":77414608,"value":null},{"id":34347708,"value":"84"},{"id":34347728,"value":"34"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"followup_ids":[],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1906.json","id":1906,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-07T18:39:54Z","updated_at":"2017-07-11T21:01:01Z","type":"incident","subject":"rebalancer license","raw_subject":"rebalancer license","description":"Have the following in our server.properties for our kafka brokers but getting a license expired when attempting to run the rebalancer\r\n\r\nconfluent.rebalancer.license=eyJhbGciOiJSUzI1NiJ9.eyJpc3MiOiJDb25mbHVlbnQiLCJhdWQiOiJDMDAxMzUiLCJleHAiOjE1MjI1NDA4MDAsImp0aSI6IkRSWUJ6WjNpSkpnMlhOYks2ZVpmZVEiLCJpYXQiOjE0OTIwMzk2NDUsIm5iZiI6MTQ5MjAzOTUyNSwic3ViIjoiY29udHJvbC1jZW50ZXIiLCJtb25pdG9yaW5nIjp0cnVlfQ.GK-c-jQeQFa4fqZL9CtsP270ypzxScOx7PBjaMVxC9hb7LwnbkfCfD6U7vMgNv588BpGspDHqH-ZI43vhbkVk9uqtouDA98lv98rNm930QJk8vuM_itvZSKKmjKYgD-iRW1bGJxY8_5b5VU9rBY5D-YGHtxzJ25GFx_hSDuOrdvLaHtjh8xkKNX8zfuwUN9QBAiNX8XMfCzxd4GYqONLPNY0DF2G5ZkOlRhO1Gj-ApuOFF-UQ3Gyu2NvBWRe6LKSBzF6I8BSduqn329zK7uJdbrIvXY2hAWrUbtepQT7qY60R0j2ZAgxLl6cD4zW_0vQScSdGnt6ZMB-39wwAKRfFw\r\n\r\n/etrade/sit-confluent-opintel-kafka_op/packages/confluent/bin/confluent-rebalancer execute --zookeeper sit320w86m7:2181 --metrics-bootstrap-server sitkafka342w88m7:9092 --throttle 10000000 --verbose\r\n\r\nYour trial period has expired. Please purchase a license to continue using this product.","priority":null,"status":"closed","recipient":null,"requester_id":21000116327,"submitter_id":21000116327,"assignee_id":5699232346,"organization_id":15862541148,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["centos_6","configuration_issue","confluent__3_2_1","general_question","gold","jdk_1_8","p3_issue","qa","summarized","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_6"},{"id":33020448,"value":"general_question"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"qa"},{"id":77414608,"value":null},{"id":34347708,"value":"1691"},{"id":34347728,"value":"289"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"centos_6"},{"id":33020448,"value":"general_question"},{"id":47641647,"value":"configuration_issue"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"qa"},{"id":77414608,"value":null},{"id":34347708,"value":"1691"},{"id":34347728,"value":"289"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"followup_ids":[],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"},{"url":"https://confluent.zendesk.com/api/v2/tickets/1898.json","id":1898,"external_id":null,"via":{"channel":"web","source":{"from":{},"to":{},"rel":null}},"created_at":"2017-07-06T21:09:10Z","updated_at":"2017-07-11T18:01:02Z","type":"incident","subject":"Create new Users to the Confluent Support Portal","raw_subject":"Create new Users to the Confluent Support Portal","description":"Please add the following 2 users to the support portal. \r\n\r\nMichael Poole - michael.poole@amway.com\r\nDaniel Newell - daniel.newell@amway.com","priority":null,"status":"closed","recipient":null,"requester_id":6022861203,"submitter_id":6022861203,"assignee_id":21324568227,"organization_id":6638527023,"group_id":29623388,"collaborator_ids":[],"forum_topic_id":null,"problem_id":null,"has_incidents":false,"is_public":true,"due_at":null,"tags":["chris_matta","confluent__3_2_1","general_question__account_admin","gold","jdk_1_8","multiple","non_technical_request__account_admin","p3_issue","summarized","ubuntu_16_04_lts","us_canada"],"custom_fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"ubuntu_16_04_lts"},{"id":33020448,"value":"general_question__account_admin"},{"id":47641647,"value":"non_technical_request__account_admin"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"180"},{"id":34347728,"value":"16"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"satisfaction_rating":{"score":"offered"},"sharing_agreement_ids":[],"fields":[{"id":24843497,"value":"confluent__3_2_1"},{"id":26235617,"value":"jdk_1_8"},{"id":26235607,"value":"ubuntu_16_04_lts"},{"id":33020448,"value":"general_question__account_admin"},{"id":47641647,"value":"non_technical_request__account_admin"},{"id":33471847,"value":"p3_issue"},{"id":33029747,"value":"multiple"},{"id":77414608,"value":null},{"id":34347708,"value":"180"},{"id":34347728,"value":"16"},{"id":47825548,"value":false},{"id":25241186,"value":true}],"followup_ids":[],"ticket_form_id":599227,"brand_id":129937,"satisfaction_probability":null,"allow_channelback":false,"result_type":"ticket"}],"facets":null,"next_page":"https://confluent.zendesk.com/api/v2/search.json?page=2&query=type%3Aticket+created%3C2017-07-14","previous_page":null,"count":1825}